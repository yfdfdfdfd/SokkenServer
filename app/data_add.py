from models import QuestionModel
from database import SessionLocal, engine

db = SessionLocal()
model1 = QuestionModel(
    question_text="単純パーセプトロンは何を学習するためのモデルですか。",
    correct_answer="b.二値分類問題",
    choices=[
        "a.回帰問題",
        "b.二値分類問題",
        "c.多クラス分類問題",
        "d.回帰と分類の両方",
    ],
    commentary="単純パーセプトロンは、二値分類問題を学習するためのモデルです。",
    tag="深層学習",
)

db = SessionLocal()
model2 = QuestionModel(
    question_text="多層パーセプトロンは何を学習するためのモデルですか。",
    correct_answer="d.回帰と分類両方",
    choices=[
        "a.回帰問題",
        "b.二値分類問題",
        "c.多クラス分類問題",
        "d.回帰と分類両方",
    ],
    commentary="多層パーセプトロンは、回帰と分類の両方の問題を学習ためのモデルです",
    tag="深層学習",
)

db = SessionLocal()
model3 = QuestionModel(
    question_text="ディープラーニングは何に対して特に効果的ですか？",
    correct_answer="c.大規模データセット",
    choices=[
        "a.小規模データセット",
        "b.中規模データセット",
        "c.大規模データセット",
        "d.ディープラーニングはデータサイズに関係なく効果的",
    ],
    commentary="ディープラーニングは、特に大規模データセットに対して効果的です。",
    tag="深層学習",
)

# db = SessionLocal()
# model4 = QuestionModel(
#     question_text="",
#     correct_answer="",
#     choices=[
#         "",
#         "",
#         "",
#         "",
#     ],
#     commentary="",
#     tag="深層学習",
# )

db = SessionLocal()
model5 = QuestionModel(
    question_text="勾配消失問題は何に関連していますか？",
    correct_answer="b.ニューラルネットワークの深さに関連する問題",
    choices=[
        "a.パラメータ更新の速度が遅い問題",
        "b.ニューラルネットワークの深さに関連する問題",
        "c.データの次元が大きい問題",
        "d.モデルの過剰適合問題",
    ],
    commentary="勾配消失問題は、ニューラルネットワーク深さに関連する問題です。",
    tag="深層学習",
)

db = SessionLocal()
model5 = QuestionModel(
    question_text="信用割当問題は何に関連していますか？",
    correct_answer="a.強化学習における行動の評価",
    choices=[
        "a.強化学習における行動の評価",
        "b.ニューラルネットワークの訓練の初期化",
        "c.データの次元削減",
        "d.モデルの評価手法",
    ],
    commentary="信用割当問題(Credit Assignment Problem)は、特定の結果に対してどの部分(ニューロン、行動、ステップなど)が貢献したかを特定する課題です。強化学習において、特定の行動が後の報酬にどの程度貢献したかを判断するのが典型的な例です。ニューラルネットワークにおいても、特定のニューロンや層が最終出力に対してどの程度寄与しているかを分析することがこれに該当します",
    tag="深層学習",
)

db = SessionLocal()
model6 = QuestionModel(
    question_text="事前学習とは何ですか？",
    correct_answer="b.事前に学習済みのモデルを使用してモデルをトレーニングすること",
    choices=[
        "a.ラベル付きデータを使用してモデルをトレーニングすること",
        "b.事前に学習済みのモデルを使用してモデルをトレーニングすること",
        "c.ラベルなしデータを使用してモデルをトレーニングすること",
        "d.事前にモデルのハイパーパラメータを設定すること",
    ],
    commentary="事前学習(Pre-training)とは、通常、大規模なデータセットを使用してモデルをあらかじめ学習させ、その後、特定のタスクに合わせて微調整(ファインチューニング)を行うプロセスです。この場合、「事前に学習済みのモデルを使用してモデルをトレーニングすること」が正しい定義です。",
    tag="深層学習",
)

db = SessionLocal()
model7 = QuestionModel(
    question_text="オートエンコーダは何を行うためのモデルですか？",
    correct_answer="c.次元削減",
    choices=[
        "a.分類",
        "b.クラスタリング",
        "c.次元削減",
        "d.特徴量エンジニアリング",
    ],
    commentary="オートエンコーダは、次元削減を行うためのモデルです。",
    tag="深層学習",
)

db = SessionLocal()
model8 = QuestionModel(
    question_text="積層オートエンコーダとは何ですか？",
    correct_answer="b.複数の隠れ層を持つオートエンコーダ",
    choices=[
        "a.単一の隠れ層を持つオートエンコーダ",
        "b.複数の隠れ層を持つオートエンコーダ",
        "c.畳み込みニューラルネットワーク",
        "d.リカレントニューラルネットワーク",
    ],
    commentary="積層オートエンコーダ(Stacked Autoencoder)は複数の隠れ層を持つオートエンコーダです。このモデルは、各層が前の層の出力を入力として使用することで、データのより複雑な特徴を学習します。積層オートエンコーダは、データの次元削減、特徴抽出、データの圧縮などに利用され、深い層を持つため、より高度なデータ表現を学習することができます。隠れ層が増えることでモデルはより抽象的で意味のある特徴を捉えることが可能になります。",
    tag="深層学習",
)

db = SessionLocal()
model9 = QuestionModel(
    question_text="ファインチューニングとは何ですか？",
    correct_answer="a.事前学習済みモデルを使してモデルを再トレーニングすること",
    choices=[
        "a.事前学習済みモデルを使してモデルを再トレーニングすること",
        "b.ハイパーパラメータを手動で調整すること",
        "c.データセットを増やすこと",
        "d.モデルのパラメータをランダムに初期化すること",
    ],
    commentary="ファインチューニングは、事前学習済みモデルを特定のタスクに適応させるために再トレーニングする手法です。一般的には、大規模なデータセット(例えばImageNetなど)で事前に訓練されたモデルを、新しいデータセットに対してさらに訓練することで、特定のタスクに対して高い性能を発揮させます。ファインチューニングでは、事前学習済みモデルの重みを初期値として使用し、それらの重みを新しいデータに基づいて微調整します。これにより、トレーニング時間の短縮や性能の向上が期待できます。",
    tag="深層学習",
)

db = SessionLocal()
model10 = QuestionModel(
    question_text="深層信念ネットワークは何を使用してトレーニングされますか？",
    correct_answer="b.教師なし学習",
    choices=[
        "a.教師あり学習",
        "b.教師なし学習",
        "c.強化学習",
        "d.半教師あり学習",
    ],
    commentary="深層信念ネットワークは、制約付きボルツマンマシン(Restricted Boltzmann Machine、RBM)を多層に積み重ねたニューラルネットワークの一種です。深層信念ネットワークは教師なし学習の一形態であり、データの特徴を自動的に学習することができます。具体的には、RBMの層間で特徴を抽出し、その後に教師あり学習などの手法を用いてタスクを解決することができます。",
    tag="深層学習",
)

db = SessionLocal()
model11 = QuestionModel(
    question_text="デンドログラムが利用されるクラスタリング手法として最も適切な選択肢を1つ選べ",
    correct_answer="d.群平均法",
    choices=[
        "a.DBSCAN",
        "b.主成分分析",
        "c.k-means法",
        "d.群平均法",
    ],
    commentary="デンドログラムは、階層的クラスタリングの結果を示す木構造の図です。この図では、データポイントがどのようにグループ化されるかを示しており、階層的なクラスタリング手法（Hierarchical Clustering）でよく利用されます。階層的クラスタリングは、データを階層的に（段階的に）クラスタに分ける手法です。a.DBSCAN（Density-Based Spatial Clustering of Applications with Noise）は密度ベースのクラスタリング手法で、デンドログラムは生成しません。b.主成分分析（PCA）**は次元削減の手法で、クラスタリングとは直接関係ありません。c.k-means法は非階層的クラスタリング手法であり、デンドログラムは生成されません。",
    tag="深層学習",
)

db = SessionLocal()
model12 = QuestionModel(
    question_text="次の文章を読み、空欄に最もよく当てはまる選択肢を選べ。ニューラルネットワーク(以下NN)における順伝播は右図のように表される。ただし、ここでは重みパラメータを（ア）として示している。NNは入力層と出力層、その間にある隠れ層で構成される。また近年では、隠れ層の活性化関数φとして、（イ）を解決できるという理由から、ReLU関数が主流になっている。NNの目標は、モデルの予測値を正解ラベル(目的変数)の値に近づけることであり、その差を表す誤差関数を最小化する手法が取られている。NNでは、この最小化アルゴリズムの一つに勾配降下法が使われる。さらにその一種として、学習データの一部を毎度ランダムに抽出し、それに対する損失関数を重み更新ごとに確率的に変える（ウ）がある。また、出力層に近い層から順に連鎖的に算出した勾配をもとに各重みパラメータを更新していく学習法は（エ）と呼ばれる。",
    correct_answer="b.(ア)w (イ)勾配消失問題 (ウ)確率的勾配降下法 (エ)誤差逆伝播法",
    choices=[
        "a.(ア)w (イ)勾配爆発問題 (ウ)確率的勾配降下法 (エ)連鎖律",
        "b.(ア)w (イ)勾配消失問題 (ウ)確率的勾配降下法 (エ)誤差逆伝播法",
        "c.(ア)b (イ)勾配爆発問題 (ウ)最急降下法 (エ)連鎖律",
        "d.(ア)b (イ)勾配消失問題 (ウ)最急降下法 (エ)誤差逆伝播法",
    ],
    commentary="勾配消失問題とは、モデルの学習中で誤差関数の勾配が0に収束して学習が滞ってしまう問題です。これに対して勾配爆発問題は、勾配が発散してしまいコンピュータの処理が困難になる問題のことを指します。a：wは重みパラメータ、bはバイアスと呼ばれます。よって（ア）にはwが当てはまります。c：損失関数の最適化手法である最急降下法と確率的勾配降下法(Stochastic Gradient Descent)の区別を問う問題です。     最急降下法とは、損失関数Lのパラメータwにおける勾配とは逆向きの方向に重みパラメータを更新する手法です。d：誤差逆伝播法とは、問題文の通りです。右図では、NNにおいて誤差逆伝播法が使われることに至った背景を示しています。ここで”コスト関数”とは、重みパラメータ全てを変数としたNNの「精度の低さ」としています。これは一般に数式では定義できません。",
    tag="深層学習",
)

db = SessionLocal()
model13 = QuestionModel(
    question_text="次の文章を読み,(ア)に最もよく当てはまる選択肢を1つ選べニューラルネットワークにおいて機械学習アルゴリズムを最適化する方法の一つに(ア)がある。(ア)は,ニューラルネットワークのレイヤー間のつながり(パラメータ)を削除し,パラメータの数を減らして計算を高速化することができる。",
    correct_answer="d.プルーニング",
    choices=[
        "a.early stopping",
        "bドロップアウト",
        "c.正規化",
        "d.プルーニング",
    ],
    commentary="正解はdである。プルーニングとは,ニューラルネットワークの重み(パラメータ)の一部を取り除く手法である。a：early stoppingは,過学習を起こす前に学習を終了するという手法である。b：ドロップアウトは,ニューラルネットワークのユニットを一定の確率でランダムに無効にしながら学習を進め る手法である。c：正規化は、入力値の範囲を揃える処理のことである。",
    tag="深層学習",
)

db = SessionLocal()
model14 = QuestionModel(
    question_text="Deep Residual Learningに関する説明として,最も適切な選択肢を1つ選べ",
    correct_answer="c.残差ブロックを導入することで勾配消失問題に対処している。",
    choices=[
        "a.2014年のILSVRCで優勝したモデルである。",
        "b.GAP(Global Average Pooling)を導入することで,パラメータ数を削減し,過学習を抑制している。",
        "c.残差ブロックを導入することで勾配消失問題に対処している。",
        "d.13層の畳み込み層と3層の全結合層により構成されるモデルである。",
    ],
    commentary="正解はcである。Deep Residual Learning(ResNet)とは,2015年のILSVRCで優勝したモデルであり,152層ものニューラルネットワークで構成されている。残差ブロックを導入することで勾配消失問題に対処し,飛躍的に層を増やすことに成功した。a：2014年のILSVRCで優勝したモデルはGoogleNetである。b：GoogleNetについての説明である。c：VGG-16についての説明である。",
    tag="深層学習",
)

db = SessionLocal()
model15 = QuestionModel(
    question_text="ドメインランダマイゼーション(Domain Randomization)に関する説明として,最も適切な選択肢を1つ選べ",
    correct_answer="d.ランダム化されたプロパティを使用して様々な学習用のシミュレーション環境を作成することが出来る。",
    choices=[
        "a.実際の分布を捉えるための大量の実データサンプルを必要とする。",
        "b.ハイパーパラメータをランダムに探索する手法である。",
        "c.教師あり学習に分類される。",
        "d.ランダム化されたプロパティを使用して様々な学習用のシミュレーション環境を作成することが出来る。",
    ],
    commentary="正解dである。ドメインランダマイゼーション(Domain Randomization)とは,ランダム化されたプロパティを使用して様々な学習用のシミュレーション環境を作成する手法である.これらすべての環境で機能するようにモデルを学習していく。a：ドメインランダマイゼーションでは実データをほとんど必要としない.。b：ランダムサーチについての説明である。c：ドメインランダマイゼーションは教師なし学習である。",
    tag="深層学習",
)

db = SessionLocal()
model16 = QuestionModel(
    question_text="以下の文章を読み、(ア)に最もよく当てはまる選択肢を１つ選べニューラルネットワークモデルの予測値を実際の値に近づけるように学習を行うために、(ア)を定義し、その値を最小化するようにモデルのパラメータを更新する。",
    correct_answer="b.損失関数",
    choices=[
        "a.カーネル関数",
        "b.損失関数",
        "c.活性化関数",
        "d.価値関数",
    ],
    commentary="正解はbである。学習の目的は、「モデルの予測出力と実際の値との誤差を最小化すること」です。モデルの出力と正解の間の誤差を表すのが損失関数(誤差関数)であり、これを最小化するように、ネットワークのパラメータ(重みなど)が更新されていきます。a：カーネル関数はサポートベクトルマシン(SVM)において、写像後の空間で線形分類できるように、データを高次元に写像するために使う関数です。c：活性化関数は、ネットワークの層間に伝播する信号を調整する関数です。d：価値関数とは、強化学習においてエージェントがある状態に存在したり、行動を選択したりすることにどれくらいの価値があるのかを定量化した関数です。",
    tag="深層学習",
)

db = SessionLocal()
model17 = QuestionModel(
    question_text="以下の文章を読み、(ア)~(イ)の組み合わせとして、最も適切な選択肢を1つ選べニューラルネットワークの中では、予測誤差に関する情報を参考にして重みの更新を行っており、誤差に関する情報はネットワークの中で、(ア)していく。この仕組みに由来するネットワークの学習の問題は(イ)である。",
    correct_answer="",
    choices=[
        "a.(ア)出力層から入力層まで伝播、(イ)誤差消失問題",
        "b.(ア)入力層から出力層まで伝播、(イ)重み衝突問題",
        "c.(ア)出力層から入力層まで伝播、(イ)勾配消失問題",
        "c.(ア)入力層から出力層まで伝播、(イ)誤差消失問題",
    ],
    commentary="正解はcである。ニューラルネットワークにおける誤差逆伝播とは、出力側から入力側に向かって逆方向に誤差情報を伝播し、その順で隠れ層の重みが更新されることです。誤差逆伝播法によって勾配消失問題が引き起こされやすくなります。具体的には、ネットワークが深くなると、勾配(重みの更新に必要な情報)が正しくネットワークの上流に反映されなくなり、ニューラルネットワークの学習が停滞してしまいます。",
    tag="深層学習",
)

db = SessionLocal()
model18 = QuestionModel(
    question_text="ニューラルネットワークについて以下の文章を読み、(ア)～(ウ)に最も当てはまる組み合わせの選択肢を1つ選べ。入力層と出力層で構成される(ア)では線形分類しか行うことができないが、入力層と出力層の間に隠れ層を追加した(イ)を用いることで非線形分類を行うことができる。ただし、(イ)では、多くの隠れ層を追加することによって(ウ)が発生し、学習がうまくいかなくなることがある。",
    correct_answer="b.(ア)単純パーセプトロン、(イ)多層パーセプトロン、(ウ)勾配消失問題",
    choices=[
        "a.(ア)単純パーセプトロン、(イ)オートエンコーダ、(ウ)学習不足問題",
        "b.(ア)単純パーセプトロン、(イ)多層パーセプトロン、(ウ)勾配消失問題",
        "c.(ア)多層パーセプトロン、(イ)単純パーセプトロン、(ウ)学習不足問題",
        "d.(ア)オートエンコーダ、(イ)多層パーセプトロン、(ウ)勾配消失問題",
    ],
    commentary="入力層と出力層のみの単純パーセプトロンは、直線の数式で表すことができ、入力値と出力値に対応した境界線を引くことができます。そのため線形分類しか行うことができません。出力層と出力層の間に隠れ層を追加することで、非線形分類を行うことができます。入力層と出力層の間に隠れ層を追加したパーセプトロンを多層パーセプトロンと呼びます。多層パーセプトロンにおいて、隠れ層を増やすとより複雑な問題を分類することができます。しかし、隠れ層を単純に増やすだけでは、誤差がどんどん小さくなっていく勾配消失問題が発生し、学習がうまくいかなくなることがあります。",
    tag="深層学習",
)

db = SessionLocal()
model19 = QuestionModel(
    question_text="当初のニューラルネットワークにおける問題点として、最も適切な選択肢を2つ選べ。",
    correct_answer="a.隠れ層を増やすことにより、伝搬される誤差が発散もしくは消失し最後まで正しく反映されなくなってしまい、学習が困難になった。b.現実の問題を解決するには、大規模なネットワークとパラメータが必要であり、それらを処理する性能を要したハードウェアが必要となった。",
    choices=[
        "a.隠れ層を増やすことにより、伝搬される誤差が発散もしくは消失し最後まで正しく反映されなくなってしまい、学習が困難になった。",
        "b.現実の問題を解決するには、大規模なネットワークとパラメータが必要であり、それらを処理する性能を要したハードウェアが必要となった。",
        "c.知識のアップデート漏れや、過去の知識との整合性、例外的対応が必要な知識など、無数の可能性を考慮する必要があり、これ以上の発展が望めなくなった。",
        "d.非常に限定された状況で設定された問題しか解くことができず、より複雑な現実社会での問題を解くことが困難である。",
    ],
    commentary="ニューラルネットワークの隠れ層を増やすことによって、隠れ層を遡るごとに伝播していく誤差がどんどん小さくなり0に近づく勾配消失問題が発生します。また、隠れ層を増やすことにより計算コストが高くなるため、計算処理に優れた演算装置が必要となりました。c：エキスパートシステムの抱える問題の説明です。d：トイプロブレムの説明です。",
    tag="深層学習",
)

db = SessionLocal()
model20 = QuestionModel(
    question_text="ニューラルネットワークの問題点について以下の文章を読み、(ア)～(イ)に最も当てはまる組み合わせの選択肢を1つ選べ。ニューラルネットワークの隠れ層を増やすことで、より複雑な関数を表現することができる。しかし、層を増やすだけでは、(ア)で勾配が消失してしまう。そこで、ネットワーク全体で学習する前に、ネットワークを順番に学習する(イ)といった手法を用いることで、深層でも誤差が適切に逆伝播されるようになった。",
    correct_answer="d.(ア)誤差逆伝播法、(イ)事前学習",
    choices=[
        "a.(ア)正規化、(イ)転移学習",
        "b.(ア)正規化、(イ)事前学習",
        "c.(ア)誤差逆伝播法、(イ)転移学習",
        "d.(ア)誤差逆伝播法、(イ)事前学習",
    ],
    commentary="ニューラルネットワークにおいて、隠れ層を増やせば増やすだけ関数を組み合わせることになり、より複雑な関数を表現することができます。ニューラルネットワークでは、モデルの予測結果と実際の正解値との誤差をネットワークに逆向きにフィードバックさせる形でネットワークの重みを更新する誤差逆伝播法を用いますが、隠れ層を増やしすぎると誤差が最後まで正しく反映されなくなってしまいます。この問題を解決するために、事前学習といった手法が取り入れられました。",
    tag="深層学習",
)

db = SessionLocal()
model21 = QuestionModel(
    question_text="ディープニューラルネットワーク(DNN)の特徴として、最も適切な選択肢を1つ選べ。",
    correct_answer="a.DNNは、人間や動物の脳神経回路をモデルとしたアルゴリズムを多層構造化したもので、大規模で高次元なデータを処理することができる。",
    choices=[
        "a.DNNは、人間や動物の脳神経回路をモデルとしたアルゴリズムを多層構造化したもので、大規模で高次元なデータを処理することができる。",
        "b.DNNは大規模なデータを処理するため、他の機械学習の手法よりも優先的に使用される。",
        "c.DNNは層を深くすることで性能を高めることができるが、それに必要な計算量が増加し、それに耐えうるハードウェアを用意しなければならないのが唯一の問題である。",
        "d.ニューラルネットワークの隠れ層を増やすことにより発生する問題は、事前学習を行うことで解決することができる。",
    ],
    commentary="多層パーセプトロンを用いたニューラルネットワークにおいて、隠れ層が深いニューラルネットワークをディープニューラルネットワーク(DNN)と呼びます。DNNは人間や動物の脳神経回路をモデルとしたアルゴリズムを多層化構造化したもので、大規模なデータを処理することができます。DNNはハードウェアの問題だけでなく、勾配消失などといった問題点を抱えています。b：全ての問題においてDNNが優先的に使用されるわけではないため適切ではありません。c：計算量とハードウェアの問題以外にも勾配消失問題があるため適切ではありません。d：事前学習を用いる以外に活性化関数を工夫する手法があるため適切ではありません。",
    tag="深層学習",
)

db = SessionLocal()
model22 = QuestionModel(
    question_text="自己符号化器について以下の文章を読み、(ア)に最も良く当てはまる選択肢を1つ選べ。オートエンコーダを多層化すると、勾配消失問題が生じるため複雑な問題を解決することは困難であった。ジェフリー・ヒントンは、各層を単層のオートエンコーダに分割し、入力層から繰り返し学習する(ア)を提唱し、汎用的なオートエンコーダの利用を可能にした。",
    correct_answer="b.積層オートエンコーダ",
    choices=[
        "a.分散オートエンコーダ",
        "b.積層オートエンコーダ",
        "c.ファインチューニング",
        "d.転移学習",
    ],
    commentary="オートエンコーダを多層化したまま学習すると、勾配消失問題により学習がうまくできないことがあります。そこで、ジェフリー・ヒントンは事前学習という手法を用いた積層オートエンコーダを考案しました。積層オートエンコーダは、多層に積み重ねたオートエンコーダの全ての層を一気に学習するのではなく、事前学習により入力層に近い層から順番に1層ずつ逐次的に学習する手法をとります。これにより、各隠れ層の重みが調節され、全体的に見ても重みが調節されたネットワークを構築することができます。",
    tag="深層学習",
)

db = SessionLocal()
model23 = QuestionModel(
    question_text="オートエンコーダの説明として、最も適切な選択肢を1つ選べ。",
    correct_answer="a.可視層と隠れ層の2層からなり、入力層と出力層に同じデータを用いる。隠れ層には入力の情報が圧縮された情報が反映される。",
    choices=[
        "a.可視層と隠れ層の2層からなり、入力層と出力層に同じデータを用いる。隠れ層には入力の情報が圧縮された情報が反映される。",
        "b.畳み込み層とプーリング層を複数組み合わせて深いネットワークを形成し、最終的に入力層と出力層をつなぎ合わせる手法である。",
        "c.時間軸方向にネットワークを展開し、再帰構造により現在の出力データを次のネットワークの入力データに使用しながら学習する。",
        "d.オートエンコーダで教師あり学習ができ、出力層から正解ラベルを得ることができる。",
    ],
    commentary="オートエンコーダは、入力層と出力層からなる可視層と、隠れ層の2層からなるニューラルネットワークです。入力層と出力層に同じデータを用いることで、隠れ層には入力の情報が圧縮された情報が反映されます。b：CNNの説明です。c：RNNの説明です。d：オートエンコーダは出力が入力そのものになるため、入力から特徴を抽出することしかできません。",
    tag="深層学習",
)

db = SessionLocal()
model24 = QuestionModel(
    question_text="ニューラルネットワークについて以下の文章を読み、(ア)～(イ)に最も当てはまる組み合わせの選択肢を1つ選べ。積層オートエンコーダに(ア)を追加すれば回帰を行うニューラルネットワークになり、(イ)を追加すれば分類を行うニューラルネットワークとなる。",
    correct_answer="a.(ア)線形回帰層、(イ)ロジスティック回帰層",
    choices=[
        "a.(ア)線形回帰層、(イ)ロジスティック回帰層",
        "b.(ア)線形回帰層、(イ)平滑化層",
        "c.(ア)ロジスティック回帰層、(イ)線形回帰層",
        "d.(ア)平滑化層、(イ)線形回帰層",
    ],
    commentary="オートエンコーダを多層に積み重ねただけでは、教師あり学習を実現することができません。そこで積層オートエンコーダにオートエンコーダを積み重ねた最後に、線形回帰層やロジスティック回帰層を足すことで、教師あり学習を実現しています。",
    tag="深層学習",
)

db = SessionLocal()
model25 = QuestionModel(
    question_text="以下の文章を読み、(ア)に最も良く当てはまる組み合わせの選択肢を1つ選べ。オートエンコーダを積み重ねるだけでは特徴を抽出することができない教師なし学習であるため、ロジスティック回帰層または線形回帰層を足し、最後にネットワーク全体で学習を行い教師あり学習を実現する。この工程を(ア)という。",
    correct_answer="c.ファインチューニング",
    choices=[
        "a.事前学習",
        "b.バックプロパゲーション",
        "c.ファインチューニング",
        "d.次元削減",
    ],
    commentary="オートエンコーダを積み重ねた積層オートエンコーダを用いることで、各層の重みを調整することができる事前学習を実現できます。しかし、それだけではラベルを出力することができないので教師なし学習となり、教師あり学習を実現することはできません。そこで重みの調整を終えた最後にロジスティック回帰層または線形回帰層を追加して学習することで、教師あり学習を実現することができます。この手法をファインチューニングと呼び、積層オートエンコーダは事前学習とファインチューニングの工程で構築されます。",
    tag="深層学習",
)

db = SessionLocal()
model26 = QuestionModel(
    question_text="制限付きボルツマンマシンを積み重ねた手法として、最も適切な選択肢を1つ選べ。",
    correct_answer="a.深層信念ネットワーク",
    choices=[
        "a.深層信念ネットワーク",
        "b.共起ネットワーク",
        "c.トランスフォーマー",
        "d.敵対的生成ネットワーク",
    ],
    commentary="深層信念ネットワークは、ジェフリー・ヒントンが積層オートエンコーダと同年に提唱した手法です。制限付きボルツマンマシンは、可視層と隠れ層の2層からなり、可視層と隠れ層にはそれぞれノードと呼ばれるユニットが存在します。ユニット同士は違う層のノードとのみ接続することができるという制限があります。層同士の関係を確率モデルとして表すことができ、入力データを再現することができます。",
    tag="深層学習",
)

db = SessionLocal()
model27 = QuestionModel(
    question_text="GPUについて以下の文章を読み、(ア)～(ウ)に最も当てはまる組み合わせの選択肢を1つ選べ。GPUは映像や3DCGなどの同一画面に同じ演算を一挙に行う、大規模な(ア)を行うことができる。画面処理以外にも、テンソルによる計算が主になるディープラーニングの計算に最適化されたGPUのことを(イ)と呼ぶ。ディープラーニング実装用のライブラリのほぼ全てが(ウ)社製のGPU上での計算をサポートしている。",
    correct_answer="c.(ア)並列演算処理、(イ)GPGPU、(ウ)NVIDIA",
    choices=[
        "a.(ア)直列演算処理、(イ)GPGPU、(ウ)NVIDIA",
        "b.(ア)直列演算処理、(イ)DLGPU、(ウ)Google",
        "c.(ア)並列演算処理、(イ)GPGPU、(ウ)NVIDIA",
        "d.(ア)並列演算処理、(イ)DLGPU、(ウ)Google",
    ],
    commentary="GPUは画像処理に関する処理を行います。映像3DCGなどを処理する場合は、同一画像に同じ演算を一挙に行います。そのため大規模な平行演算処理が必要となります。そこで、大規模な平行演算処理に特化したGPUが生み出されました。ディープラーニングでは、行列計算やベクトルの計算(テンソル)が主になり、同じような計算処理が大規模に行われます。そのためGPUが最適ですが、元のGPUは画像処理に最適化されています。そこで画像処理以外の目的での使用に最適化されたGPUであるGPGPUが生み出されました。そのGPGPUの開発をリードしているのはNVIDIA社で、ディープラーニング実装用のライブラリのほぼ全てがNVIDIA社製のGPU上での計算をサポートしています。",
    tag="深層学習",
)

db = SessionLocal()
model28 = QuestionModel(
    question_text="Google社が開発した演算処理装置として、最も適切な選択肢を1つ選べ。",
    correct_answer="d.TPU",
    choices=[
        "a.VPU",
        "b.CUDA",
        "c.cuDNN",
        "d.TPU",
    ],
    commentary="TPUはTensor Processing Unitの略で、Google社が開発したテンソル計算処理に最適化された演算処理装置です。a：Intel社が提供する視覚情報の取得および解析向けに設計された演算処理装置です。b：NVIDIA社が提供する並列演算を行う開発環境です。c：NVIDIA社が提供するディープラーニング用のライブラリです。",
    tag="深層学習",
)

db = SessionLocal()
model29 = QuestionModel(
    question_text="GPUとCPUについて以下の文章を読み、(ア)～(イ)に最も当てはまる当てはまる組み合わせの選択肢を1つ選べ。ディープラーニングを利用する上で、GPUは重要な計算資源である。GPUは、CPUと比較した時、(ア)という点で優れており、ディープラーニングのように幾度とないループ処理を高速に行うことに優れている。一方のCPUは、(イ)という点で優れている。",
    correct_answer="b.(ア)同じ演算を一挙に行う、(イ)様々な種類のタスクを順番に処理する",
    choices=[
        "a.(ア)同じ演算を一挙に行う、(イ)耐久性が高い",
        "b.(ア)同じ演算を一挙に行う、(イ)様々な種類のタスクを順番に処理する",
        "c.(ア)様々な種類のタスクを順番に処理する、(イ)同じ演算を一挙に行う",
        "d.(ア)可用性が高い、(イ)様々な種類のタスクを順番に処理する",
    ],
    commentary="コンピュータにはCPUとGPUの2つの演算処理装置があり、両者は異なる役割を担っています。GPUは画像処理などの演算を行う役割を担っています。大規模な並列演算処理を行う点で優れています。一方のCPUはコンピュータの作業を処理する役割を担っており、様々な種類のタスクを順番に処理する点で優れています。",
    tag="深層学習",
)

db = SessionLocal()
model30 = QuestionModel(
    question_text="GPUの説明として最も適切でない選択肢を1つ選べ。",
    correct_answer="c.GPUは大規模なテンソル演算を行うことに特化しているのに対し、GPGPUは画像処理に関する計算を効率的に行うことに特化している。",
    choices=[
        "a.2012年に、GPUで学習したディープニューラルネットワークであるAlexNetが、イメージネット画像認識コンテストで優勝した。",
        "b.ディープラーニングでは大規模な行列の積和演算が行われるため、内積計算を並行して行うことができるGPUがディープラーニングの発展に大きく貢献している。",
        "c.GPUは大規模なテンソル演算を行うことに特化しているのに対し、GPGPUは画像処理に関する計算を効率的に行うことに特化している。",
        "d.第3次AIブームとしてディープラーニングが急速な盛り上がりを見せたのは、GPUの性能が向上したことが要因の1つとしてあげられる。",
    ],
    commentary="GPUは画像処理などの演算を行う役割を担っています。大規模な並列演算処理を行う点で優れています。ディープラーニングでは、行列計算やベクトルの計算(テンソル)が主になり、大規模な平行演算処理が必要となります。そこで画像処理以外に使用し、ディープラーニングの計算に特化したGPGPUが開発されました。第3次AIブームにおいて大規模な行列計算で行うことができるGPGPUの演算処理の向上がディープラーニングの急速な盛り上がりを支えました。",
    tag="深層学習",
)

db = SessionLocal()
model31 = QuestionModel(
    question_text="ディープラーニングのデータ量の説明として、最も適切でない選択肢を1つ選べ。",
    correct_answer="b.データ量の目安となる経験則が存在し、モデルのパラメータ数の100倍のデータ量が必要となるとされている。",
    choices=[
        "a.モデルに対して必要なデータ量は明確には決まっておらず、モデルが複雑になればなるほど必要なデータ量は増えてく。",
        "b.データ量の目安となる経験則が存在し、モデルのパラメータ数の100倍のデータ量が必要となるとされている。",
        "c.データの次元が増えることにより、そのデータで表現できる組み合わせが多くなってしまい、学習に必要なサンプル数が急増してしまう。",
        "d.畳み込みニューラルネットワークの手法の1つであるAlexNetの学習に必要なサンプル数は約600,000,000個であり、膨大なデータ量が必要になることから少ないデータ数でいかに高い精度を出すかという工夫が多数考案されている。",
    ],
    commentary="ディープラーニングの学習の目的は、モデルが持つパラメータを最適化することです。そのため、ディープニューラルネットワークでは、ネットワークが深くなればなるほど、その最適化すべきパラメータ数も増えるので、必要な計算量も増加します。データ量の目安となる経験則が存在し、「バーニーおじさんのルール」という経験則によると、モデルのパラメータ数の10倍のデータ数が必要であるとされています。この経験則によると、AlexNetと呼ばれるモデルのパラメータ数は60,000,000個であるため、必要なデータ数は600,000,000個となります。",
    tag="深層学習",
)

db = SessionLocal()
model32 = QuestionModel(
    question_text="検証データに与えるデータリーケージの影響として、最も適切な選択肢を1つ選べ。",
    correct_answer="a.推論時に検証時よりも大きく精度が落ちる",
    choices=[
        "a.推論時に検証時よりも大きく精度が落ちる",
        "b.学習が継続できなくなる",
        "c.学習に大幅に時間がかかるようになる",
        "d.過学習を引き起こす",
    ],
    commentary="データリーケージは学習時、検証時に未確定の情報が含まれてしまうことを言います。推論時に未確定情報を使用することができないため、推論時のみ精度が落ちてしまいます。",
    tag="深層学習",
)

db = SessionLocal()
model33 = QuestionModel(
    question_text="以下の文章を読み、(ア)に最もよく当てはまる選択肢を1つ選べ。全結合ニューラルネットワークにおける隠れ層の活性化関数として、ReLU関数が主流となっている。ReLU関数はシグモイド関数と比べて(ア)が起きにくい。",
    correct_answer="a.勾配消失問題",
    choices=[
        "a.勾配消失問題",
        "b.ブラックボックス問題",
        "c.ノイズ",
        "d.転移学習",
    ],
    commentary="シグモイド関数は微分の最大値が小さいため、誤差逆伝播法で何層も遡る過程で誤差がほとんど失われてしまうことがあります。これを勾配消失問題といいます。ReLU関数は入力値が正の値であれば微分値は常に1であるため、勾配消失問題が比較的起きにくいです。",
    tag="深層学習",
)

db = SessionLocal()
model34 = QuestionModel(
    question_text="ニューラルネットワークの出力層において、一般に回帰問題で用いられる活性化関数として、最も適切な選択肢を1つ選べ。",
    correct_answer="a.恒等関数",
    choices=[
        "a.恒等関数",
        "b.シグモイド関数",
        "c.ソフトマックス関数",
        "d.ReLU関数",
    ],
    commentary="回帰問題の出力層では、受け取った値を変換せずにそのまま出力すればよいため、恒等関数が用いられます。",
    tag="深層学習",
)

db = SessionLocal()
model35 = QuestionModel(
    question_text="ニューラルネットワークの出力層において、一般に2値分類問題で用いられる活性化関数として、最も適切な選択肢を1つ選べ。",
    correct_answer="b.シグモイド関数",
    choices=[
        "a.恒等関数",
        "b.シグモイド関数",
        "c.ソフトマックス関数",
        "d.ReLU関数",
    ],
    commentary="シグモイド関数で出力の値を0～1の範囲に押し込め、0.5以上か0.5未満か判定することで2値分類を行うことができます。",
    tag="深層学習",
)

db = SessionLocal()
model36 = QuestionModel(
    question_text="ニューラルネットワークの出力層において、一般に多クラス分類問題で用いられる活性化関数として、最も適切な選択肢を1つ選べ。",
    correct_answer="c.ソフトマックス関数",
    choices=[
        "a.恒等関数",
        "b.シグモイド関数",
        "c.ソフトマックス関数",
        "d.ReLU関数",
    ],
    commentary="ソフトマックス関数を用いて、出力層の各ユニットの出力値の合計が1になるように調整することで、各クラスの確率を表現することができます。",
    tag="深層学習",
)

db = SessionLocal()
model37 = QuestionModel(
    question_text="ディープラーニングにおけるハイパーパラメータとして、最も適切でない選択肢を1つ選べ。",
    correct_answer="b.重み",
    choices=[
        "a.学習率",
        "b.重み",
        "c.バッチサイズ",
        "d.隠れ層ユニット数",
    ],
    commentary="人間が調整しなければならないパラメータをハイパーパラメータといいます。重みやバイアスは、大量のデータによる学習によって自動で調整されるため、ハイパーパラメータには該当しません。",
    tag="深層学習",
)

db = SessionLocal()
model38 = QuestionModel(
    question_text="ハイパーパラメータのすべての組み合わせを試す手法として、最も適切な選択肢を1つ選べ。",
    correct_answer="d.グリッドサーチ",
    choices=[
        "a.ランダムサーチ",
        "b.ミニバッチ学習",
        "c.ベイズ最適化",
        "d.グリッドサーチ",
    ],
    commentary="グリッドサーチとは格子状の空間でパラメータを探索する手法であり、パラメータのすべての組み合わせを試行しているとみなすことができます。",
    tag="深層学習",
)

db = SessionLocal()
model39 = QuestionModel(
    question_text="以下の文章を読み、(ア)～(イ)に当てはまる組み合わせの選択肢を1つ選べ。ニューラルネットワークにおける最適化では、いくつかの問題が考えられる。たとえば、ある限られた区間において誤差が最小となる(ア)に捕らわれ、真の解である(イ)にたどりつけない場合が考えられる。",
    correct_answer="a.(ア)局所最適解、(イ)大域最適解",
    choices=[
        "a.(ア)局所最適解、(イ)大域最適解",
        "b.(ア)一時解、(イ)局所最適解",
        "c.(ア)局所最適解、(イ)決定解",
        "d.(ア)大域最適解、(イ)局所最適解",
    ],
    commentary="限られた区間における最小値は局所最適解であり、真の解とは大域最適解です。",
    tag="深層学習",
)

db = SessionLocal()
model40 = QuestionModel(
    question_text="ニューラルネットワークの最適化について以下の文章を読み、(ア)に最もよく当てはまる選択肢を1つ選べ。パラメータ空間においてある次元から見た場合は極小値であるが、別の次元から見た場合は極大値となる(ア)という問題がある。(ア)の周辺では勾配がほとんどなくなり、学習が停滞するプラトーと呼ばれる状態に陥りやすい。",
    correct_answer="d.鞍点",
    choices=[
        "a.モーメンタム",
        "b.盆点",
        "c.一時解",
        "d.鞍点",
    ],
    commentary="ある次元から見た場合は極小値であるが、別の次元から見た場合は極大値となる点を鞍点と呼びます。",
    tag="深層学習",
)

db = SessionLocal()
model41 = QuestionModel(
    question_text="以下の文章を読み(ア)に最もよく当てはまる選択肢を1つ選べ。ディープラーニングでは勾配降下法を用いて最適化する。勾配降下法は、誤差関数の(ア)にもとづいてパラメータを調整する手法である。まず基本的な方法として、(ア)の値に学習率を掛けた値を用いてパラメータを更新する。",
    correct_answer="b.偏微分",
    choices=[
        "a.二乗",
        "b.偏微分",
        "c.積分",
        "d.平方根",
    ],
    commentary="勾配降下法では目的関数(誤差関数)の偏微分によって、パラメータの値をどの程度増減するか決定します。",
    tag="深層学習",
)

db = SessionLocal()
model42 = QuestionModel(
    question_text="勾配降下法の中でもランダムに選択したデータを用いてパラメータを更新する手法として、最も適切な選択肢を1つ選べ。",
    correct_answer="c.SGD",
    choices=[
        "a.AdaGrad",
        "b.RMSprop",
        "c.SGD",
        "d.モーメンタム",
    ],
    commentary="ランダムに選んだデータから求めた勾配でパラメータを更新する手法を確率的勾配降下法(SGD)といいます。一方、全てのデータの誤差の合計から求めた勾配で更新する場合は、最急降下法といいます。",
    tag="深層学習",
)

db = SessionLocal()
model43 = QuestionModel(
    question_text="勾配降下法の中でも前回の更新量を慣性として利用する手法として、最も適切な選択肢を1つ選べ。",
    correct_answer="d.モーメンタム",
    choices=[
        "a.AdaGrad",
        "b.RMSprop",
        "c.SGD",
        "d.モーメンタム",
    ],
    commentary="モーメンタムは前回の更新量を慣性として利用します。パラメータ空間において、谷間での振動を抑制し、平坦な地点でも学習の収束を早める効果があります。",
    tag="深層学習",
)

db = SessionLocal()
model44 = QuestionModel(
    question_text="AdaGradの改良版で、より最近のパラメータ更新を重視して学習率を調整する勾配降下法のアルゴリズムとして、最も適切な選択肢を1つ選べ。",
    correct_answer="b.RMSprop",
    choices=[
        "a.Adam",
        "b.RMSprop",
        "c.SGD",
        "d.AdaGrad",
    ],
    commentary="AdaGradはこれまで大きく更新されたパラメータほど学習率が低くなるように設定するアルゴリズムですが、RMSpropではより最近のパラメータに対して更新の影響が大きくなります。",
    tag="深層学習",
)

db = SessionLocal()
model45 = QuestionModel(
    question_text="学習率の上限と加減を学習回数に応じて徐々に狭めることで、より速い学習の収束を実現したアルゴリズムとして、最も適切な選択肢を1つ選べ。",
    correct_answer="d.AdaBound",
    choices=[
        "a.Adam",
        "b.勾配クリッピング",
        "c.AdaDelta",
        "d.AdaBound",
    ],
    commentary="RMSpropとモーメンタムの考えと取り入れたAdamは、学習後半の収束のしづらさが課題でした。そのAdamを更に改良した手法としてAdaBoundが考案されました。AdaBoundは、学習率の上限と加減を学習回数に応じて徐々に狭めることでより速い学習の収束を実現しました。同様の考えで学習の収束をさせるアルゴリズムとしてAMSBoundもあります。",
    tag="深層学習",
)

db = SessionLocal()
model46 = QuestionModel(
    question_text="活性化関数にReLU関数を用いているニューラルネットワークに有効とされる重みの初期値として、最も適切な選択肢を1つ選べ。",
    correct_answer="c.Heの初期値",
    choices=[
        "a.Xavierの初期値",
        "b.Hintonの初期値",
        "c.Heの初期値",
        "d.Goodfellowの初期値",
    ],
    commentary="活性化関数としてReLU関数を用いる場合は、重みにHeの初期値を設定するのが効果的です。対して、活性化関数としてシグモイド関数やtanh関数を用いる場合は、重みにXavierの初期値を設定すると効果的です。",
    tag="深層学習",
)

db = SessionLocal()
model47 = QuestionModel(
    question_text="以下の文章を読み、(ア)～(ウ)に当てはまる組み合わせの選択肢を1つ選べ。機械学習では入力データの値の範囲を揃える(ア)を行うことで学習が上手く進む場合がある。なかでも、データの分布の(イ)が0、(ウ)が1になるように変換する標準化がよく使用される。",
    correct_answer="b.(ア)正規化、(イ)平均、(ウ)分散",
    choices=[
        "a.(ア)正規化、(イ)最小値、(ウ)最大値",
        "b.(ア)正規化、(イ)平均、(ウ)分散",
        "c.(ア)汎化、(イ)平均、(ウ)分散",
        "d.(ア)汎化、(イ)分散、(ウ)平均",
    ],
    commentary="入力データの範囲を揃える処理を正規化といいます。標準化は入力データを標準正規分布に則って平均は0、分散は1に変換します。なお、標準化の他に入力データが0から1の範囲に収まるように変換することも多いです。",
    tag="深層学習",
)

db = SessionLocal()
model48 = QuestionModel(
    question_text="以下の文章を読み、(ア)～(イ)に当てはまる組み合わせの選択肢を1つ選べ。過学習とは学習を進めた結果、(ア)は小さくなったが(イ)が大きくなってしまった状態を指す。",
    correct_answer="d.(ア)訓練誤差、(イ)汎化誤差",
    choices=[
        "a.(ア)勾配、(イ)汎化誤差",
        "b.(ア)汎化誤差、(イ)訓練誤差",
        "c.(ア)訓練誤差、(イ)学習率",
        "d.(ア)訓練誤差、(イ)汎化誤差",
    ],
    commentary="訓練データに対する誤差を訓練誤差と呼びます。過学習が起きている状態では、訓練誤差は十分に小さくなっているといえます。一方で、母集団に対する誤差のことを汎化誤差と呼びます。(実際的にはテストデータに対する誤差を用います)。過学習とは訓練データに過剰に適合してしまい、母集団に対する適合度が低くなってしまっている状態を指します。",
    tag="深層学習",
)

db = SessionLocal()
model49 = QuestionModel(
    question_text="ニューラルネットワークの過学習対策として、最も適切でない選択肢を1つ選べ。",
    correct_answer="d.学習率を下げる",
    choices=[
        "a.ドロップアウト",
        "b.正則化",
        "c.バッチ正規化",
        "d.学習率を下げる",
    ],
    commentary="ドロップアウトはニューラルネットワークの一部のノードを無視しながら学習を行う手法で、過学習を抑える効果があります。正則化は、極端なパラメータにペナルティを与える手法で、過学習を抑える効果があります。バッチ正規化は、ミニバッチ単位で隠れ層ごとに正規化を行う手法で、過学習を抑える効果があります。",
    tag="深層学習",
)

db = SessionLocal()
model50 = QuestionModel(
    question_text="以下の文章を読み、(ア)に最もよく当てはまる選択肢を1つ選べ。ドロップアウトは毎回ネットワークの経路が異なるので、(ア)を行っているとみなすことができる。",
    correct_answer="a.アンサンブル学習",
    choices=[
        "a.アンサンブル学習",
        "b.蒸留",
        "c.Encoder-Decoder",
        "d.転移学習",
    ],
    commentary="ドロップアウトは、ニューラルネットワークを構成するユニットを一定の確率でランダムで無効にしながら学習を進める手法です。毎回ネットワークの経路が異なるということは、複数の学習器で多数決をとるアンサンブル学習を行っているとみなすことができます。",
    tag="深層学習",
)

db = SessionLocal()
model51 = QuestionModel(
    question_text="ドロップアウトを用いる際に設定するドロップアウト率として、最も適切な選択肢を1つ選べ。",
    correct_answer="a.ハイパーパラメータとして設定する",
    choices=[
        "a.ハイパーパラメータとして設定する",
        "b.学習で調整されるパラメータである",
        "c.どのように設定しても結果はほとんど変わらない",
        "d.一般的に1%以下のきわめて小さな値を設定する",
    ],
    commentary="ドロップアウト率(無効にするユニットの確率)は、ハイパーパラメータとして分析者が設定します。一般的に50%程度とされることが多いです。",
    tag="深層学習",
)

db = SessionLocal()
model52 = QuestionModel(
    question_text="過学習に陥る前に学習を打ち切る手法として、最も適切な選択肢を1つ選べ。",
    correct_answer="a.early stopping(早期終了)",
    choices=[
        "a.early stopping(早期終了)",
        "b.Intermediate learning(中間学習)",
        "c.pre training(事前学習)",
        "d.checkpoint(チェックポイント)",
    ],
    commentary="過学習に陥る前に学習を打ち切る手法はearly stopping(早期終了)です。チェックポイントを利用してearly stoppingを実装することがありますが、学習を打ち切る手法そのものの名前ではありません。",
    tag="深層学習",
)

db = SessionLocal()
model53 = QuestionModel(
    question_text="以下の文章を読み、(ア)～(ウ)に当てはまる組み合わせの選択肢を1つ選べ。過学習を抑える手法のひとつに正則化がある。(ア)は不要な入力に対する重みが0になるようにはたらく。(イ)は重みが大きくなりすぎないようにすることで滑らかなモデルをつくる。(ア)と(イ)を組み合わせて特に線形回帰に適合した場合に(ウ)という。",
    correct_answer="",
    choices=[
        "a.(ア)L0正則化、(イ)L1正則化、(ウ)Ridge Net",
        "b.(ア)L1正則化、(イ)L2正則化、(ウ)Ridge Net",
        "c.(ア)L1正則化、(イ)L2正則化、(ウ)Elastic Net",
        "d.(ア)L2正則化、(イ)L1正則化、(ウ)Elastic Net",
    ],
    commentary="L1正則化は重みができるだけ0になるようにしてスパース(疎)なモデルをつくります。L2正則化は重みが大きくなりすぎないようにすることで、モデルの複雑さが低減され過学習が抑えられます。L1正則化を適用した線形回帰をLASSO回帰、L2正則化を適用した線形回帰をRidge回帰と呼びます。L1正則化とL2正則化を組み合わせた手法をElastic Netといいます。",
    tag="深層学習",
)

db = SessionLocal()
model54 = QuestionModel(
    question_text="勾配消失問題が起こりやすいニューラルネットワークの特徴として、最も適切な選択肢を1つ選べ。",
    correct_answer="b.層が深い",
    choices=[
        "a.一つの隠れ層あたりのユニット数が多い",
        "b.層が深い",
        "c.活性化関数としてReLU関数を用いている",
        "d.入力データの次元が小さい",
    ],
    commentary="ニューラルネットワークでは、入力層に近づくほど誤差が小さくなる傾向があるため、層が深いネットワークでは勾配消失問題が起きやすくなります。活性化関数としてReLU関数を用いることで、勾配消失を低減することができます。その他の選択肢は、勾配消失問題と直接の関係はありません。",
    tag="深層学習",
)

db = SessionLocal()
model55 = QuestionModel(
    question_text="学習時のデータの渡し方の中で、データを1件ずつ渡してその都度パラメータを更新する学習方法として、最も適切な選択肢を1つ選べ。",
    correct_answer="b.オンライン学習",
    choices=[
        "a.ファインチューニング",
        "b.オンライン学習",
        "c.ミニバッチ学習",
        "d.バッチ学習",
    ],
    commentary="データを1件ずつ渡してその都度パラメータを更新する学習方法はオンライン学習です。バッチ学習はデータ全体をモデルに渡して一括でパラメータを更新する学習方法、ミニバッチ学習は分割したデータのかたまりごとにパラメータを更新する学習方法です。ファインチューニングは、積層オートエンコーダにおいてネットワーク全体のパラメータを教師あり学習で更新する工程のことです。",
    tag="深層学習",
)

db = SessionLocal()
model56 = QuestionModel(
    question_text="以下の文章を読み、(ア)～(イ)に当てはまる組み合わせの選択肢を1つ選べ。ミニバッチ学習では、訓練データを(ア)ごとに分割して学習する。(ア)が決まると、訓練データ全体を学習に使うのに必要な(イ)数が決まる。(イ)を1周して学習したとき、訓練データ全体を使った1回の学習を終えたことになる。",
    correct_answer="a.(ア)バッチサイズ、(イ)イテレーション",
    choices=[
        "a.(ア)バッチサイズ、(イ)イテレーション",
        "b.(ア)バッチサイズ、(イ)エポック",
        "c.(ア)イテレーション、(イ)バッチサイズ",
        "d.(ア)エポック、(イ)イテレーション",
    ],
    commentary="ミニバッチ学習では訓練データ全体から、一部のデータを決まった数だけ取り出して学習しパラメータを更新します。このとき、取り出すデータの数をバッチサイズといいます。バッチサイズが決定すると、訓練データ全体を学習に使うのに必要なイテレーション数が決定します。なお、訓練データ全体を1周分使って学習すると、1エポック学習したということになります。",
    tag="深層学習",
)

db = SessionLocal()
model57 = QuestionModel(
    question_text="あるタスクのために訓練された学習済みモデルを別のタスクに適用する手法をなんというか？",
    correct_answer="a.転移学習",
    choices=[
        "a.転移学習",
        "b.回帰結合型ニューラルネットワーク",
        "c.教師なし学習",
        "d.オートエンコーダ",
    ],
    commentary="あるタスクのために訓練した学習済みモデルを、別のタスクに適用する手法を転移学習といいます。",
    tag="深層学習",
)

db = SessionLocal()
model58 = QuestionModel(
    question_text="以下の文章を読み、(ア)に最もよく当てはまる選択肢を1つ選べ。学習済みモデル(教師モデル)に入力したデータと、それにより出力されたデータを訓練データとして、新しいモデル(生徒モデル)を訓練する手法を(ア)という。",
    correct_answer="c.蒸留",
    choices=[
        "a.凝結",
        "b.重複学習",
        "c.蒸留",
        "d.ファインチューニング",
    ],
    commentary="蒸留は学習済みモデルの入力と出力を使って新たなモデルを学習する手法です。蒸留では学習済みモデルを教師モデル、新しいモデルを生徒モデルと呼びます。生徒モデルの構造をシンプルにすることで、計算リソースを削減することができます。",
    tag="深層学習",
)

db = SessionLocal()
model59 = QuestionModel(
    question_text="学習済みモデルを基に新たなモデルを訓練する蒸留を用いることで、予測精度を保ったままよりシンプルで軽量なモデルを作成できる。シンプルなモデルでも精度を保つことができる理由として、最も適切な選択肢を1つ選べ。",
    correct_answer="a.新たなモデルがクラス間の類似度も学習するから",
    choices=[
        "a.新たなモデルがクラス間の類似度も学習するから",
        "b.新たなモデルが性能のよいアルゴリズムを持つから",
        "c.新たなモデルが最適化された重みの初期値を持つから",
        "d.新たなモデルが長い時間訓練されるから",
    ],
    commentary="学習済みモデル(教師モデル)から生成したラベルには、それぞれのクラスである確率が出力されているため、新たなモデル(生徒モデル)はクラス間の類似度も学習することができるといわれています。",
    tag="深層学習",
)

db = SessionLocal()
model60 = QuestionModel(
    question_text="データを無相関化したのちに標準化することをなんというか選択肢から選べ。",
    correct_answer="d.白色化",
    choices=[
        "a.ノーマライゼーション",
        "b.正規化",
        "c.ドロップアウト",
        "d.白色化",
    ],
    commentary="白色化はデータを無相関化してから標準化することを言います。白色化を行うことによってより効果的な学習が期待できます。",
    tag="深層学習",
)

db = SessionLocal()
model61 = QuestionModel(
    question_text="モデルの圧縮の手法として最も適切でない選択肢を1つ選べ。",
    correct_answer="c.early stopping",
    choices=[
        "a.蒸留",
        "b.プルーニング",
        "c.early stopping",
        "d.量子化",
    ],
    commentary="early stoppingは過学習する前に学習を終了する手法です。モデル圧縮は基本的に学習後のモデルの軽量化が目的ですので、適切ではありません。",
    tag="深層学習",
)

db = SessionLocal()
model62 = QuestionModel(
    question_text="以下の文章を読み、(ア)～(イ)に当てはまる組み合わせの選択を1つ選べ。画像認識でよく使われるCNNは、畳み込み層と(ア)を持つニューラルネットワークである。畳み込み層ではフィルタによる処理を行い、画像の特徴を抽出した(イ)を得る。(ア)では、畳み込み層で得た(イ)を縮小することで、対象物の位置のズレに対し頑健にすることができる。",
    correct_answer="d.(ア)プーリング層、(イ)特徴マップ",
    choices=[
        "a.(ア)チューニング層、(イ)ヒートマップ",
        "b.(ア)チューニング層、(イ)特徴マップ",
        "c.(ア)プーリング層、(イ)ヒートマップ",
        "d.(ア)プーリング層、(イ)特徴マップ",
    ],
    commentary="CNNは、画像から特徴を抽出する畳み込み層と特徴を残しつつ画像を縮小するプーリング層の2種類で構成されます。畳み込み処理によって得た新たな二次元データを特徴マップといいます。プーリング層で特徴マップを縮小することで、次元削減や移動不変性の獲得に貢献します。",
    tag="深層学習",
)

db = SessionLocal()
model63 = QuestionModel(
    question_text="CNNの畳み込み層において、フィルタを適用する前に入力データの周囲を0などで埋めてサイズを広げる処理として、最も適切な選択肢を1つ選べ。",
    correct_answer="b.パディング",
    choices=[
        "a.マージ",
        "b.パディング",
        "c.エクステンション",
        "d.ストライド",
    ],
    commentary="CNNの畳み込み層では、入力データにフィルタ(カーネル)を重ね積和計算を行います。畳み込み処理における入力データの周囲を0などで埋めることをパディングといいます。パディングにより畳み込み後の特徴マップのサイズを調整できるほか、画像の端の特徴を抽出しやすくなるというメリットがあります。なお、ストライドはフィルタをずらす幅のことです。",
    tag="深層学習",
)

db = SessionLocal()
model64 = QuestionModel(
    question_text="GoogleNetに関する説明として、最も不適切な選択肢を1つ選べ。",
    correct_answer="c.福島邦彦が開発したモデルである",
    choices=[
        "a.Inceptionモジュールにより畳み込み層を並列に構成する",
        "b.Inception-v2やInception-ResNetといった改良版が提案されている",
        "c.福島邦彦が開発したモデルである",
        "d.Global Average Poolingが過学習の抑制に寄与している",
    ],
    commentary="福島邦彦は、CNNの前身のモデルであるネオコグニトロンを提唱した人であり、GoogleNetが開発した人物ではありません。GoogleNetが採用している特徴的な仕組みとして、Inceptionモジュール、Global Average Pooling(GAP)、Auxiliary Lossが挙げられます。",
    tag="深層学習",
)

db = SessionLocal()
model65 = QuestionModel(
    question_text="以下の文章を読み、(ア)に最もよく当てはまる選択肢を1つ選べ。ResNetは、畳み込み層と(ア)を組み合わせた残差ブロックを導入したことで、飛躍的に層の深いネットワークを構築することができるようになった。",
    correct_answer="a.shortcut connection",
    choices=[
        "a.shortcut connection",
        "b.Inceptionモジュール",
        "c.Attention",
        "d.再帰構造",
    ],
    commentary="残差ブロックにおいて、shorcut connectionは畳み込み層をまたいで入力の値をそのまま伝えます。ResNetでは残差を学習することで、層が深いネットワークでも効率よく学習を進めることができます。なお、層を深くした分だけ学習にかかる時間は長くなります。",
    tag="深層学習",
)

db = SessionLocal()
model66 = QuestionModel(
    question_text="CNNの前身となったモデルで、人間の視覚の2つの神経細胞に注目したモデルをなんというか。",
    correct_answer="c.ネオコグニトロン",
    choices=[
        "a.DenseNet",
        "b.VisionAI",
        "c.ネオコグニトロン",
        "d.ロバスト",
    ],
    commentary="ネオコグニトロンは人間の視覚を司る2つの神経細胞、S細胞とC細胞に注目したモデルです。",
    tag="深層学習",
)

db = SessionLocal()
model67 = QuestionModel(
    question_text="データ拡張の方法として不適切なものを選択肢から選べ。",
    correct_answer="d.量子化",
    choices=[
        "a.Cutout",
        "b.回転",
        "c.移動",
        "d.量子化",
    ],
    commentary="量子化はAIの文脈ではモデル圧縮の手法を指すことが多く、データ拡張の手法ではないので不適切です。移動や回転は画像を平行移動させたり、中心点を軸に回転させたりすることで、データを増やす手法です。",
    tag="深層学習",
)

db = SessionLocal()
model68 = QuestionModel(
    question_text="CNNを発展させたモデルとして不適切なものを選択肢から選べ。",
    correct_answer="a.LeNet",
    choices=[
        "a.LeNet",
        "b.MobileNet",
        "c.NasNet",
        "d.EfficientNet",
    ],
    commentary="LeNetはCNNの前身となったモデルです。",
    tag="深層学習",
)

db = SessionLocal()
model69 = QuestionModel(
    question_text="画像の物体ごとにのみクラス分類を行うセグメンテーションの手法として適切なものを選択肢から選べ。",
    correct_answer="d.インスタンスセグメンテーション",
    choices=[
        "a.パノプティックセグメンテーション",
        "b.オブジェクトセグメンテーション",
        "c.セマンティックセグメンテーション",
        "d.インスタンスセグメンテーション",
    ],
    commentary="aは物体ごと、ピクセルごとに行います。bは存在しません。cはピクセルごとにのみ行います。",
    tag="深層学習",
)

db = SessionLocal()
model70 = QuestionModel(
    question_text="XAI(Explainable AI)のモデルとして不適切なものを選択肢から選べ。",
    correct_answer="d.SSD",
    choices=[
        "a.LIME",
        "b.SHAP",
        "c.GradCAM",
        "d.SSD",
    ],
    commentary="SSDは物体検出手法の一つで解釈根拠を説明する機能は持ちません。",
    tag="深層学習",
)

db = SessionLocal()
model71 = QuestionModel(
    question_text="モデルのパラメータや構造を自動的に最適化するモデルとして適切なものを選択肢から選べ。",
    correct_answer="a.NAS",
    choices=[
        "a.NAS",
        "b.SENet",
        "c.CNN",
        "d.CutMix",
    ],
    commentary="Neural Architecture Search(NAS)はモデルのパラメータや構造を最適化する機構を持っています。NASを応用したモデルにNasNetなどがあります。",
    tag="深層学習",
)

db = SessionLocal()
model72 = QuestionModel(
    question_text="shorcut connectionを全ての層に対して適用したモデルを何と呼ぶか選択肢から選べ。",
    correct_answer="c.DenseNet",
    choices=[
        "a.WideResNet",
        "b.SENet",
        "c.DenseNet",
        "d.LeNet",
    ],
    commentary="DenseNetはshorcut connectionを全ての層に対して適用したモデルです。従来のResNetよりも勾配消失問題を改善しました。",
    tag="深層学習",
)

db = SessionLocal()
model73 = QuestionModel(
    question_text="MobileNetについて説明した文章の空欄に当てはまるものを選択肢から選べ。MobileNetは、空間方向の畳み込みである。(ア)と、チャンネル方向の畳み込みである(イ)を分けて行うことで計算量を減らしている。",
    correct_answer="b.(ア)Depthwise Convolution、(イ)Pointwise Convolution",
    choices=[
        "a.(ア)Pointwise Convolution、(イ)Depthwise Convolution",
        "b.(ア)Depthwise Convolution、(イ)Pointwise Convolution",
        "c.(ア)Separable Convolution、(イ)Simple Convolution",
        "d.(ア)Simple Convolution、(イ)Separable Convolution",
    ],
    commentary="空間方向の畳み込みをDepthwise Convolution、チャンネル方向の畳み込みをPointwise Convolutionと呼びます。通常の畳み込み処理ではこの二つは同時に行われますが、計算量を減らすために分けて行う畳み込み手法を、Depthwise Separable Convolutionと呼びます。",
    tag="深層学習",
)

db = SessionLocal()
model74 = QuestionModel(
    question_text="SegNetで利用される隙間の空いたフィルタで畳み込みを行うことを何と呼ぶか選択肢から選べ。",
    correct_answer="a.Dilated Convolution",
    choices=[
        "a.Dilated Convolution",
        "b.Depthwise Convolution",
        "c.Fully Convolution",
        "d.Seperable Convolution",
    ],
    commentary="Dilated Convolutionは隙間の空いたフィルタで畳み込みを行います。これによりプーリング層を挟まずに広範囲を抽象化することができます。",
    tag="深層学習",
)

db = SessionLocal()
model75 = QuestionModel(
    question_text="セマンティックセグメンテーションを作成するために初めて使用されたモデルとして適切なものを選択肢から選べ。",
    correct_answer="a.FCN",
    choices=[
        "a.FCN",
        "b.SegNet",
        "c.ネオコグニトロン",
        "d.RCNN",
    ],
    commentary="FCNはセマンティックセグメンテーションを作成するために初めて使用されました。全結合層を使用せずに画像データを出力するモデルです。",
    tag="深層学習",
)

db = SessionLocal()
model76 = QuestionModel(
    question_text="セマンティックセグメンテーションを作成するためのモデルとして不適切なものを選択肢から選べ。",
    correct_answer="d.EfficientNet",
    choices=[
        "a. SegNet",
        "b.U-Net",
        "c.PSPNet",
        "d.EfficientNet",
    ],
    commentary="EfficientNetはネットワークの幅、深さ、画像の解像度を定数倍することで効率的にスケールできることを示したモデルであり、セマンティックセグメンテーションの作成には一般的に用いられません。",
    tag="深層学習",
)

db = SessionLocal()
model77 = QuestionModel(
    question_text="動画からリアルタイムに姿勢を解析し、人の関節や軸を可視化する手法としてもっとも適切な選択肢を選べ。",
    correct_answer="d.OpenPose",
    choices=[
        "a.CAM",
        "b.LIME",
        "c.R-CNN",
        "d.OpenPose",
    ],
    commentary="CAMやLIMEはXAIの文脈で利用される手法、モデルです。R-CNNは物体検出ではありますが、人の関節等を可視化するわけではありません。",
    tag="深層学習",
)

db = SessionLocal()
model78 = QuestionModel(
    question_text="画像全体をグリッド領域に分割し、それぞれの領域ごとに検出したい物体か否かを確率的に推論するモデルとして最も適切な選択肢から選べ。",
    correct_answer="d.YOLO",
    choices=[
        "a.SSD",
        "b.R-CNN",
        "c.RCN",
        "d.YOLO",
    ],
    commentary="全て物体検出のモデルです。その中でもSSDとYOLOは物体の座標の推論と、物体の認識の推論を同時に行うモデルです。YOLOは分割された領域ごとに物体か背景かを推論します。",
    tag="深層学習",
)

db = SessionLocal()
model79 = QuestionModel(
    question_text="画像認識以外の回帰問題や分類問題でも利用可能であることを特徴としているXAIのモデルとして最も適切なものを選択肢から選べ。",
    correct_answer="a.SHAP",
    choices=[
        "a.SHAP",
        "b.LIME",
        "c.CAM",
        "d.FCN",
    ],
    commentary="選択肢cのCAMは画像認識分野のXAIですが、選択肢aのSHPや選択肢bのLIMEはその他の分野でも利用できます。特にSHAPは回帰でも分類でも利用できる汎用性の高いモデルです。",
    tag="深層学習",
)

db = SessionLocal()
model80 = QuestionModel(
    question_text="セマンティックセグメンテーションを作成することができるモデルとして最も不適切なものを選択肢から選べ。",
    correct_answer="d.FPN",
    choices=[
        "a.FCN",
        "b.SegNet",
        "c.PSPNet",
        "d.FPN",
    ],
    commentary="FPNはスケールした特徴マップ毎に推論を行う物体検出の手法であり、セマンティックセグメンテーションの手法ではありません。選択肢a～選択肢cはセマンティックセグメンテーションを作成する手法です。それぞれの特徴を復習しておきましょう。",
    tag="深層学習",
)

db = SessionLocal()
model81 = QuestionModel(
    question_text="RNN(Recurrent Neural Network、再帰結合型ニューラルネットワーク)は、一般的にどのようなデータを扱うことに適しているといわれているか？",
    correct_answer="a.時系列データ",
    choices=[
        "a.時系列データ",
        "b.画像データ",
        "c.件数の多いデータ",
        "d.次元数の小さいデータ",
    ],
    commentary="RNNでは時系列データに対し過去の情報を考慮した推論ができます。",
    tag="深層学習",
)

db = SessionLocal()
model82 = QuestionModel(
    question_text="自然言語処理において文章内の単語群を低次元の実数ベクトルで表現することで演算を可能とする手法として、最も適切な選択肢を1つ選べ。",
    correct_answer="c.word2vec",
    choices=[
        "a.seq2seq",
        "b.doc2vec",
        "c.word2vec",
        "d.pix2pix",
    ],
    commentary="word2vecは、文章中の単語群を低次元の実数ベクトルで表現する手法です。ベクトル化したものは単語ベクトルと呼ばれ、単語ベクトルの値を足したり引いたりすることで単語の意味関係を捉えることができます。",
    tag="深層学習",
)

db = SessionLocal()
model83 = QuestionModel(
    question_text="内部にAゲート機構を持つLSTMによって解決したRNNの課題点として、最も適切な選択肢を1つ選べ。",
    correct_answer="a.勾配消失してしまう",
    choices=[
        "a.勾配消失してしまう",
        "b.解像度の高い画像が扱えない",
        "c.計算量が大きくなりすぎる",
        "d.過去の情報を考慮できない",
    ],
    commentary="RNNでは、逆伝播のパラメータ更新(BPTT)において勾配を伝える計算が何度も繰り返されるため、勾配消失がしばしば起こりうるという課題がありました。LSTMはこうした課題の解決に寄与しています。",
    tag="深層学習",
)

db = SessionLocal()
model84 = QuestionModel(
    question_text="以下の文章を読み、(ア)～(ウ)に当てはまる組み合わせの選択肢を1つ選べ。RNNを拡張したLSTMは内部にCEC(Constant Error Carousel)という記憶素子と3つのゲート機構(入力ゲート、出力ゲート、忘却ゲート)を持つ。CECは(ア)を、入力ゲートは(イ)を、出力ゲートは(ウ)をそれぞれ防ぐことができる。忘却ゲートは不要になった過去の情報をリセットする役割を持つ。",
    correct_answer="c.(ア)勾配消失、(イ)入力重み衝突、(ウ)出力重み衝突",
    choices=[
        "a.(ア)勾配消失、(イ)出力重み衝突、(ウ)入力重み衝突",
        "b.(ア)出力重み衝突、(イ)勾配消失、(ウ)入力重み衝突",
        "c.(ア)勾配消失、(イ)入力重み衝突、(ウ)出力重み衝突",
        "d.(ア)入力重み衝突、(イ)出力重み衝突、(ウ)勾配消失",
    ],
    commentary="CECは過去の情報を保持し続けることができ、勾配消失の防止に貢献します。また、LSTMは入力ゲートによって入力重み衝突を、出力ゲートによって出力重み衝突を防ぐことができます。重み衝突とは、矛盾する重み更新が求められ、重みが適切な値に収束しないことをいいます。",
    tag="深層学習",
)

db = SessionLocal()
model85 = QuestionModel(
    question_text="LSTMよりゲート機構をシンプルにすることで計算コストを削減し、高速化を実現したモデルとして、最も適切な選択肢を1つ選べ。",
    correct_answer="d.GRU",
    choices=[
        "a.BPTT",
        "b.VGC",
        "c.Elastic Net",
        "d.GRU",
    ],
    commentary="GRUはLSTMを簡略化したモデルです。シンプルである分、LSTMよりも高速に動作しました。更新ゲートとリセットゲートの2つのゲートで、LSTMの3つのゲートに相当する役割を果たします。",
    tag="深層学習",
)

db = SessionLocal()
model86 = QuestionModel(
    question_text="以下の文章を読み、(ア)に最もよく当てはまる選択肢を1つ選べ。RNNにおける勾配爆発の問題は、勾配に対して閾値に基づく制約をかける(ア)によって回避する。",
    correct_answer="d.勾配クリッピング",
    choices=[
        "a.勾配プロット",
        "b.シール",
        "c.フロー制御",
        "d.勾配クリッピング",
    ],
    commentary="単純なRNNをLSTMなどに拡張しても、それだけでは勾配爆発を防ぐことはできません。勾配クリッピングは、勾配が閾値よりも大きくならないように制限することで勾配爆発を防ぎます。",
    tag="深層学習",
)

db = SessionLocal()
model87 = QuestionModel(
    question_text="以下の文章を読み、(ア)に最もよく当てはまる選択肢を1つ選べ。時系列データの予測をするときに、未来の情報を入力してよい場合は(ア)を使用することで精度の向上が期待できる。",
    correct_answer="a.BiRNN",
    choices=[
        "a.BiRNN",
        "b.VAE",
        "c.Maxプーリング",
        "d.FCNN",
    ],
    commentary="機械翻訳のように、未来の情報を用いてもよいタスクでは、BiRNN(Bidirectional RNN；双方向RNN)を使用することで精度の向上が期待できます。",
    tag="深層学習",
)

db = SessionLocal()
model88 = QuestionModel(
    question_text="ベクトル自己回帰モデル(VARモデル)の分析例として、最も適切な選択肢を1つ選べ。",
    correct_answer="b.現在の日経平均株価を、過去の日経平均株価、海外株式指標、為替レートから予測する",
    choices=[
        "a.前年の桜の開花日から今年の開花日を予測する",
        "b.現在の日経平均株価を、過去の日経平均株価、海外株式指標、為替レートから予測する",
        "c.数多くあるメールをスパムメールとそうでないメールに分類する",
        "d.ユーザーの購買データから年代別に嗜好性をグループ分けする",
    ],
    commentary="VARモデルは過去の複数の変数を使って現在の値を予測するモデルです。現在の日経平均株価を多変量で予測する選択肢bが最も適切な分析例です。選択肢aはARモデルの分析例です。",
    tag="深層学習",
)

db = SessionLocal()
model89 = QuestionModel(
    question_text="テキストマイニングにおけるBag-of-Wordsの処理の説明として、最も適切な選択肢を1つ選べ。",
    correct_answer="b.テキストをベクトル形式に変換する",
    choices=[
        "a.テキストを単語などの最小単位に分解する",
        "b.テキストをベクトル形式に変換する",
        "c.テキスト内の単語の関係性を解析する",
        "d.出現頻度などから各単語の重要度をつける",
    ],
    commentary="形態素解析によって品詞ごとに区切られた単語群を数値化(ベクトル化)します。Bag-of-Words(BoW)は単語の順番を考慮せず、文章内に出現した数でベクトル化をします。これにより元の文章を機械学習で扱える形式となります。",
    tag="深層学習",
)

db = SessionLocal()
model90 = QuestionModel(
    question_text="テキストマイニングにおけるTF-IDFの処理の説明として、最も適切な選択肢を1つ選べ。",
    correct_answer="d.出現頻度などから各単語の重要度をつける",
    choices=[
        "a.テキストを単語などの最小単位に分解する",
        "b.テキストをベクトル形式に変換する",
        "c.テキスト内の単語の関係性を解析する",
        "d.出現頻度などから各単語の重要度をつける",
    ],
    commentary="TF-IDFは、区切られた単語群に対して重要度を付けていきます。ある文章内での出現頻度が高い単語には大きな値を付けたり、様々な文章で横断的に使われている単語には低い値を付けたりしていきます。",
    tag="深層学習",
)

db = SessionLocal()
model91 = QuestionModel(
    question_text="自然言語処理のいくつかの用語について整理する。「形態素解析」の説明として、最も適切なものを1つ選べ。",
    correct_answer="c.ひとのつながりの文章を、意味をもつ最小の表現要素まで区切る",
    choices=[
        "a.単語間の意味的な関係性を捉えつつ、単語をベクトル表現する",
        "b.文章内の係り受けの構造を解析する",
        "c.ひとのつながりの文章を、意味をもつ最小の表現要素まで区切る",
        "d.単語間の意味的な関係性を調べて適切な構文を選択する",
    ],
    commentary="日本語などの単語間に区切りのない文章の場合、品詞ごとに分解する必要があります。たとえば、「私(名詞)/は(助詞)/ステーキ(名詞)/を(助詞)/食べ(動詞)/た(助動詞)」のように分解します。",
    tag="深層学習",
)

db = SessionLocal()
model92 = QuestionModel(
    question_text="自然言語処理のいくつかの用語について整理する。「構文解析」の説明として、最も適切なものを1つ選べ。",
    correct_answer="b.文章内の係り受けの構造を解析する",
    choices=[
        "a.単語間の意味的な関係性を捉えつつ、単語をベクトル表現する",
        "b.文章内の係り受けの構造を解析する",
        "c.ひとのつながりの文章を、意味をもつ最小の表現要素まで区切る",
        "d.単語間の意味的な関係性を調べて適切な構文を選択する",
    ],
    commentary="形態素間(品詞間)の関係を、木構造などを用いて解析します。たとえば、「私(名詞)」と「は(助詞)」は主語に繋がり、「ステーキ(名詞)」と「を(助詞)」は目的語に繋がり、「食べ(動詞)」と「た(助動詞)」は述語に繋がります。",
    tag="深層学習",
)

db = SessionLocal()
model93 = QuestionModel(
    question_text="自然言語処理のいくつかの用語について整理する。「意味解析」の説明として、最も適切なものを1つ選べ。",
    correct_answer="d.単語間の意味的な関係性を調べて適切な構文を選択する",
    choices=[
        "a.単語間の意味的な関係性を捉えつつ、単語をベクトル表現する",
        "b.文章内の係り受けの構造を解析する",
        "c.ひとのつながりの文章を、意味をもつ最小の表現要素まで区切る",
        "d.単語間の意味的な関係性を調べて適切な構文を選択する",
    ],
    commentary="構文解析により文章の係り受けの構造を構文木で表現できますが、意味的に正しいかどうかが問題となります。そこで辞書をもとに単語間の意味的な関係性を調べます。たとえば、「高い山と海」において「高い」と「山」は関係性が高いですが、「高い」と「海」は関連性が低いというように解析し、正しい構文木を選択します。こうした処理を意味解析と言います。",
    tag="深層学習",
)

db = SessionLocal()
model94 = QuestionModel(
    question_text="ベクトルの表現手法の一つである局所表現の特徴として、最も不適切な選択肢を1つ選べ。",
    correct_answer="b.扱う単語が増えても計算時間を少なくできる",
    choices=[
        "a.単語とベクトルを一対一の関係で表現できる",
        "b.扱う単語が増えても計算時間を少なくできる",
        "c.0と1でベクトルを表現する",
        "d.単語同士が同一であるか判定できる",
    ],
    commentary="局所表現はベクトルのすべての要素のうち、該当する要素だけを「1」、他のすべてを「0」で表現するため、扱う単語が増えるほどベクトルの要素数が増え、計算時間が増大するという問題があります。",
    tag="深層学習",
)

db = SessionLocal()
model95 = QuestionModel(
    question_text="文章をベクトル表現した後に用いられるコサイン類似度の性質として、最も適切な選択肢を1つ選べ。",
    correct_answer="c.ベクトル間の類似度を求めるものであり、-1～1の値を取る",
    choices=[
        "a.距離と同じ概念であり、0に近いほど類似性が高い",
        "b.ベクトル内の単語の発生頻度から重要度を求める手法である",
        "c.ベクトル間の類似度を求めるものであり、-1～1の値を取る",
        "d.単語間の類似度を求めるために局所表現の和が用いられる",
    ],
    commentary="コサイン類似度は、ベクトル間の類似度を算出する計算手法で、-1～1の値を取ります。単語の比較などの場合は0～1の値を使うことが多く、1に近いほど類似しており、0に近いほど類似していないことを表します。類似度の算出には分散表現の和が用いられます。",
    tag="深層学習",
)

db = SessionLocal()
model96 = QuestionModel(
    question_text="woed2vecにおいて周辺の単語からある単語を予測するモデルとして、最も適切な選択肢を1つ選べ。",
    correct_answer="a.CBOW",
    choices=[
        "a.CBOW",
        "b.Attention",
        "c.Skip-gram",
        "d.BERT",
    ],
    commentary="CBOWは周辺の単語からある単語を予測するモデルです。一方で、Skip-gramは、ある単語を与えて周辺の単語を予測するモデルです。",
    tag="深層学習",
)

db = SessionLocal()
model97 = QuestionModel(
    question_text="自動翻訳で用いられるseq2seqは、RNNを用いたEncoder-Decoder(RNN Encoder-Decoder)モデルとして機能する。RNN Encoder-Decoderの特徴として、最も適切な選択肢を1つ選べ。",
    correct_answer="d.入力された時系列データが固定長ベクトルに変換され、それが可変長ベクトルに変換されて出てくる",
    choices=[
        "a.1つのRNNで構成されている",
        "b.入力される文章の単語数と出力される文章の単語数が異なることはない",
        "c.Decoderの翻訳元の文章を入力し、Encoderから翻訳語の文章が出力される",
        "d.入力された時系列データが固定長ベクトルに変換され、それが可変長ベクトルに変換されて出てくる",
    ],
    commentary="RNN Encoder-Decoderモデルは、EncoderとDecoderと呼ばれる2つのRNN(LSTMなど)から構成されており、Encoderに入力された時系列データが固定長のベクトルに変換され、Decoderからは時系列データ(可変長のベクトル)に変換されて出てくるという仕組みです。そのため、入力される単語数と出力される単語数が異なるケースもあります。",
    tag="深層学習",
)

db = SessionLocal()
model98 = QuestionModel(
    question_text="ディープラーニングによる時系列タスクに用いられ、時系列のどの時点に着目すべきかという重みづけをする技術として、最も適切な選択肢を1つ選べ。",
    correct_answer="d.Attention",
    choices=[
        "a.Warning",
        "b.Transformer",
        "c.TF-IDF",
        "d.Attention",
    ],
    commentary="RNNのどの時間軸の出力が重要であるかという重みづけをする技術をAttentionと言います。たとえば機械翻訳では、入力の単語と出力の単語の相応関係を意識した予測がされると考えられます。そのため、自動翻訳において重要な技術の一つとされ、Google翻訳の精度向上に大きく寄与したニューラル機械翻訳は、seq2seqモデルにAttentionを組み合わせて実現されています。選択肢bのTransformerは、RNNやCNNを使わずにAttentionだけで構成したモデルです。選択肢cのTF-IDFは、出現頻度から各単語の重要度を評価する手法です。",
    tag="深層学習",
)

db = SessionLocal()
model99 = QuestionModel(
    question_text="RNNやCNNを使わずにAttentionだけで構成したTransformerの特徴として、最も適切でない選択肢を1つ選べ。",
    correct_answer="a.ベクトル表現手法として局所表現が採用されている",
    choices=[
        "a.ベクトル表現手法として局所表現が採用されている",
        "b.RNNを用いるよりも計算の高速化ができる",
        "c.CNNを用いるよりも長文への対応がしやすい",
        "d.EncoderとDecoderから構成されている",
    ],
    commentary="Transformerは、入力されたデータを基に単語の分散表現を生成して処理します。生成した分散表現を基にAttentionで単語間の関連性などを計算することになります。",
    tag="深層学習",
)

db = SessionLocal()
model100 = QuestionModel(
    question_text="Transformerにおいては、文章中の単語の相対的な位置情報が含まれない。単語の位置情報を付与する処理として、最も適切な選択肢を1つ選べ。",
    correct_answer="c.Positional Encoding",
    choices=[
        "a.Position-wise Feed-Forward Network",
        "b.Vector Encoding",
        "c.Positional Encoding",
        "d.Positional Normalization",
    ],
    commentary="Transformerは、RNNの再帰構造やCNNの畳み込みがないため、文中における単語の相対的な位置情報が含まれません。そこで、Positional Encodingにより分散表現と同形状の位置情報ベクトルが付与されます。",
    tag="深層学習",
)

db = SessionLocal()
model101 = QuestionModel(
    question_text="Transformer内では、Self-Attentionにより各文章ベクトルから単語間の関連性が計算される。算出された関連性から重要度を表す重みを計算するために用いられる関数として、最も適切な選択肢を1つ選べ。",
    correct_answer="b.ソフトマックス関数",
    choices=[
        "a.シグモイド関数",
        "b.ソフトマックス関数",
        "c.ReLU関数",
        "d.恒等関数",
    ],
    commentary="Self-Attentionを用いて各文章ベクトルから単語間の関連性を計算し、算出した関連性をソフトマックス関数で0～1の値に表します。0～1の値は、文章内のどの単語が重要かを示す重みと考えることができます。",
    tag="深層学習",
)

db = SessionLocal()
model102 = QuestionModel(
    question_text="Googleが発表した自然言語処理モデルであるBERTは、双方向Transformerにより高速かつ高精度な予測精度を実現したモデルである。その仕組みの一つであるマスクされた言語モデルの特徴として、最も適切な選択肢を1つ選べ。",
    correct_answer="a.任意の文字や文字列を隠して、前後の文脈から予測する",
    choices=[
        "a.任意の文字や文字列を隠して、前後の文脈から予測する",
        "b.与えられた文章を元に、次に繋がる文章を生成する",
        "c.与えられた2つの文章が意味的に繋がるかどうかを判定する",
        "d.代名詞が指す対象を文脈から推定する",
    ],
    commentary="マスクされた言語モデルは、文章を構成するトークン(文章の最小単位である文字や文字列)からランダムに15%のトークンを選び、MASKトークンで隠します。一部を隠した文章を渡すと、前後の文脈から隠されたトークンを予測するという仕組みです。",
    tag="深層学習",
)

db = SessionLocal()
model103 = QuestionModel(
    question_text="人工知能を研究する非営利組織OpenAIが開発したもので、フェイクニュースやスパムメールの生成などの悪用が危険視され、一般向けに公開することに懸念を示したモデルとして、最も適切な選択肢を1つ選べ。",
    correct_answer="c.GPT-2",
    choices=[
        "a.BERT",
        "b.ELMo",
        "c.GPT-2",
        "d.GAN",
    ],
    commentary="OpenAIが開発したGPT-2は、非常に高精度な文章を生成するモデルですが、悪用の危険性があるほど精度が高く、論文公開が延期される事態にもなりました。",
    tag="深層学習",
)

db = SessionLocal()
model104 = QuestionModel(
    question_text="自然言語処理分野における客観的にモデルの予測精度を計測するためのデータセットとして、最も適切な選択肢を1つ選べ。",
    correct_answer="b.GLUE",
    choices=[
        "a.DETR",
        "b.GLUE",
        "c.CLIP",
        "d.ImageNet",
    ],
    commentary="GLUEは英語圏で自然言語処理の標準ベンチマークとして用いられる測定用のデータセットです。同義言い換えや質疑応答といった言語に関するテストデータが含まれており、テストデータを使って総合的な言語能力のスコアを算出できます。",
    tag="深層学習",
)

db = SessionLocal()
model105 = QuestionModel(
    question_text="音声処理について以下の文章を読み、(ア)～(イ)に当てはまる組み合わせの選択肢を1つ選べ。音波から特徴量を抽出する処理を行うためにまず(ア)を行う。そして(イ)を行って音声が存在する区間のみを見つけ出す。その音声に対して(ウ)をすることで周波数成分を抽出する。",
    correct_answer="d.(ア)A-D変換、(イ)音声区間検出、(ウ)離散フーリエ変換",
    choices=[
        "a.(ア)D-A変換、(イ)ケプストラム分析、(ウ)ラプラス変換",
        "b.(ア)D-A変換、(イ)ケプストラム分析、(ウ)離散フーリエ変換",
        "c.(ア)A-D変換、(イ)音声区間検出、(ウ)ラプラス変換",
        "d.(ア)A-D変換、(イ)音声区間検出、(ウ)離散フーリエ変換",
    ],
    commentary="スペクトル解析では、まずA-D変換することで時系列データをデジタルデータに変換します。次に音声区間検出をして音声と音声以外の音、(雑音や無音区間など)が含まれる音声データから音声が存在する区間のみ検出します。その音声に対して離散フーリエ変換を行うことで周波数成分を抽出します。",
    tag="深層学習",
)

db = SessionLocal()
model106 = QuestionModel(
    question_text="音声認識において人間の聴覚特性に基づいて提案された特徴量として、最も適切な選択肢を1つ選べ。",
    correct_answer="a.メル周波数ケプストラム係数",
    choices=[
        "a.メル周波数ケプストラム係数",
        "b.音響インテンシティ",
        "c.スペクトル包絡",
        "d.音響透過損失",
    ],
    commentary="フーリエ変換により抽出したスペクトルから得られる代表的な特徴量としてメル周波数ケプストラム係数があります。メル周波数ケプストラム係数は、人間の聴覚特性(音の高さを捉える働き)に基づいて提案された特徴量です。",
    tag="深層学習",
)

db = SessionLocal()
model107 = QuestionModel(
    question_text="音素の説明として、最も適切な選択肢を1つ選べ。",
    correct_answer="d.意味を区別する音の最小単位",
    choices=[
        "a.人間が発声する区別可能な音",
        "b.音の大きさを表す単位",
        "c.二つの音の高さの隔たり",
        "d.意味を区別する音の最小単位",
    ],
    commentary="音素は、母音や子音などの音の最小単位です。英語では「r」と「l」の発音によって言葉の意味が変わってきます。音声認識では、言葉の意味を正しく区別するために音素の特定が必要になります。",
    tag="深層学習",
)

db = SessionLocal()
model108 = QuestionModel(
    question_text="人間の音の高さに対する感覚量を指標として、最も適切な選択肢を1つ選べ。",
    correct_answer="c.メル尺度",
    choices=[
        "a.音韻",
        "b.音素",
        "c.メル尺度",
        "d.CEC",
    ],
    commentary="メル尺度は、人間の聴覚において音の高さ(音高)を知覚する際の量を表す尺度です。人間の聴覚には、周波数の低い音に対して敏感で、周波数の高い音に対しては鈍感であるという性質があることから考案されました。",
    tag="深層学習",
)

db = SessionLocal()
model109 = QuestionModel(
    question_text="音の周波数について以下の文章を読み、(ア)～(イ)に当てはまる組み合わせの選択肢を1つ選べ。周波数の振幅を表す(ア)は、母音を認識する際などに利用できる特徴である。(ア)には山と谷があり、ピークの地点を(イ)といい、母音に対する特徴を示す。",
    correct_answer="c.(ア)スペクトル包絡、(イ)フォルマント",
    choices=[
        "a.(ア)聴覚高調波、(イ)フォルマント",
        "b.(ア)聴覚高調波、(イ)サンプリング定理",
        "c.(ア)スペクトル包絡、(イ)フォルマント",
        "d.(ア)スペクトル包絡、(イ)サンプリング定理",
    ],
    commentary="メルフィルタバンクにかけて音の周波数をメル尺度に変換すると、周波数成分のエネルギーの包絡であるスペクトル包絡の特徴が抽出できます。包絡のピークの地点をフォルマントといい、ピークである共振周波数をフォルマント周波数といいます。",
    tag="深層学習",
)

db = SessionLocal()
model110 = QuestionModel(
    question_text="音声認識について以下の文章を読み、(ア)に最もよく当てはまる選択肢を1つ選べ。音声認識において入力と出力の系列長が異なる場合に用いられる損失関数に(ア)がある。(ア)は、音素や単語などの区切りにブランクのラベルを追加し、繰り返される同一ラベルとブリンクを削除することで、出力へとマッピングする。この縮約によって、音響モデルの出力を最適化することができ、翻訳精度の向上が期待できる。",
    correct_answer="d.CTC",
    choices=[
        "a.HMM",
        "b.DFT",
        "c.MFCC",
        "d.CTC",
    ],
    commentary="異なる系列長のデータをマッピングするために提案されたCTC(Connectionist Temporal Classification)という損失関数の説明です。選択肢aのHMMは隠れマルコフモデル、選択肢bのDFTは離散フーリエ変換、選択肢cのMFCCはメル周波数ケプストラム係数のことです。",
    tag="深層学習",
)

db = SessionLocal()
model111 = QuestionModel(
    question_text="WaveNetの説明として、最も適切でない選択肢を1つ選べ。",
    correct_answer="b.ブラインドテストにおいて、英語は既存手法の結果を超えたが、中国語は超えられていない",
    choices=[
        "a.人間の音声をサンプルに音声波形を解析している",
        "b.ブラインドテストにおいて、英語は既存手法の結果を超えたが、中国語は超えられていない",
        "c.CNNを応用することで音声生成と音声認識を可能にしている",
        "d.いくつかの入力をスキップすることで音声データを効率的に処理する",
    ],
    commentary="DeepMind社が開発した音声生成・音声認識モデルのWaveNetは、RNNではなくCNNを応用して構成されています。WaveNetは、ブラインドテストにおいて英語、中国ともに既存手法よりも高いスコアを出しています。",
    tag="深層学習",
)

db = SessionLocal()
model112 = QuestionModel(
    question_text="GAN(Generative Adversarial Network)について述べた文章として、最もよく当てはまる選択肢を1つ選べ。",
    correct_answer="d.ジェネレータとディスクリミネータから構成される",
    choices=[
        "a.GANは、系列データを逐次的に計算するため、学習にはGPUを用いることができない",
        "b.GANは、入力と統計分布に変換し、平均と分散を表現するように学習する",
        "c.GANは、オートエンコーダを利用する",
        "d.ジェネレータとディスクリミネータから構成される",
    ],
    commentary="GANはジェネレータとディスクリミネータという2つのニューラルネットワークで構成される。画像を生成する場合、ジェネレータはノイズから画像を生成し、ディスクリミネータは実際の画像ジェネレータが生成した画像の真偽を判定します。ジェネレータは、ディスクリミネータを騙せるように学習し、実際の画像に近づけるという手法をとる。",
    tag="深層学習",
)

db = SessionLocal()
model113 = QuestionModel(
    question_text="DCGANについて述べた文章として、最もよく当てはまる選択肢を1つ選べ。",
    correct_answer="c.GANにCNNを取り込んだもの",
    choices=[
        "a.GANにRNNに取り込んだもの",
        "b.GANにDQNを取り込んだもの",
        "c.GANにCNNを取り込んだもの",
        "d.GANにVAEを取り込んだもの",
    ],
    commentary="DCGAN(Deep Convolutional GAN)は、GANにCNNを取り込んだものです。",
    tag="深層学習",
)

db = SessionLocal()
model114 = QuestionModel(
    question_text="CycleGANを説明した文章として適切なものを選択肢から選べ。",
    correct_answer="b.異なるドメインの関係性を学習する",
    choices=[
        "a.オートエンコーダを仕組みを用いたものである",
        "b.異なるドメインの関係性を学習する",
        "c.学習時に条件を入力することができる",
        "d.ニューラルネットワークを繋げ再帰的に学習するものである。",
    ],
    commentary="選択肢aは、変分オートエンコーダの説明です。選択肢cはCGANの説明、選択肢dはENNの説明です。",
    tag="深層学習",
)

db = SessionLocal()
model115 = QuestionModel(
    question_text="CGANの仕組みを取り入れたモデルとして最も適切なものを選択肢から選べ。",
    correct_answer="c.pix2pix",
    choices=[
        "a.LeNet",
        "b.TensorFlow",
        "c.pix2pix",
        "d.word2vec",
    ],
    commentary="CGANはConditional GANの略で、条件を入力データとして画像生成します。画像を条件として、画像から画像をつくるpix2pixというモデルが考案されました。pix2pixはpicture to pictureを省略した表現です。",
    tag="深層学習",
)

db = SessionLocal()
model116 = QuestionModel(
    question_text="次の(  )に当てはまる言葉を選択肢から１つ選べ。学習等にデータを使用、他者と共有、又は、他者へデータを提供する場合にはデータが営業秘密等であるかに注意する必要がある。(   )のデータに対し、不正に取得されたものを使用する行為等が、不正競争防止法における民事上·刑事上の措置を受ける場合がある。でなくとも、ガイドライン等で一定の行為が禁止されているデータもある。例えば、金融分野における「機微(センシティブ)情報」等がある。",
    correct_answer="a.営業秘密·限定提供データ",
    choices=[
        "a.営業秘密·限定提供データ",
        "b.オープンデータ·営業秘密",
        "c.限定提供データ·学習データ",
        "d.オープンデータ·官民データ",
    ],
    commentary="不正競争防止法で不正な取得等から保護されているデータがある。営業秘密は、有用性、秘密管理性、及び、非公知性の要件を備える情報である(不正競争防止法第２条第６項)。限定提供データは、「業として特定の者に提供する情報として電磁波的方法(電子的方法、磁気的方法その他人の知覚によっては認識することができない方法をいう。事項において同じ。)により相当量蓄積され、及び管理されているものを除く。)」である。(不正競争防止法第２条第７項)。訓練データは、AIの学習用データをいう。検証データは、AIの評価用データをいう。オープンデータは、一般的な公知となったデータをいう。著作権法等で、保護対象になっている場合もある。官民データは、国若しくは地方公共団体又は独立行政法人が管理等をするデータをいう(官民データ活用推進基本法第２条第１項)。",
    tag="法規・倫理",
)

db = SessionLocal()
model117 = QuestionModel(
    question_text="次の(  )に当てはまらない言葉を選択肢から１つ選べ。学習等にデータを使用、又は、他者へデータを提供する場合には個人情報の扱いに注意する必要がある。例えば、個人情報を示す元のデータを特定の個人を特定できないように加工し、個人情報を復元できない状態にした「匿名加工情報」にする必要等がある。元のデータを匿名加工情報にするには(    )等の匿名化技術がある。",
    correct_answer="b.マスキング",
    choices=[
        "a.トップ(ボトム)コーディング",
        "b.マスキング",
        "c.項目削除",
        "d.一般化",
    ],
    commentary="a：トップ(ボトム)コーディングは手法の１つである(個人情報保護委員会規則第１９条(第５号)。b：マスキングは十分ではない(個人情報保護委員会ホームページ「1.匿名加工情報とは」)。c.項目削除は手法の１つである(個人情報保護委員会規則１９条(第５号)。d.一般化は手法の１つである(個人情報保護委員会規則１９条(第５号)。",
    tag="法規・倫理",
)

db = SessionLocal()
model118 = QuestionModel(
    question_text="次の(  ) に当てはまる言葉を選択肢から１つ選べ。学習等にデータを使用、又は、他者へデータを提供する場合には個人情報の扱いに注意する必要がある。例えば、個人情報を示す元のデータを特定の個人を識別できないように加工し、個人情報を復元できない状態にした「匿名加工情報」にする必要等がある。元のデータを匿名加工情報にするには(    )等の匿名化技術がある。",
    correct_answer="a.k-匿名化",
    choices=[
        "a.k-匿名化",
        "b.特異な記述の維持",
        "c.個人情報を復元できるように加工",
        "d.氏名の情報を残すように加工",
    ],
    commentary="a：匿名加工情報として扱うには「特定の個人を識別すること及びその作成に用いる個人情報を復元することができないようにするため」加工を行う義務がある。(個人情報の保護に関する法律第３６条)。匿名加工情報であれば、一定の条件下で本人同意なく事業者間でやりとりが可能となる(個人情報の保護に関する法律第２条)。b：特異な記述や珍しい事例は削除が必要である(個人情報保護委員会規則第１９条(第４号))。c.復元できないように加工する義務がある。d.削除対象である(個人情報保護委員会規則第１９条(第１号))。",
    tag="法規・倫理",
)

db = SessionLocal()
model119 = QuestionModel(
    question_text="次の(  )に当てはまる言葉を選択肢から１つ選べ。学習用のデータ、及び、プログラムといった無体物を扱うには法律上、有体物とは扱いの違いに注意する。データは民法上、所有権、占有権、用益物権、及び、保護物権等の対象にできない。そこで、(   )として不正競争防止等で保護する配慮が必要となる。",
    correct_answer="a.営業秘密",
    choices=[
        "a.営業秘密",
        "b.発明",
        "c.秘密意匠",
        "c.個人情報",
    ],
    commentary="データは民法上、所有権、占有権、用益物権、及び、担保物権等の対象にできない(AI・データの利用に関する契約ガイドライン1.1版、民法205条、85条)。そこで、不正競争防止法第2条第6項で定められている有用性、秘密管理性、及び、非公知正の3つの要件を備えて「営業秘密」として不正競争防止法で保護が可能である。なお、プログラム等は特許権・著作権法等で保護対象となる場合があるが「営業秘密」である必要はない。",
    tag="法規・倫理",
)

db = SessionLocal()
model120 = QuestionModel(
    question_text="次の(  )に当てはまる言葉を選択肢から１つ選べ。学習用データ、プログラム、データベース、仕様書、及び、AIによる成果物等のデータは特許法及び(  )の法律で模倣されるから保護できる。共同使用、販売又は共同開発等でオープンにする客体と、他者には秘密にする客体とで保護方法を使い分ける必要がある。オープンにするプログラム等は特許出願をして特許権を取得して保護を図る。一方で、社外へ開示しないデータ等は(   )における営業秘密で保護する方法等がある。",
    correct_answer="a.不正競争防止法",
    choices=[
        "a.不正競争防止法",
        "b.特許法",
        "c.個人情報保護法",
        "d.外為法",
    ],
    commentary="不正競争防止法第2条第6項で定められている有用性、秘密管理性、及び、非公知性であり、この3つの要件を備える「営業秘密」等は不正競争防止法で差止請求等の保護が可能である。オープンイノベーション等といった他者と連携する場合等では互いに保有する技術を共有する場合が多いため、特許権等の権利を確保するか、又は、営業秘密で保護するかのどちらで保護するかを使い分ける戦略が必要である。",
    tag="法規・倫理",
)

db = SessionLocal()
model121 = QuestionModel(
    question_text="次の(   )に当てはまる言葉を選択肢から１つ選べ。学習用データ等のデータ、及び、プログラムは特許権又は営業秘密等で法的に保護できる場合がある。営業秘密で保護するには、(   )、及び、非公知性等の要件を備える必要がある。",
    correct_answer="a.有用性、秘密管理性",
    choices=[
        "a.有用性、秘密管理性",
        "b.新規性・進歩性",
        "c.新規性・非創作容易性",
        "d普通名称でない・慣用商標でない",
    ],
    commentary="不正競争防止法で保護の客体となる営業秘密要件は不正競争防止法第2条第6項で定められている有用性、秘密管理性、及び、非公知性である。b：特許権の要件である(特許法第29条)。c：意匠登録の要件である(意匠法第3条)。d.商標登録の要件である(商標法第3条)。",
    tag="法規・倫理",
)

db = SessionLocal()
model122 = QuestionModel(
    question_text="次の(  )に当てはまる言葉を選択肢から１つ選べ。学習用データ等のデータ、及び、プログラムは特許権又は営業秘密等で法的に保護できる場合がある。学習用等のデータ、プログラム、データベース、仕様書、ソースコード、及び、設計図のうち、営業秘密で保護できる可能性があるのは(  )である。営業秘密として保護の客体となるには、有用性、秘密管理性、及び、非公知性等を備える必要がある。",
    correct_answer="a.すべて",
    choices=[
        "a.すべて",
        "b.データのみ",
        "c.プログラムのみ",
        "d.データ以外",
    ],
    commentary="正解は１学習用等のデータ、プログラム、データベース、仕様書、ソースコード、及び、設計図の「すべて」である。ただし、不正競争防止法で保護の客体となるには、営業秘密である必要がある。営業秘密となる要件は不正競争防止法第2条第6項で定められている有用性、秘密管理性、及び、非公知性であり、この3つの要件を備えれば形式や書面であるか否かを問わない。",
    tag="法規・倫理",
)

db = SessionLocal()
model123 = QuestionModel(
    question_text="次の問題に当てはまる言葉を選択肢から１つ選べ。学習用データ、プログラム、データベース、仕様書、及び、AIによる成果物等のデータは「営業秘密」として保護される場合がある。転職、社外への発表、販売、情報提供、又は、他者との共同開発等で営業秘密を扱う場合には、(  )に該当する行為が注意する必要がある。例えば、(  )となる行為は、不正取得、不正使用、又は、不正開示等がある。",
    correct_answer="",
    choices=[
        "a.特許権侵害",
        "b.著作権侵害",
        "c.情報漏洩",
        "d.不正競争",
    ],
    commentary="不正競争防止法では、営業秘密不正取得行為等の「不正競争」を原則禁じている(不正競争防止法第2条第1項各号)。a：特許権侵害の対象となるものは特許発明である。b：著作権侵害の対象となるものは著作物である。c：情報漏洩は意図しない外部への情報流出全般を指し、不正競争によるもの以外(例えば、セキュリティ上の設定ミス)も含む。",
    tag="法規・倫理",
)

db = SessionLocal()
model123 = QuestionModel(
    question_text="次の( )に当てはまる言葉を選択肢から1つ選べ。学習用データ等のデータ、 及び、 プログラムは特許権又は( )等で法的に保護されている場合がある。他者の特許発明又は( )を権利者に無断で実施すると民事・刑事上の請求又は罰則を受ける場合があるため注意する。発明を特許出願をして特許権を取得して保護を図る、及び、 データを( )として保護を図る方法等がある。( )として保護の客体となるには、有用性、 秘密管理性、及び、 非公知性等を備える必要がある。",
    correct_answer="b.営業秘密",
    choices=[
        "a.発明",
        "b.営業秘密",
        "c.秘密意匠",
        "d.個人情報",
    ],
    commentary="不正競争防止法でデータ等の保護を図るには、 営業秘密である必要がある。営業秘密の要件は不正競争防止法第2条第6項で定められている有用性、 秘密管理性、及び、 非公知性である。a：発明は 「自然法則を利用した技術的思想の創作のうち高度のもの」である (特許法第2条第1項)。c：秘密意匠は「意匠出願において秘密にすることを請求された意匠」である (意匠法第14条)。d：個人情報は「生存する個人に関する情報であって、氏名等」である(個人情報の保護に関する法律第2条)。",
    tag="法規・倫理",
)

db = SessionLocal()
model124 = QuestionModel(
    question_text="次の( )に当てはまる言葉を選択肢から1つ選べ。学習等にデータを使用、 又は、 他者へデータを提供する場合には個人情報の扱いに注意する必要がある。例えば、 個人情報を示す元のデータを特定の個人を識別できないように加工し、 個人情報を復元できない状態にした 「匿名加工情報」にする必要等 がある。匿名加工情報にするには、(  )が必要となる。",
    correct_answer="c.個人情報に含まれる個人識別符号の全部を削除",
    choices=[
        "a.IDの付与",
        "b.本人の同意",
        "c.個人情報に含まれる個人識別符号の全部を削除",
        "d.個人情報を復元できるように加工",
    ],
    commentary="正解はc「個人情報に含まれる個人識別符号の全部を削除」である。匿名加工情報として扱うには 「特定の個人を識別すること及びその作成に用いる個人情報を復元することができないようにするため」加工を行う義務がある(個人情報の保護に関する法律第36条)。a：個人情報に含まれる個人識別符号の全部を削除する加工が必要であるが (個人情報保護委員会規則第19条 (第2号))、IDの付与は義務付けられていない。b：匿名加工情報であれば、一定の条件下で本人同意なく事業者間でやりとりが可能となる(個人情報の保護に関する法律第2条)。d：復元できないように加工する義務がある。",
    tag="法規・倫理",
)

db = SessionLocal()
model125 = QuestionModel(
    question_text="次の( )に当てはまる言葉を選択肢から1つ選べ。学習等に用いるデータを他者から提供してもらう場合、又は、共有する場合にはデータの利用に関して契約を結ぶ。 外部に漏洩したくない情報を扱う場合には、契約で(   )を課す。 契約後、(   )がある者のみで営業秘密等を扱うように配慮する必要がある。",
    correct_answer="a.秘密保持義務",
    choices=[
        "a.秘密保持義務",
        "b.情報開示義務",
        "c.勤労の義務",
        "d.届出の義務",
    ],
    commentary="正解はa「秘密保持義務」である。営業秘密等の情報を扱う従業員等には契約で秘密保持義務を課すのが重要である(AIデータの利用に関する契約ガイドライン 1.1版) 秘密保持義務のある者の間で扱われる情報は、秘密の状態、すなわち、「非公知性」 を確保でき、営業秘密で保護できる場合がある。「秘密保持義務」は「守秘義務」と呼ばれる場合もある。",
    tag="法規・倫理",
)

db = SessionLocal()
model126 = QuestionModel(
    question_text="次の( )に当てはまる言葉を選択肢から1つ選べ。学習用データ、プログラム、データベース、 仕様書、及び、AIによる成果物等のデータは法律で保護されている場合がある。他者と共同して開発をする場合等には、オープンにする客体と、秘密にする客体とで保護方法を使い分ける必要がある。オープンにするプログラム等は特許出願をして特許権を取得して保護を図る。一方で、社外へ開示しないデータ等は(   )として保護を図る方法等がある。(   )として保護の客体となるには、有用性、秘密管理性、及び、非公知性等を備える必要がある。",
    correct_answer="d.営業秘密",
    choices=[
        "a.発明",
        "b.秘密意匠",
        "c.個人情報",
        "d.営業秘密",
    ],
    commentary="正解はd「営業秘密」である。不正競争防止法でデータ等の保護を図るには、営業秘密である必要がある。オープンイノベーション等といった他者と連携する場合等では互いに保有する技術を共有する場合が多いため、特許権等の権利を確保するか、又は、営業秘密で保護するかのどちらで保護するかを使い分ける戦略が必要である。a：発明は「自然法則を利用した技術的思想の創作のうち高度のもの」である (特許法第2条第1項)。b：秘密意匠は「意匠出願において秘密にすることを請求された意匠」である(意匠法第14条)。c：個人情報は「生存する個人に関する情報であって、氏名等」である(個人情報の保護に関する法律第2条)。",
    tag="法規・倫理",
)

db = SessionLocal()
model127 = QuestionModel(
    question_text="次の( )に当てはまる言葉を選択肢から1つ選べ。学習用データ、プログラム、データベース、仕様書、及び、AIによる成果物等のデータは法律で保護されている場合がある法的に技術等の知的財産を保護しようとする場合には、特許出願をして特許権を取得して保護を図る、及び、(   )として保護を図る方法等がある(   )として保護の客体となるには、有用性、秘密管理性、及び、非公知性等を備える必要がある。",
    correct_answer="b.営業秘密",
    choices=[
        "a.発明",
        "b.営業秘密",
        "c.秘密意匠",
        "d.個人情報",
    ],
    commentary="正解はb「営業秘密」である。不正競争防止法でデータ等の保護を図るには、営業秘密である必要がある。営業秘密の要件は不正競争防止法第2条第6項で定められている有用性、秘密管理性、及び、非公知性である。a：発明は「自然法則を利用した技術的思想の創作のうち高度のもの」である (特許法第2条第1項)。c：秘密意匠は「意匠出願において秘密にすることを請求された意匠」である(意匠法第14条)。d：個人情報は「生存する個人に関する情報であって、氏名等」である(個人情報の保護に関する法律第2条)。",
    tag="法規・倫理",
)

db = SessionLocal()
model128 = QuestionModel(
    question_text="次の( )に当てはまる言葉を選択肢から1つ選べ。学習用のデータ等は大量のデータを効率よく収集する必要がある。官民データ活用推進基本法により、(   )はオープンデータに取り組むことが義務づけされた。オープンデータ等のデータをうまく利用するのが求められる。",
    correct_answer="d.国及び地方公共団体",
    choices=[
        "a.大企業",
        "b.中小企業",
        "c.製造業の企業",
        "d.国及び地方公共団体",
    ],
    commentary="正解はd「国及び地方公共団体」である。官民データ活用推進基本法(平成28年法律第103号)で、オープンデータへの取り組みが義務付けられ、 オープンデータへの取り組み組により、国民参加・ 官民協働の推進を通じた諸課題の解決、経済活性化、行政の高度化・効率化等が期待されている。機械学習用に使えるオープンデータのデータセットを検索できるサイト等もある。",
    tag="法規・倫理",
)

db = SessionLocal()
model129 = QuestionModel(
    question_text="個人情報を保護するための対策について、最も適切な選択肢を1つ選べ。",
    correct_answer="",
    choices=[
        "a.個人データの利用が終了した後でも、個人情報取扱事業者は当該個人データを高い緻密性で保管する義務がある。",
        "b.信条、病歴、犯罪の経歴などの要配慮個人情報を利用する際に、取得した情報の利用目的を公表すれば、本人の同意を事前に得る必要がない。",
        "c.単体では個人を特定できないように個人情報を加工したものを仮名加工情報と呼ぶ。",
        "d.カメラ画像から性別という1つの属性のみ抽出した情報でも個人情報に該当するため、その利用にあたっては写された本人への通知が必要である。",
    ],
    commentary="仮名加工情報とは、個人情報から、個人を特定できる情報を削除し、単体では個人を特定できないように加工した情報として定義されています。ただし、仮名加工情報は、他の情報と照らし合わせると個人を特定できる可能性が残ります。企業による情報の利活用を促進することを目的に、改正個人情報保護法のもとで、2022年4月1日から導入されました。a：個人データを利用する必要がなくなった場合、個人情報取扱事業者はその個人データを遅滞なく消去するよう努めなければなりません。b：要配慮個人情報は個人情報の中で特に取り扱いの制限が多く、利用や公開はもちろん、その取得にも厳しい規制が課せられています。特定の条件に当てはまる場合、(例：法令にもとづく場合、生命、身体、財産の保護のために必要な場合など)を除いて、予め本人の同意を得ないで取得してはなりません。d：個人情報保護委員会によると、個人情報とは、特定の個人を識別することができる情報と定義されます。カメラから抽出した移動軌跡データが、性別、年齢、又は全身のシルエット画像など”のみ”であれば、抽出元の本人を判別可能なカメラ画像や個人識別符号など本人を識別することができる情報と容易に照合することができる場合を除き、個人情報には該当しません。",
    tag="法規・倫理",
)

db = SessionLocal()
model130 = QuestionModel(
    question_text="個人データの扱い方について、最も適切な選択肢を1つ選べ。",
    correct_answer="c.故人に関する情報をその人の死後に取得し学習に利用した場合は、個人情報保護法が適用されない。",
    choices=[
        "a.法人には個人が雇用されているため、法人に関する情報も一定条件を満たせば、個人情報に含まれることがある。",
        "b.単体で個人を特定できる番号や文字は個人識別符号と呼ばれ、氏名、生年月日、マイナンバー、パスポート番号などが挙げられる。",
        "c.故人に関する情報をその人の死後に取得し学習に利用した場合は、個人情報保護法が適用されない。",
        "d.第三者から個人情報を含むデータを受領した場合、確認しなければいけない項目は、提供者本人の氏名と住所の2つである。",
    ],
    commentary="個人情報保護法の対象となるのは、原則として「生きている個人の情報」です。よって、法人の情報は個人情報保護法の対象とされないため、選択肢aは誤りです。b：個人識別符号とは、単独で個人を識別可能な個人情報であり、以下のいずれかに該当します。①生存する個人の身体的な特徴に関する情報例：生体情報を変換した符号(DNA、顔、声紋、歩行の態様、指紋)②個人に割り当てられる符号例：公的な番号(パスポート番号、基礎年金番号、免許証番号、住民票コード、マイナンバーなど)氏名と生年月日は、他の個人情報と照らし合わせた際に個人と特定できる可能性がありますが、上記の個人識別符号の条件には該当しません。d：第三者から個人情報を含むデータを受領した際、以下を確認しなければいけません。①提供者が個人の場合は、その人の氏名と住所、法人である場合は代表者の氏名②個人情報が取得された経緯",
    tag="法規・倫理",
)

db = SessionLocal()
model131 = QuestionModel(
    question_text="個人データの扱い方として、最も適切な選択肢を1つ選べ。",
    correct_answer="b.要配慮個人情報は原則として、本人の同意なく取得することが禁止されている。",
    choices=[
        "a.個人情報の利用目的が当初予定された目的から変更が生じた場合、システムを公開前に、個人情報取扱事業者は必ず本人に連絡を取って同意を得なければいけない。",
        "b.要配慮個人情報は原則として、本人の同意なく取得することが禁止されている。",
        "c.データ分析業務を別の企業に委託する場合、個人情報の不正使用や漏洩を防止するための安全管理措置は委託先に委ねることができ、監督の義務は原則生じない",
        "d.企業に課される個人情報を保護するために規制は、取り扱われる個人情報のデータ量が多いほど厳しくなる。",
    ],
    commentary="要配慮個人情報は、以下のように定義されている個人情報です。「本人の人種、信条、社会的身分、病歴、犯罪の経歴、犯罪により害を被った事実その他本人に対する不当な差別、偏見その他の不利益が生じないようにその取扱いに配慮を要するものとして政令で定める記述などが含まれる個人情報」特定の条件に当てはまる場合、(例：法令にもとづく場合、生命、身体、財産の保護のために必要な場合など)を除いて、要配慮個人情報を、予め本人の同意を得ないで取得してはいけません。a：本来は自由に変更することができないのですが、例外として利用目的を変更できるのは、変更前の利用目的と関連性を有すると合理的に認められる範囲に限ります。別の言い方をすると、客観的にみて本人が予期できる範囲内での変更であることに限ります。また、変更された利用目的は、本人に通知するか、又は公表しなければならない、となっているため、「必ず本人に連絡を取って同意を得なければいけない」というわけではありません。c：データの安全管理措置については、委託する側が委託先の監督を行うことが義務づけられています。d.電話での通話に関して、その声や通話内容から個人を特定できる可能性がある場合、個人情報に該当します。",
    tag="法規・倫理",
)

db = SessionLocal()
model132 = QuestionModel(
    question_text="個人情報保護法の説明として、最も適切な選択肢を1つ選べ。",
    correct_answer="b.匿名加工情報を作成した場合、その情報に含まれる個人に関する情報の項目を公表する義務がある。",
    choices=[
        "a.個人情報として保護されるための条件の1つに機密性があるため、既にウェブなど一般向け媒体で公表されている個人に関する情報は、個人情報保護法の保護の対象とならない。",
        "b.匿名加工情報を作成した場合、その情報に含まれる個人に関する情報の項目を公表する義務がある。",
        "c.外国に住む外国籍の人の個人情報は、日本の個人情報保護法の保護の対象とならない。",
        "d.コールセンターで録音した顧客と会話内容は、原則として個人情報に該当しない。",
    ],
    commentary="匿名加工情報を作成した場合、その情報に含まれる個人に関する情報の項目を公表する義務があります。a：利用目的や他の個人情報との照合によっては個人の権利利益の侵害につながるリスクがあることから、個人情報保護法により、公知の情報も保護の対象になります。c：日本にある個人情報取扱事業者及び政機関などが取り扱う個人情報は、居住地や国籍にかかわらず、個人情報保護法による保護の対象となり得ます。d：電話での通話に関して、その声や通話内容から個人を特定できる可能性がある場合、個人情報に該当します。",
    tag="法規・倫理",
)

db = SessionLocal()
model133 = QuestionModel(
    question_text="個人情報の利用に関して、最も適切な選択肢を1つ選べ。",
    correct_answer="a.個人情報取扱事業者は、オプトアウト制度を利用することにより、事前に本人の同意を得なくても、個人データを第三者に提供することが可能なケースがある。",
    choices=[
        "a.個人情報取扱事業者は、オプトアウト制度を利用することにより、事前に本人の同意を得なくても、個人データを第三者に提供することが可能なケースがある。",
        "b.個人情報にあたる箇所をマスキングすることで加工したものは、仮名加工情報と呼ばれ、これは匿名加工情報に比べて匿名化の程度が低い。",
        "c.匿名加工情報は他の種類の個人情報と照らし合わせない限り、個人を特定できないことが要請されている。",
        "d.仮名加工情報にするためには、他の情報と照らし合わせても個人を特定できないように加工しなければいけない。",
    ],
    commentary="オプトアウト制度とは、個人情報を第三者提供するにあたって、その個人情報を持つ本人が反対をしない限り、個人情報の第三者提供を認める制度です。個人情報取扱事業者は、オプトアウト制度を利用することにより、事前に本人の同意を得なくても、その個人データを第三者に提供可能です。b、d：仮名加工情報とは、個人情報から、個人を特定できる情報を削除し、単体では個人を特定できないように加工した情報として定義されています。マスキングをしただけで、仮名加工情報にはなりません。一方で、他の情報と照らし合わせると個人を特定できる可能性が許されています。c：匿名加工情報は、復元して特定の個人を識別することができないようにしなければいけません。よって、他の種類の個人情報と照らして個人を特定できる場合は、匿名加工情報にはなりません。",
    tag="法規・倫理",
)

db = SessionLocal()
mode134 = QuestionModel(
    question_text="経済産業省により公表されている「カメラ画像利活用ガイドブックver3.0」について、最も適切な選択肢を1つ選べ。",
    correct_answer="c.カメラ画像から形状認識技術などを用いて通行人の形のみ判別し、顔の特徴などを識別しない場合、通行人の数を計測したカウントデータは個人情報としてみなされない。",
    choices=[
        "a.カメラ画像に顔の一部が映り込んでいる場合は個人情報保護の対象とはなることがない。",
        "b.日本国内で公共空間に設置された防犯カメラに関する案内指示などは、多言語化することが必要ではなく、明確な日本語で表示することが望ましい。",
        "c.カメラ画像から形状認識技術などを用いて通行人の形のみ判別し、顔の特徴などを識別しない場合、通行人の数を計測したカウントデータは個人情報としてみなされない。",
        "d.カメラ画像から、性別や年齢といった属性情報を抽出し、それに基づいて被写体にカスタマイズした広告を表示する際、元のカメラ画像を速やかに消去すれば、公表や本人への通知は必要ではない。",
    ],
    commentary="選択肢cが正しい解答である。この場合、カメラ画像から得られる情報単体では特定の個人は識別できず、かつ、それと紐づけることで個人を特定できるような情報を取得していません。a：顔の一部のみ映り込んでいても、それを他の情報(例えば別の時に撮影された同じ人物の顔や生活の様子)と照らし合わせることで個人を特定できる可能性があり、個人情報保護の対象になり得ます。b：カメラの設置を公表する掲示物は、目のつきやすい場所に掲示する必要があり、そして、必要に応じて日本語だけでなくイラストを用いた工夫や多言語化の対応が望まれます。d.カメラ画像から、性別や年齢といった属性情報を抽出する時点で「個人情報の利用」に該当しており、個人情報取扱事業者として、利用目的を公表したり、本人に通知したりする義務が発生します。",
    tag="法規・倫理",
)

db = SessionLocal()
mode135 = QuestionModel(
    question_text="データ活用の例として、最も不適切な選択肢を1つ選べ。",
    correct_answer="d.安心して子供を公園で遊ばせられるように、自治体が公園の防犯用監視カメラの画像を希望する保護者のみ公開した。",
    choices=[
        "a.ImageNetから、個人が無断で画像データをダウンロードし、それを用いて畳み込みニューラルネットワークを訓練した。後ほど、この一連のプロセスを自分のYouTubeチャネルで解説した。",
        "b.政府が調査、集計、公開を行っている人口動態データを、民間企業のデータサイエンティストがデータ分析案件に活用した。",
        "c.講師が、DBPediaから抽出した構造化データを自分が担当する大学のデータサイエンス講義の題材として使った。",
        "d.安心して子供を公園で遊ばせられるように、自治体が公園の防犯用監視カメラの画像を希望する保護者のみ公開した。",
    ],
    commentary="選択肢dが誤った内容である。経産省が公表している「カメラ画像利活用ガイドブックver3.0」において、プライバシーに配慮したカメラ画像の利活用について検討が進みました。一般的に、公開を伴わなくても、カメラ画像の撮影(取得)自体でも、プライバシーや肖像権の侵害について問われる場合があります。違法とされるかどうかは、情報の性質、取得、利用の目的と態様など個々の状況により判断されます。カメラ画像を適法に利用するためには以下の点を考慮する必要があります。・カメラ画像を利用する目的が正当であり、撮影の必要性があること・撮影方法、手段や利用の方法が相当であること防犯カメラには個人の顔や姿、行動や生活状況を推測できる私物が写っています。一般的な防犯カメラの設置に関しては、「取得の状況から見て利用目的は明らか」であるため、上記項目に違反せず、原則として利用目的の通知・公表は不要とされます。「防犯カメラ作動中」の札が店舗や公共施設の入り口などの設置場所に掲示され、防犯カメラによって個人情報が取得されていることが通行人に容易に認識可能な措置が取られているのがほとんどです。一方で、防犯カメラの画像を公開するとなると、管理上追跡できなくなり、(第三者による)必要な期間外でのデータの保存、同意を得ないで第三者への提供、生活者の情報の目的外での利用を可能にしてしまうなど、いくつもの項目に該当してしまい、公開は不適切です。よって選択肢dは誤りです。選択肢a~cは全てオープンデータを利活用している例です。オープンデータを取得して営利、非営利の目的で使用することが可能です。",
    tag="法規・倫理",
)

db = SessionLocal()
mode136 = QuestionModel(
    question_text="AIの成果物と著作物の関係について、最も不適切な選択肢を1つ選べ。",
    correct_answer="d.プログラムの作成の手段であるプログラム言語、プロトコール、アルゴリズム、規約及び解法は、「プログラム著作物」に相当する。",
    choices=[
        "a.著作権法には「著作物の例示」という規定があり、それによると「プログラムの著作物」が存在する。",
        "b.学習済みモデルのパラメータは、一定条件を満たせば、著作権法上の保護を受けられる可能性がある。",
        "c.学習済みモデルであっても、誰が書いても同じ内容になる簡単なプログラムは、創作性が認められず、プログラム著作物にはあたらないとされる可能性が高い。",
        "d.プログラムの作成の手段であるプログラム言語、プロトコール、アルゴリズム、規約及び解法は、「プログラム著作物」に相当する。",
    ],
    commentary="選択肢dが誤った内容である。プログラム言語、プロトコール、アルゴリズム、規約及び解法は、「プログラム著作物」に該当せず、著作権法による保護を受けません。(著作権法10条3項)著作物であるための条件(著作権法2条1項)・表現したもの(表現物)であること・思想又は感情を表現したものであること・創作的に表現した(創作性を有する)ものであること・文芸、学術、美術又は音楽の範囲に属する表現であることa：一定条件(十分に創作性が認められる)を満たす場合、人間が書いたプログラムの「表現物」は著作物として保護されることがあります。しかし、その作成に用いられたプログラミング言語やアイデアなどは保護の対象外です。設計書やユーザー説明書などは著作物として保護されることがあります。b、ｃ：明確な基準が存在しないものの、一定条件を満たす場合、学習済みモデル(またはその学習済みパラメータ)は著作物として保護されます。",
    tag="法規・倫理",
)

db = SessionLocal()
mode136 = QuestionModel(
    question_text="著作権法に関する記述として、最も適切な選択肢を1つ選べ。",
    correct_answer="d.個人の著作者の著作権が存続する期間は、原則として著作者の死後70年間である。",
    choices=[
        "a.成果物が職務著作に該当する場合、原則として従業員と所属する法人の共同著作権となる。",
        "b.AIモデルを実装するためにPythonで書いたソースコードは、著作権法の保護対象になることはない。",
        "c.著作権は、著作物を創作後に文化庁への登録をもって成立する。",
        "d.個人の著作者の著作権が存続する期間は、原則として著作者の死後70年間である。",
    ],
    commentary="選択肢dが正しい解答である。a：職務著作とは、企業の従業員がその職務に関連して著作物を創作する場合のことを指しています。原則として職務著作の著作者は法人その他の使用者となります。b：使用されるプログラミング言語は著作物にはなりませんが、創作性などの条件を満たせば、書かれたプログラム自体は「プログラムの著作物」として保護されることがあります。c：特許権と異なり、著作権の場合は登録をしなくても著作物を創作した時点で著作権が成立します。",
    tag="法規・倫理",
)

db = SessionLocal()
mode137 = QuestionModel(
    question_text="",
    correct_answer="",
    choices=[
        "",
        "",
        "",
        "",
    ],
    commentary="",
    tag="法規・倫理",
)

db = SessionLocal()
mode138 = QuestionModel(
    question_text="(ア)と(イ)にあてはまる組み合わせとして、最も適切な選択肢を1つ選べ。AI開発プロジェクトにおいて、(ア)およびその生成に用いた(イ)の保護が契約の重要な論点となることが多い。",
    correct_answer="c.(ア)学習済みモデル　(イ)学習用データセット",
    choices=[
        "a.(ア)学習済みモデル　(イ)取扱説明書",
        "b.(ア)ソースコード　(イ)プログラミング言語",
        "c.(ア)学習済みモデル　(イ)学習用データセット",
        "d.(ア)ソースコード　(イ)プロトコル",
    ],
    commentary="選択肢cが正しい解答である。特許権や著作権など知的財産権の保護は、AI開発の契約において必須の課題です。学習済みモデルなどの成果物について、ユーザーと開発者の間で誰がどのような権利を持つのかが論点となります。選択肢cの学習用データセットとは、生データを分析や機械学習に使いやすい形に変換した二次元な加工データです。このような変換または加工の例として、欠損値の処理、正解ラベルの付与、画像のリサイズなどが挙げられます。学習済みモデルとは、学習用データセットを用いて訓練を行った後の推論プログラムのことです。学習で得られた学習済みパラメータが組み込まれており、新しく入力されたデータに対して一定の制度で推論や予測ができます。「学習済みモデル」は、大きく分けてプログラムと学習パラメータの2つの部分から成り立ちます。プログラムには十分な創作性が認められる場合、著作権で保護される対象にあります。学習済みパラメータは、人間による「創作意図」と「創作的寄与」を示せば、コンピュータを道具として創作した著作物として肯定される見解があります。",
    tag="法規・倫理",
)

db = SessionLocal()
model139 = QuestionModel(
    question_text="学習を終えた機械学習のモデルを「学習済みモデル」と呼ぶ。機械学習をビジネスに利活用する際に、学習済みモデルの権利を適切に保護しなければならないが、これについて、最も不適切な選択肢を1つ選べ。",
    correct_answer="c.日本の法律では、機械学習のために他者の著作物を複製することは原則として認められていない。",
    choices=[
        "a.AIモデルの学習に用いられた生データや学習用データセットの提供者は、基本的に著作者としては認められない。",
        "b.AIには思想または感情がないため、AIが生成した表現は著作物として保護の対象にならない。",
        "c.日本の法律では、機械学習のために他者の著作物を複製することは原則として認められていない。",
        "d.誰が書いても同じ簡単なプログラムなどは、プログラム著作物にはあたらない可能性がある。",
    ],
    commentary="選択肢cが誤った内容である。著作権法では、機械学習など「情報解析」のためであれば、他人の著作物を複製しても問題ないと規定されています。a：AI(人口知能)の著作者は原則としてモデルの作成者です。データの単なる提供者は著作者として認められません。b：著作物は、思想又は感情を創作的に表現した表現物であることが求められます。d：プログラムにおける記述のオリジナリティや表現のバリエーションが広がれば広がるほど、創作性が認められやすく、プログラム著作物として保護を受けられる可能性が高くなります。逆に言うと、誰が書いても同じ内容になる簡単なプログラムなどは記述の選択肢が乏しいため、創作性が認められず、プログラム著作物にはあたらない可能性があります。",
    tag="法規・倫理",
)

db = SessionLocal()
model140 = QuestionModel(
    question_text="著作権法に関する説明として、最も適切なものを1つ選べ。",
    correct_answer="d.共同著作権が第三者によって無断で利用された場合、共同者全員の同意が得られなくても差し止めを請求できる。",
    choices=[
        "a.共同著作権の持ち分は、共同者の過半数の同意が得られない限り譲渡できない。",
        "b.法人が著作の名義を有する著作権は、法人が解散登記するまで存続する。",
        "c.共同著作権に関して、全ての共有者の合意が取れなくても行使できる。",
        "d.共同著作権が第三者によって無断で利用された場合、共同者全員の同意が得られなくても差し止めを請求できる。",
    ],
    commentary="選択肢dが正しい解答である。記述の通り、共同著作権が侵害された場合、共同者のうちの誰でも差し止めを請求できます。a、c：共同著作権は、共有者全員の同意を得て初めて著作権の行使および譲渡が可能です。b：法人などの団体が著作の名義を有する著作権は、著作物の公表後70年を経過するまで存続します。",
    tag="法規・倫理",
)

db = SessionLocal()
model141 = QuestionModel(
    question_text="2019年1月に実施された改正著作権法にもとづいて、著作物を学習用データとして取り扱う時の条件として、最も適切なものを1つ選べ。",
    correct_answer="d.非営利目的で他社の著作物を複製し加工した成果物が、著作権の利益を不当に害する場合は、著作権侵害に当たる可能性がある。",
    choices=[
        "a.他者が作成したデータの記録や編集は、コンピュータによる情報解析を目的とする場合に禁止されている。",
        "b.インターネット上で公開されているデータを無断でダウンロードしたり、加工したりすることが認められていない。",
        "c.インターネット上に公開されている他者の著作物を複製してデータセットを作成した場合、そのデータセットを用いて訓練させた機械学習モデルは、営利目的での利用が認められない。",
        "d.非営利目的で他社の著作物を複製し加工した成果物が、著作権の利益を不当に害する場合は、著作権侵害に当たる可能性がある。",
    ],
    commentary="選択肢dが正しい解答である。当該著作物の種類及び用途に当該利用の態様に照らし著作権者の利益を不当に害することとなる場合には、それらのデータを無断で利用したり、販売したりすることは著作権侵害に当たる」(著作権法第30条の4より引用)a：コンピュータなどを用いて情報解析(大量の情報から言語、音、映像などを抽出し、比較、分類などの統計的な解析)を行うことを目的とする場合、他者が作成したデータの記録(著作物)を複製・記録・翻案することが認められることがあります(著作権法第47条の7)。b：AIモデルを開発するために、ウェブからデータをダウンロード、加工することは原則として問題なく行えるようになりました(著作権法第30条の4)。c：営利目的の機械学習モデルであっても、モデルの訓練には、公開されている著作物を複製して作ったデータセットの使用が可能です(著作権法第30条の4)。例えば、権利者から公に提供されている画像データをダウンロードし、複製し、画像認識モデルの学習用データを用いて学習した画像認識モデルを販売することは適法となります。",
    tag="法規・倫理",
)

db = SessionLocal()
model142 = QuestionModel(
    question_text="特許権を取得することにより、自らの特許発明の実施を独占できるとともに、第三者による特許発明の無断実施を排除できるようになる。特許法において、「特許発明の実施をする」に該当する内容として、最も不適切な選択肢を1つ選べ。",
    correct_answer="b.新しい発明を行う。",
    choices=[
        "a.同じ生産方式で物を生産する。",
        "b.新しい発明を行う。",
        "c.発明した物を輸出する。",
        "d.同じ生産方式で生産した物を使用する。",
    ],
    commentary="選択肢bが誤った内容である。「特許発明の実施をする」とは「発明を行う」意味ではありません。「実施をする」は、特許権の対象が「物の発明」である場合、対象となる物を生産、使用、譲渡、輸出又は輸入するなどの行為を指します。特許権の対象が「物を生産する方法の発明」である場合、対象となる生産方法を用いて物を生産、または生産した物を使用、譲渡、輸出又は輸入するなどの行為を指します。",
    tag="法規・倫理",
)

db = SessionLocal()
model143 = QuestionModel(
    question_text="特許権に関する説明として、最も適切なものを1つ選べ。",
    correct_answer="d.特許制度の目的の1つは、所有者を明確にしつつ、社会の中で発明を活用しやすい仕組みを整えることである。",
    choices=[
        "a.特許権における先願主義とは、一番先に発明を開始した人に特許を認める制度である。",
        "b.特許権は発明の完成の時点から20年で終了となる。",
        "c.人工知能によって発明されたものは、特許権の対象外と定められている。",
        "d.特許制度の目的の1つは、所有者を明確にしつつ、社会の中で発明を活用しやすい仕組みを整えることである。",
    ],
    commentary="選択肢dが正しい解答である。発明や提案は目に見える形がないため、誰が所有しているのかが曖昧です。先行発明について知識を十分に持たないままでは、無駄な研究や投資を行うリスクがあり、結局社会全体にとって不利益をもたらします。そこで所有者を明確にした上で、他の人が適切に発明を活用できる仕組みを整えることが特許制度の目的の1つです。a：特許権における先願主義とは、一番先に出願した人に特許を認める制度です。b：特許権は、「発明の完成」ではなく、「特許出願」の日から20年で終了となります。c：人工知能によって発明されたものでも、人間の関わりの内容や特許を満たしているかどうかによって、特許権の対象となる場合があります。例えば、GPT-3のような高性能AIを用いてソースコードを生成する能力を有し、ソースコードを書くAIを含むシステムを設計したのが人間であれば、権利が認められる要因となり得ます。(※たとえ話であり、実際にこのようなケースが存在したとは限りません)",
    tag="法規・倫理",
)

db = SessionLocal()
model144 = QuestionModel(
    question_text="特許を受ける権利に関して、最も不適切な選択肢を1つ選べ。",
    correct_answer="a.通常実施権を持つ者のみが、特許権侵害に対する差し止めを請求できる。",
    choices=[
        "a.通常実施権を持つ者のみが、特許権侵害に対する差し止めを請求できる。",
        "b.特許を受ける権利は発明者以外でも取得できるケースがある。",
        "c.特許権を使ってできることは主に、特許発明の実施と特許権の実施承諾といえる。",
        "d.特許を受ける権利は、発明と同時に発生する。",
    ],
    commentary="選択肢aが誤った内容である。特許権者または専用実施権者は、自己の特許権または専用実施権を侵害する者に差し止めを請求することができます。(特許法第100条)。よって、「通常実施権を持つ者のみ」が誤りです。b、c：特許権を取得することにより、自らの特許発明の実施を独占し、第三者による特許発明の無断実施を排除できると同時に、特許権の実施承諾ができるようになります。「特許権の実施承諾」とは、特許権者が、他人に自己の有する特許発明を実施する権利を承諾することです。(注意)「実施承諾」と選択肢bにある「発明者以外が特許を受ける権利」は異なります。「発明者以外が特許を受ける権利」とは、発明者以外が「出願人」となることです。例えば、職務発明の場合、発明者は従業員本人ですが、出願人は会社であることがあります。d：記述の通り、特許を受ける権利は、発明と同時に発生します。",
    tag="法規・倫理",
)

db = SessionLocal()
model145 = QuestionModel(
    question_text="特許権の取得に関する説明として、最も適切なものを1つ選べ。",
    correct_answer="a.特許法上、複数人が同じ発明をほぼ同時に進めている場合、一番先に発明の出願をした人に特許が認められる。",
    choices=[
        "a.特許法上、複数人が同じ発明をほぼ同時に進めている場合、一番先に発明の出願をした人に特許が認められる。",
        "b.生データは特許法に保護されないのに対して、それを人が工夫をして加工・集計した学習用データセットは特許法による保護対象となりうる。",
        "c.人工知能は発明者になることができず、発明者になることができるのは、個人と法人のみである。",
        "d.複数人が共同でプログラムを開発しても、そのうちの代表者一人だけが、発明者になることができる。",
    ],
    commentary="選択肢aが正しい解答である。記述の通り、特許権における先願主義により、一番先に出願した人に特許を認める制度です。b：学習用データセットも、単に収集したデータへの操作に過ぎないため、発明に該当せず、従って特許の対象になりません。c：特許法上、人間のみが発明者になることができます。AIや法人が発明者になることができません。d：複数人の共同作業によりプログラムを開発し、その成果物が発明として認められた場合、全員が発明者になりえます。",
    tag="法規・倫理",
)

db = SessionLocal()
model146 = QuestionModel(
    question_text="特許法の説明に関して、最も適切な選択肢を1つ選べ。",
    correct_answer="b.特許を受ける権利は、発明の完成と同時に発生する。",
    choices=[
        "a.新規性、進歩性、産業上利用可能性の3つの条件を満たすことは、特許権を取得するための十分条件である。",
        "b.特許を受ける権利は、発明の完成と同時に発生する。",
        "c.職務発明の特許を受ける権利は、発明を行った従業員または所属企業に帰属する。",
        "d.特許権者である場合、専用実施権を設定した以降でも、自ら特許権を実施可能である。",
    ],
    commentary="選択肢がbが正しい解答である。記述の通り、特許を受ける権利は発明の完成と同時に発生します。a：特許の要件である、新規性、進歩性、産業上利用可能性を全て満たしたとしても、公の秩序、善良の風俗または公衆の衛生を害する恐れがある発明については特許をうけることができません。c：職務発明とは、企業の従業員が、企業の業務の範囲に属し、企業の設備等を利用して、現在または過去の職務として実現した発明として定義づけられています。職務発明の特許を受ける権利は、発明をした従業員にのみ帰属します。一方で、企業にはその発明を実施する通常実施権が認められます。d：専用実施権を設定すると、自ら特許発明の実施もできなくなります。",
    tag="法規・倫理",
)

db = SessionLocal()
model147 = QuestionModel(
    question_text="不正競争防止法の内容について、最も適切な選択肢を1つ選べ。",
    correct_answer="a.顧客リストの盗用は不正競争行為に該当する。",
    choices=[
        "a.顧客リストの盗用は不正競争行為に該当する。",
        "b.不正競争防止法上の営業秘密として保護されるための要件の1つである「非公知性」とは、情報の保有者以外の人がその情報にアクセス不可能な状態を保証することを指す",
        "c.学習済みモデルを生成した場合、この学習済みモデルは不正競争防止法上の営業秘密として保護される可能性はあるが、生成ノウハウが営業秘密の保護対象になることはない。",
        "d.不正競争防止法上の営業秘密として保護されるために、必ずしもマル秘表示やアクセス制限をかける必要があるとは限らない。",
    ],
    commentary="選択肢aが正しい解答である。不正競争防止法が禁じている「不正競争」には、営業秘密の不正取得行為が含まれます。顧客リストやノウハウは営業秘密に該当するため、これらの盗用は不正競争にあたる行為です。b、d：営業秘密とは以下の要件を満たすものとして定義されています。➀秘密管理性：秘密として管理され、秘密情報であることが分かるように、アクセス制限や㊙表示などの秘密管理措置がなされていること➁有用性：有用な技術または営業上の情報であること、かつ保有者の管理下以外では一般的に入手できないこと➂非公知性：公然と知られていないことc：技術を開発するノウハウは営業秘密に該当します。",
    tag="法規・倫理",
)

db = SessionLocal()
model148 = QuestionModel(
    question_text="不正競争防止法の各項目に関して、最も適切な選択肢を1つ選べ。",
    correct_answer="c.営業秘密を含む情報は、どの従業員からみても秘密にしたいことが明確に分かる程度の管理措置が求められている。",
    choices=[
        "a.営業秘密に該当し、ビジネスに有益な情報を含むデータの1つとして、限定提供データがあげられる。",
        "b.営業秘密の侵害に対する措置として、差止請求権、損害賠償請求権などの救済が行われるが、刑事罰が科せられることはない。",
        "c.営業秘密を含む情報は、どの従業員からみても秘密にしたいことが明確に分かる程度の管理措置が求められている。",
        "d.ネガティブ・インフォメーションは営業秘密として保護される対象に含まれない。",
    ],
    commentary="選択肢cが正しい解答である。営業秘密に課される条件の1つは「秘密管理性」です。従業員からみて、その情報が秘密としたい情報であることがわかる程度に、アクセス制限や㊙表示などの秘密管理措置がなされていることを指します。a：限定提供データは特許法・著作権法に保護されず、営業秘密にも該当しないデータです。その定義は以下の通りです「業として特定の者に提供する情報として電磁的方法により相当量蓄積され、および電磁的な方法によって管理されている技術上または営業上の情報」例えば、企業の取引先とのウェブ会議の電子ファイルで保存されたログは上記の条件をみたし、限定提供データにあたります。b：営業秘密の侵害に対する措置として以下をとることができます。・民事的救済：差止請求権、損害賠償請求権、信用回復措置・営業秘密侵害行為などについては刑事罰が科されることもあるd：例えば、失敗した実験データなど、ネガティブ・インフォメーションも営業秘密として保護されます。",
    tag="法規・倫理",
)

db = SessionLocal()
model149 = QuestionModel(
    question_text="知的財産権に関して、最も不適切な選択肢を1つ選べ。",
    correct_answer="a.知的財産権と著作権の違いとは、前者は権利を取得するために申請や登録など一定の手続きが必要であるのに対し、後者は著作物が創られた時点で付与されること。",
    choices=[
        "a.知的財産権と著作権の違いとは、前者は権利を取得するために申請や登録など一定の手続きが必要であるのに対し、後者は著作物が創られた時点で付与されること。",
        "b.特許権は知的財産権の一種である。",
        "c.営業秘密を保護するために、知的財産権として認められる必要がない。",
        "d.企業名やサービスの正式なロゴは知的財産権である。",
    ],
    commentary="選択肢aが誤った内容である。知的財産権には著作権が含まれます。よって選択肢aのように、知的財産権と著作権を異なる概念として記述することが不適切です。選択肢aの記述内容を改めて確認しましょう。特許権などの産業財産権(知的財産権の一種)は、権利を取得するために申請や登録などの手続きが必要です。詳しくは文化庁のウェブサイトをご参照ください。一方で、著作権は無方式主義に従っており、登録が不要で、著作権が創られた時点で付与されます。知的財産権とは、知的な創作活動によって成果物を創り出した人には、一定期間にわたって付与される権利です。創作物が他人に無断で利用されないように保護することが目的です。知的財産権は大きく分けて2種類あります。➀知的創造物：創作意欲の促進を目的とした権利(例：特許権、著作権)➁営業上の標識：使用者の信用維持を目的とした権利(例：商標権)c：平成30年に、不正競争防止法が改正され、営業秘密など、知的財産権が認められていない一部のデータの保護に関しても一定の対策ができるようになりました。d：知的財産権に商標権が含まれます。問題文にある会社名、サービス名またロゴ以外に、キャラクターやコピーも商標権の対象として挙げられます。商標権は、商標登録がされると、出願人に付与されます。商標を保護することによる、商標の使用をする者の業務上の信用の維持に寄与します。",
    tag="法規・倫理",
)

db = SessionLocal()
model150 = QuestionModel(
    question_text="AIをビジネスに活用する上で、データやモデルの知的財産権を正しく理解することが重要である。最も適切な選択肢を1つ選べ。",
    correct_answer="d.業として特定の者に提供する情報であり、電磁的方法により相当量蓄積されたデータは、不正競争防止法の限定提供データとして保護の対象になることがある。",
    choices=[
        "a.従業員が職務命令に反して開発したプログラムは、職務説明に該当することはないため、そのプログラムが所属する企業の事業に有用であることが明らかになったとしても、企業は通常実施権を得ることができない。",
        "b.学習済みモデルが営業秘密として保護されるためには、暗号化などにより秘密管理されているだけでなく、そのモデルが新規なものとして特許出願されていることが必須要件とされている。",
        "c.収集した生データは、原則として著作物として保護の対象になる。",
        "d.業として特定の者に提供する情報であり、電磁的方法により相当量蓄積されたデータは、不正競争防止法の限定提供データとして保護の対象になることがある。",
    ],
    commentary="選択肢dが正しい解答である。特許法と著作権法に保護されず、営業秘密にも該当しないデータは限定提供データとして保護されることがあります。例えば、企業間で共有されることで、サービス・製品の改善が期待されるようなデータが該当します。a：職務命令に反していたとしても、従業員の身分や使用者の発明への寄与により職務発明が成立することがあります。職務命令が成立した場合、従業員が所属する企業は通常実施権を取得できます。b：学習済みモデルが営業秘密として保護されるためには、暗号化などにより秘密管理される必要があります。特許出願は要件に入りません。c：創作性がなく、収集しただけの生データは著作権法上の著作物として保護の対象になりません。体系的に構成したデータセットは、創作性が認められ、著作権法上の著作物として保護の対象になります。",
    tag="法規・倫理",
)

db = SessionLocal()
model151 = QuestionModel(
    question_text="学習用データセットを用意するのにあたっての留意点について、不適切な選択肢を1つ選べ。",
    correct_answer="d.第三者から受領した個人情報を用いてデータセットを作成する場合、その個人情報が取得された経緯を当事者同士で共有することはプライバシー違反に該当する。",
    choices=[
        "a.第三者の著作物を複製し、モデルの開発用の学習用データに使用する場合、一般的に著作権法上合法であっても、制約を受ける可能性がある。",
        "b.2019年に実施された改正著作権法においては、目的が営利・非営利を問わず、公開されている他者の著作物を複製してデータセットを作ったり、そのデータセットで機械学習のモデルを開発したりすることが原則認められるようになった。",
        "c.ウェブ上の画像やテキストをスクレイピングするというデータ収集手法は、データ・プライバシーに対する社会の懸念が増えていることにより、法的にリスクが高くなっている。",
        "d.第三者から受領した個人情報を用いてデータセットを作成する場合、その個人情報が取得された経緯を当事者同士で共有することはプライバシー違反に該当する。",
    ],
    commentary="選択肢dが誤った内容である。第三者から受領した個人情報を用いてデータセットを作成する場合、その個人情報が取得された経緯を必ず確認しなければいけません。a：例えば、不正競争防止法で定義されている営業秘密に当たるデータを利用している場合、著作権法で認められても、利用制限を受ける可能性があります。b：改正著作権法の実施により記述の通りの内容になりました。c：スクレイピングが違法に当たる可能性がある場合があります。例えば、ウェブの利用規約の中にスクレイピングを禁止する条項が含まれている場合、ウェブサイトに高頻度でアクセスしたため、サーバーがダウンし、ウェブサイトを運営する企業などに業務妨害を及ぼした場合、スクレイピングを通じて個人情報を取得し、プライバシー・ポリシーや個人情報保護方針に従わなかった場合が挙げられます。",
    tag="法規・倫理",
)

db = SessionLocal()
model152 = QuestionModel(
    question_text="ディープフェイクの説明として、最も適切な選択肢を1つ選べ。",
    correct_answer="d.2つの画像(動画)を生成することは、ディープフェイクを用いることで実現できる。",
    choices=[
        "a.SNSでは表現の自由を守るために、ディープフェイクの適用を禁止する規制が導入されていない。",
        "b.海外ではディープフェイクに関する倫理問題が報告されているが、日本国内で刑事法や民事法に触れた事例はまだ存在しない。",
        "c.ディープフェイクはAIによって作成されている以上、AIを使って検出することは不可能であることは情報科学の理論にもとづいて証明されている。",
        "d.2つの画像(動画)を生成することは、ディープフェイクを用いることで実現できる。",
    ],
    commentary="選択肢dが正しい解答である。ディープフェイクは一般的に敵対的生成ネットワーク(GAN)などの深層生成モデルを用いて、本物に限りなく近い画像、動画、音声、文章などの「フェイクコンテンツ」を生み出す技術を指します。2つの画像(動画)を結合させて実在しない画像(動画)を生成することは、ディープフェイクを用いることで実現できます。a：ディープフェイクの画像や動画は、facebookやInstagramで禁止されています。b：日本では、過去にディープフェイクの悪用で逮捕が実施された例があります。例えば、フェイクポルノは、名誉棄損、著作権法違反、わいせつ物頒布罪などの刑事罰の対象に該当する可能性があります。c：ディープフェイクを検出できるAIモデルを訓練する研究が行われています。例えば、実際フェイク動画を見破るツールが開発されており、Microsoft社のMicrosoft Video Authenticatorがその一例です。",
    tag="法規・倫理",
)

db = SessionLocal()
model153 = QuestionModel(
    question_text="ディープフェイクの説明として、最も不適切な選択肢を1つ選べ。",
    correct_answer="b.社会に脅威を及ぼす可能性が高い技術であるため、日本国内の一部の自治体はその利用を完全に禁止している。",
    choices=[
        "a.ディープフェイクビデオやディープフェイクボイスなどが、選挙において競合する候補者に対するネガティブキャンペーンに用いられた事例が存在する。",
        "b.社会に脅威を及ぼす可能性が高い技術であるため、日本国内の一部の自治体はその利用を完全に禁止している。",
        "c.ディープフェイクを用いた偽動画は、現在スマートフォンのアプリを用いて誰でも簡単に作れるようになった。",
        "d.エンターテインメントや広告などの分野において、制作費用の削減に貢献することができる。",
    ],
    commentary="選択肢bが誤った内容である。ディープフェイクは、有益な使い方もあるので、自治体や政府の全体レベルとして完全に禁止することは現時点ではありません。a：例えば、米大統領の選挙期間中に、相手候補の印象を悪くする目的でディープフェイクを用いて偽造された動画が拡散されました。このようにディープフェイクが悪用されると、民主主義を脅かす恐れがあり、政府からSNS企業にディープフェイクの悪用の取り締りなど、対応の要請がなされています。c、d：一般のユーザーが容易にアクセスできるスマートフォンアプリが開発されており動画の中で顔の変換などができます。娯楽や制作などの目的での使用が想定されています。",
    tag="法規・倫理",
)

db = SessionLocal()
model154 = QuestionModel(
    question_text="捏造や改ざんなど不正なデータ処理に当たる行為として、最も当てはまる選択肢を1つ選べ。",
    correct_answer="b.店で実施したキャンペーンの効果を検証する分析業務を引き受けた。効果の有無を分かりやすく説明できた方が将来の案件の受注につながるため、全データのうち効果を説明しやすい期間のみ取り出して、それを使って検証を行った。報告書ではその期間を選んだ理由を明記せず、検証結果の説明だけを記述した。",
    choices=[
        "a.依頼先から受領したデータだけでは量が足りず、それを用いて学習した機械学習モデルの制度が不十分だった。そこで、データ拡張という手法を用いて、データをランダムに水増しした。再度モデルを学習したところ、予測モデルの制度が上昇したので、そのモデルを納品した。",
        "b.店で実施したキャンペーンの効果を検証する分析業務を引き受けた。効果の有無を分かりやすく説明できた方が将来の案件の受注につながるため、全データのうち効果を説明しやすい期間のみ取り出して、それを使って検証を行った。報告書ではその期間を選んだ理由を明記せず、検証結果の説明だけを記述した。",
        "c.店で実施したキャンペーンの効果を検証する分析業務を引き受けた。一部の属性を持つ買い物客にのみ、キャンペーンの効果が見られた。この考察結果とともに、該当する特定のデータ群だけを用いた検証結果を業務依頼先のクライアントに共有し、原因をこれから深堀りすることにした。",
        "d.機械学習モデルを構築するために受領したデータに欠損値が含まれるので、適切と判断した方法で欠損値を補填後、そのデータで機械学習モデルを開発し、納品した。顧客に補填値を決める手段を報告したが、補填した値を報告書に書かなかった。",
    ],
    commentary="選択肢がbが正しい解答である。説明がしやすくなるという理由のために、恣意的に一部のデータを用いてキャンペーンの効果を見せかけることは、捏造や改ざんに該当します。それ自体は検証を果たしたことにならないだけではなく、報告書に上記の行為を明らかにしなかったことが更なる不正行為に該当します。選択肢dにある、補填した値(これは通常多数あるため)を個別に報告することは、データ分析案件では通常しません。代わりに補填後(加工後)の学習用データセットを納品することがあります。",
    tag="法規・倫理",
)

db = SessionLocal()
model155 = QuestionModel(
    question_text="データ汚染(Data Poisoning)に関して、最も不適切な選択肢を1つ選べ。",
    correct_answer="b.画像データの特定の画素に加える変更は、慎重に観察してはじめて目線で気づけるくらい巧みなものである。",
    choices=[
        "a.AIモデルの学習データを収集または加工する工程の中でデータに加えられる攻撃である。",
        "b.画像データの特定の画素に加える変更は、慎重に観察してはじめて目線で気づけるくらい巧みなものである。",
        "c.データ汚染は悪用だけではなく、人間社会によって有益な使い方も可能である。",
        "d.摂動を加えたデータを学習データに乱入させると、それを学習したモデルは特定のクラスについて、入力データの誤分類をする可能性がある。",
    ],
    commentary="選択肢bが誤った内容である。データ汚染で加える変更は目視では確認できない程度のものです。a、d：データ汚染とは、AI・機械学習モデルの学習データに加えられる攻撃です。学習データの一部に「摂動」を加え、それをモデルに学習させることで、特定のクラスについて、入力データの誤分類を恣意的に引き起こします。b：画像データの場合、「摂動」とは、特定の画素(ピクセル)に目視では確認できないような微小な変更操作を加えることです。目視では認識できなくても、機械学習を「騙す」ことで、誤った判断をさせる可能性があります。c：データ汚染は人間社会のセキュリティを守るためにも使われます。例えば、顔写真の漏洩や悪用による様々な被害を防ぐために顔画像をウェブに投稿する前に、データ汚染(画像への摂動)でプライバシー保護の加工を行うツールが開発されています。",
    tag="法規・倫理",
)

db = SessionLocal()
model156 = QuestionModel(
    question_text="画像データに人間から見て変化がわからない程度のノイズや変更を加えることによって、機械学習に誤分類引き起こす可能性がある。このように摂動を加えたデータの名称として最も適切な選択肢を1つ選べ。",
    correct_answer="c.Adversarial Example",
    choices=[
        "a.Noisy Sample",
        "b.Deep Fake Example",
        "c.Adversarial Example",
        "d.Contaminated Example",
    ],
    commentary="選択肢cが正しい解答である。英語の'Adversarial Example'は、日本語でいうと敵対的サンプルです。これは、敵対攻撃によって作成されます。敵対攻撃とは、学習済みモデルがある入力に対して誤った出力をするように、入力データを恣意的に加工する(敵対的サンプルを作る)ことです。この場合、機械学習モデルを混乱させるような、人間の目で識別できない程度の微小なノイズを入力データに乗せます。他の選択肢は存在しない、誤った用語です。",
    tag="法規・倫理",
)

db = SessionLocal()
model157 = QuestionModel(
    question_text="データ偽造の問題点と対策に関して、最も不適切な選択肢を1つ選べ。",
    correct_answer="a.データを実際の値から勝手に変更する不正行為は、「捏造」という。",
    choices=[
        "a.データを実際の値から勝手に変更する不正行為は、「捏造」という。",
        "b.AIを芸術作品の模倣や再現に活用することは、故人への尊重や著作権に関する懸念を引き起こすことがある。",
        "c.偽造された画像や動画が明るすぎたり暗すぎたりするとき、それらをAIで検出することが困難になる。",
        "d.人間は文字よりも映像を信じやすいという心理的側面があるため、偽造された画像や動画を見かけると、それを疑うよりも信じて拡散しようとする傾向にある。",
    ],
    commentary="選択肢aが誤った内容である。無断でデータの値を変更することは、改ざん(改竄)と呼ばれます。捏造とは、存在しないデータを偽造することを指します。b：技術の進歩により、芸術作品を生成するAIが現れています。AIに画家や音楽家の「くせ」を学習させて、類似したスタイルの芸術作品を作らせることは、著作権違反と認定されません。しかし、倫理的な妥当性について、及び、著作権が認められた芸術家(故人を含めて)に対する尊重という観点から、問題があるとされています。c：画像サンプルの明暗が極端に外れている場合は、偽造画像を検出する学習済みAIが習得したパターンにあてはまりにくくなります。d：記述の通りです。",
    tag="法規・倫理",
)

db = SessionLocal()
model158 = QuestionModel(
    question_text="AI活用によって公平性が損なわれた下記の事例のうち、AIシステムが差別的な振る舞いをした事例として、最もあてはまらない選択肢を1つ選べ。",
    correct_answer="c.高度なAIを活用するためには、ある程度のデジタルリテラシー水準が必要である。貧困層にあたる人は十分なリテラシーに達成することが今困難であるため、デジタルデバイドが生じやすい。",
    choices=[
        "a.ある企業が開発したAI人事査定システムが、男性の従業員に有利に働くことが判明され、学習データに用いられた履歴書データや業務報告書を調査したところ、男女の比率が顕著に異なることがわかった。",
        "b.ある防犯AIシステムは特定の人種に対して犯罪率を高く予測する傾向があるように見える。モデル解釈ツールを用いて調査したところ、使用されたアルゴリズムは肌の色に重みをおいていることがわかった。",
        "c.高度なAIを活用するためには、ある程度のデジタルリテラシー水準が必要である。貧困層にあたる人は十分なリテラシーに達成することが今困難であるため、デジタルデバイドが生じやすい。",
        "d.性別や信仰などのセンシティブ属性に偏りを持った発言を多く学習したチャットボットが暴言を吐く事態となった。",
    ],
    commentary="選択肢cが誤った内容である。選択肢cの内容はAI活用に関連する社会問題ではありますが、AIそのものが差別的に振る舞った結果とは言えません。他の選択肢は全てデータの偏りやアルゴリズムバイアスなどによって引き起こされた不公平な結果です。",
    tag="法規・倫理",
)

db = SessionLocal()
model160 = QuestionModel(
    question_text="AIの学習データに潜むバイアスがAIの利用者と社会に及ぼす影響について、最も適切な選択肢を1つ選べ。",
    correct_answer="b.層化サンプリングを用いることで、サンプリングバイアスを減らす効果が期待できる。",
    choices=[
        "a.アップサンプリングまたはダウンサンプリングを使うことで、不均等なデータからバイアスを完全に排除することが示されている。",
        "b.層化サンプリングを用いることで、サンプリングバイアスを減らす効果が期待できる。",
        "c.アルゴリズムバイアスを防ぐ上で分析手法の一貫性を重要視すべきであるため、複数の手法で機械学習モデルを構築するのは推奨されない。",
        "d.データバイアスとは、モデルが特定の特徴量を強調して学習してしまうことである。",
    ],
    commentary="選択肢bが正しい解答である。母集団から無作為で標本抽出(サンプリング)を行った場合でも不均等データが生じる可能性があります。層化サンプリング(Stratifed Sampling)とは、母集団を予め複数の層に分け、各層の中から必要な数だけ無作為抽出する手法です。この手法によって母集団の特徴を反映しつつ、データの偏りを防止できることがあります。a：アップサンプリングは機械学習を用いた分類問題において不均衝なデータセット(クラス間でサンプルサイズが大きく異なる)を扱う場合、データ数の少ないクラスに対してデータの水増しを行う手法です。ダウンサンプリングはその逆で、データ数の多いクラスのサンプルに対してサンプリングを行い不均衝を改善する可能性があるものの、人為的なバイアスを及ぼすリスクもあります。c、d：モデルが特定の特徴量を強調して学習してしまうのは、アルゴリズムバイアスです。アルゴリズムバイアスはモデル(アルゴリズム)の振る舞いに要因があるため、複数の手法で機械学習モデルを構築し、それらの結果を比べることが推奨されます。データバイアスとは、不均衝なデータなど、データそのものの中に偏った特徴量が含まれることです。",
    tag="法規・倫理",
)

db = SessionLocal()
model161 = QuestionModel(
    question_text="XAI(Explainable AI;説明可能AI)の説明として、最も適切な選択肢を1つ選べ。",
    correct_answer="a.モデルによる予測や推論のプロセスの解釈性が比較的高い。",
    choices=[
        "a.モデルによる予測や推論のプロセスの解釈性が比較的高い。",
        "b.煩雑な処理を可能な限り削減し、可読性の高いソースコードで実装されている。",
        "c.人間によって分かりやすいように、特徴量を手動で抽出している。",
        "d.全てのAIシステムに、その仕組みを記述した多言語の説明書を添える義務がある。",
    ],
    commentary="選択肢aが正しい解答である。AIモデルの中身や出力結果の説明が難しい、というブラックボックス問題は、社会のAI技術へ不信を引き起こし、AIの社会実装を阻止する要素になりかねません。ブラックボックス性の解消に向けた取り組みとして、XAI(Explainable AI;説明可能AI)の研究開発が進められています。XAIとは出力結果に至った経緯や判断の根拠を、可視化や言葉などで人間がわかるように説明できるAIです。例えば、どの特徴量が予測に一番影響力があったのか、データの場合わけの閾値などを示すことが求められます。b：システムの裏側で動いているソースコードは、AIシステムのユーザーが見るものではないので、その可読性はXAIとは直接的に関係するとは言えません。c：「特徴量を手動で抽出すること」はXAIの条件ではありません。Grad-CAMのように画像認識の際にどのピクセルに着目しているのかを可視化させるXAIの取り組みが存在します。ｄ:多言語の説明書は現時点XAIの要件に含まれていません。",
    tag="法規・倫理",
)

db = SessionLocal()
model162 = QuestionModel(
    question_text="",
    correct_answer="",
    choices=[
        "",
        "",
        "",
        "",
    ],
    commentary="",
    tag="法規・倫理",
)

db = SessionLocal()
model163 = QuestionModel(
    question_text="近年、ディープラーニングの利活用を普及させる上で説明可能AI(Explainable Artificial Intelligence; XAI)が重要視されている。XAIが必要とされる理由として最も不適切な選択肢を1つ選べ。",
    correct_answer="b.XAIは人間と同じところに着目してAIを解釈するアプローチをとるため、人間と同程度の推論能力を目指す「強いAI」の実現に貢献する。",
    choices=[
        "a.AIによる判断の根拠を一般の人が理解できるように説明できれば、AIを安心に、安全に使用できるようになれる。",
        "b.XAIは人間と同じところに着目してAIを解釈するアプローチをとるため、人間と同程度の推論能力を目指す「強いAI」の実現に貢献する。",
        "c.AIによるご認識が生じた際に、その原因を特定し防止対策に寄与するため、モデルの精度の向上につながる。",
        "d.医療AIなどの高リスク分野において、AIによる予測の根拠を可視化できることは信頼性を保つために重要である。",
    ],
    commentary="選択肢bが誤った内容である。AIを説明可視化するためには、人間と同じところに着目して推論を行う必要は必ずしもありません。また、XAIは強いAIとは関係しません。強いAIとは人間と同じレベルの自律性や意思決定の能力を有する汎用型AIを指しており、現時点で実現されていません。他の選択肢はXAIのメリットに関する正しい記述です。a、d：利用者の健康安全や個人情報に関与するAIサービスでは、ブラックボックス問題は特に深刻であり、XAIの活躍が期待されています。c：AIの仕組みを説明できるようになると、モデルの設計の観点から予測精度の向上にもつながります。",
    tag="法規・倫理",
)

db = SessionLocal()
model164 = QuestionModel(
    question_text="モデルによる推論の根拠を説明しづらいことが、ディープラーニングの難点として挙げられているが、これを改善すべく、説明可能AI(Explainable AI;XAI)という研究が注目されている。XAIの目的として、最も適切な選択肢を1つ選べ。",
    correct_answer="d.推論の理由を可視化や自然言語で記述できるようになること。",
    choices=[
        "a.モデルのパラメータの数を減らして推論を行うこと。",
        "b.学習データ量を少なくしても、同程度の精度の推論をできるようになること。",
        "c.根拠の説明困難と引き換えに、推論をより高速に行えるようになること。",
        "d.推論の理由を可視化や自然言語で記述できるようになること。",
    ],
    commentary="選択肢dが正しい解答である。XAIの目的は、モデルによる推論の根拠を、人間がわかるように可視化したり自然言語で表現したりすることです。選択肢d以外の選択肢は、XAIの目的ではありません。b：要求するデータ量を減らせることは、開発コストを下げるには有効ですが、XAIの目的と直接関係するとは言えません。c：XAIはモデルの判断の根拠の説明を重視しており、それを犠牲にして推論の速度を優先することはXAIの目的に反します。",
    tag="法規・倫理",
)

db = SessionLocal()
model165 = QuestionModel(
    question_text="AIをビジネスや社会に活用する上で、透明性(Transparency)が重要な観点です。AIの透明性に関して、最も不適切な選択肢を1つ選べ。",
    correct_answer="b.最新のアルゴリズムほどAIの透明性が確保されやすい傾向にあるため、開発から時間が経っているアルゴリズムの使用を見直すべきである。",
    choices=[
        "a.透明性を高めるために、データセットの内容や加工法やモデルの学習の仕組みなどを記述したドキュメントを提示することが望ましい。",
        "b.最新のアルゴリズムほどAIの透明性が確保されやすい傾向にあるため、開発から時間が経っているアルゴリズムの使用を見直すべきである。",
        "c.AIの透明性の確保は、セキュリティや知的財産権の保護とトレードオフになる可能性が考えられる。",
        "d.AIによって人間を評価するシステムでは、評価対象者に対して、判断を行うのがAIであることを公表し、判断の根拠を説明することが好ましい。",
    ],
    commentary="選択肢bが誤った内容である。最新のアルゴリズムの透明性も高いとは限りません。実際、なぜ高い精度が得られるのか十分に理解されていないブラックボックスであることが多くあります。従って、透明性を確保するためには必ずしも最新のアルゴリズムが最適だと考えるのではなく、多くの活用実績があり、信頼性が高い従来のモデルも検討対象に入れるべきです。他の選択肢はAIの透明性に関する正しい記述です。a：AI、機械学習、データ分析において透明性とは、各プロセスが誰にでもわかるように説明できる状態を指します。c：透明性を確保するために情報公開を行う場合、情報セキュリティと知的財産権の保護とのバランスを考える必要があり、それを実現するための研究・議論が進められています。d：人事評価や採用判断、クレジットカードのスコアリングなどの結果は、対象者の生活と健康や安全に顕著な影響を及ぼすことがあります。AIが判断を行っていることを公表しないこと、あるいはAIのアルゴリズムが不透明であることは倫理的な問題があるとみなされます。例えば、学習データに偏りがある場合、AIの判断の公平性が疑問視されます。",
    tag="法規・倫理",
)

db = SessionLocal()
model166 = QuestionModel(
    question_text="AI倫理に関する取り組みの1つとして、FAT(Fairness Accountability Transparency)があります。FATの内容について、最も適切な選択肢を1つ選べ。",
    correct_answer="b.他の機械学習の手法に比べて、ニューラルネットワークは、透明性(Transparency)を実現することが困難である。",
    choices=[
        "a.公平性(Fairness)とは、不正競争防止法に反する行為をしないように配慮すること。",
        "b.他の機械学習の手法に比べて、ニューラルネットワークは、透明性(Transparency)を実現することが困難である。",
        "c.FATの3原則は、AIを開発するにあたり、守らなければいけない設計思想を記述している。",
        "d.説明責任(Accountability)とは、AIのアルゴリズムを一般的に理解可能な形で説明できるようにすること。",
    ],
    commentary="選択肢bが正しい解答である。FAT(Fairness Accountability Transparency)は国際的にAIの社会実装において留意すべき基準として認識されています。日本語では「公平性・説明責任・透明性」といいます。FATの「透明性」とは、AIモデルの構造、仕組み、処理プロセスを一般の人が理解できるようにすることです。様々な手法の中で、ニューラルネットワーク(ディープラーニング)は特にモデルの構造が複雑でブラックボックス性が高いので、その予測の根拠や結果を説明することが難しいです。a：FATの「公平性」とは、AIが不当なバイアスを社会に反映させることがないように配慮することです。AIや機械学習モデルを作成する段階で人種・性別・民族・文化などのセンシティブ属性に対する不公平を排除しなければなりません。選択肢にある「不正競争防止法」とは関係しません。c：FATは、AIを社会で運用するにあたり、遵守すべき設計思想の3つの原則であり、AIの開発に限ったものではありません。d：FATの「説明責任」とは、AIを用いた業務の内容や目的、不祥事が生じた場合の責任体制を開示する責任を指しています。AIの利用者は責任体制の開示を要求する権利があります。選択肢dは「透明性」の内容を記述しているので誤りです。",
    tag="法規・倫理",
)

db = SessionLocal()
model167 = QuestionModel(
    question_text="2018年5月に適用開始されたEU一般データ保護規則(GDPR)に関する説明として、最も不適切な選択肢を1つ選べ。",
    correct_answer="a.GDPRで認められているデータポータビリティの権利とは、EU域内に限って、収集した個人データを信頼性の高いクラウド技術などを活用して共有できる権利である。",
    choices=[
        "a.GDPRで認められているデータポータビリティの権利とは、EU域内に限って、収集した個人データを信頼性の高いクラウド技術などを活用して共有できる権利である。",
        "b.EUには拠点が全くなく、日本国内にのみ拠点を持つ企業でもGDPRが適用される可能性がある。",
        "c.GDPRでは、個人の氏名、所在地、クレジットカード情報、メールアドレス、クッキー情報などを個人情報とみなしている。",
        "d.EU域内へ個人データを移転させる際に、移転先の国が十分性認定を受けることで、手続きの一部が簡略される。",
    ],
    commentary="選択肢aが誤った内容である。GDPR(General Data Protection Regulation;EU一般データ保護規則)は、EUにおける個人データやプライバシー保護に関する規則であると同時に、EU域内および域内におけるデータの利活用の促進を目指しています。データポータビリティとは、あるサービスが特定のユーザーに対して収集・蓄積した利用履歴などのデータ(以下「個人データ」という)を他のサービスでも再利用できること、すなわち持ち運び可能であること(ポータビリティ)を指します。これと関連し、GDPRに定められている「データポータビリティ権」とは、各サービスのユーザーが、自身の個人データにアクセスできるとともに、その持ち出しや移転を可能にすることです。具体的には、自身の個人データの管理者に対して次の権利を行使可能です。・自身の個人データを、その管理者から一定のフォーマット(構造化され、一般的に利用され、機械により読み取れる形式)で受け取り、他の管理者に移転する権利・自身の個人データを、異なる管理者間で直接移転させる権利b：GDPRによって定められた規定はEU域内に拠点を有する管理者、あるいはEU域内に拠点がなくてもEU域内のデータ主体に対して品物・サービスの提供または行動の監視を行う場合に適用されます。よって、日本国内にのみ拠点を持つ企業にもGDPRが適用される可能性があります。c：記述の通りです。d：GDPRでは、無断でEU域内への個人データ移転(持ち出し)が禁止されています。持ち出しには「越堺移転規制」というルールをクリアし、煩雑な手続きをする必要があります。一方で、欧州委員会から十分性認定を受けた国には、この越堺移転規制が適用されません。つまり、EU域内から個人データを持ち出すための規制が緩和され、当該国の企業は手続きの負担が大きく軽減されます。",
    tag="法規・倫理",
)

db = SessionLocal()
model168 = QuestionModel(
    question_text="次の文章を読み、空欄(ア)～(イ)の組み合わせに最もよくあてはまる選択肢を1つ選べ。EU一般データ保護規則(GDPR)では(ア)の権利を認めている。これはあるサービスに対して、そのユーザーが自らに関して収集・蓄積した利用履歴などのデータを、ほかのサービスでも利用可能な形で移転可能にすることを求める権利である。欧州委員会は、この権利は個人データについてのユーザーの管理権限を強化するだけでなく、(イ)という意義がある。",
    correct_answer="d.(ア)データポータビリティ (イ)新興企業による新規サービス創出を促す",
    choices=[
        "a.(ア)データトランスペアレンシー (イ)自動処理のみにもとづく自動意思決定を防ぐ",
        "b.(ア)データトランスペアレンシー (イ)新興企業による新規サービス創出を促す",
        "c.(ア)データポータビリティ (イ)自動処理のみにもとづく自動意思決定を防ぐ",
        "d.(ア)データポータビリティ (イ)新興企業による新規サービス創出を促す",
    ],
    commentary="選択肢dが正しい組み合わせである。あるサービスが特定のユーザーに関して収集・蓄積した利用履歴などのデータ(個人データ)を他のサービスでも再利用できること、すなわち「持ち運び可能」(ポータブル:portable)であることを指します。欧州委員会によるデータポータビリティ権を導入した目的には、個人データの管理者間の競争、そして新規サービスの創出を促すことが含まれています。",
    tag="法規・倫理",
)

db = SessionLocal()
model169 = QuestionModel(
    question_text="AIを社会やビジネスに導入するのにあたって、様々な団体、企業、自治体がガイドラインの制定に取り組んでいる。これに関する記述として、最も不適切な選択肢を1つ選べ。",
    correct_answer="a.法や倫理はリスクの削減につながるものの、トレードオフとして技術革新を阻害する要因にもなりうる。",
    choices=[
        "a.法や倫理はリスクの削減につながるものの、トレードオフとして技術革新を阻害する要因にもなりうる。",
        "b.「人間中心のAI社会原則」には、AIの開発と活用に関して国、自治体、社会全体が考慮すべき7つの基本原則がまとめられている。",
        "c.「Society 5.0」は、IoTで全ての人とモノをつなげ、様々な知識や情報が共有されることで新たな価値を生み出す社会を目指す。",
        "d.AIを活用する企業が匿名加工情報を作成した場合、それに含まれる個人情報の項目を公表する義務が課せられている。",
    ],
    commentary="選択肢aが誤った内容である。法律や倫理が技術革新を阻害する要因となると考えるのは適切とは言えません。むしろ技術を開発する側にも利用する側にも安心と自由を与える存在みなすべきです。b：2019年に内閣府によって公表された「人間中心のAI社会原則」には、「公平性、説明責任、及び透明性の原則」や「セキュリティ確保の原則」などの7つの基本原則が定められています。c：内閣府が定めた「Society 5.0」とは、サイバー空間とフィジカル空間を高度に融合させたシステムにより、経済発展と社会的課題の解決を両立する人間中心を指す概念です。d：記述の通りです。",
    tag="法規・倫理",
)

db = SessionLocal()
model170 = QuestionModel(
    question_text="国内外のAI倫理ガイドラインまた方針について、適切な選択肢を1つ選べ。",
    correct_answer="d.Google社、Amazon社、Meta社、IBM社、Microsoft社など米国のIT企業を中心に、AIにおける安全性、公平性、透明性、責任を確立することを目標を、Partnership on AIが形成された。",
    choices=[
        "a.米国電気電子学会(IEEE)が公表した'Ethically Aligned Design'は、米国内の人工知能の専門家の意見を集約して作成された倫理ガイドラインである。",
        "b.上記の'Ethically Aligned Design'では、自律型兵器システムを開発しないことが宣言されている。",
        "c.EUが発表した'Ethics Guidelines for Trustworthy AI'では、信頼できるAIを運用するための評価リストが提示されており、これらに関して法規制の導入が進められている。",
        "d.Google社、Amazon社、Meta社、IBM社、Microsoft社など米国のIT企業を中心に、AIにおける安全性、公平性、透明性、責任を確立することを目標を、Partnership on AIが形成された。",
    ],
    commentary="選択肢がdが正しい解答である。2016年に非営利団体であるPartnership on Artificial Intelligence to Benefit People and Society(Partnership on AI;人々と社会に利益をもたらす人工知能のためにパートナーシップ)が創立されました。AIの分野における理解度促進とベストプラクティスの策定、さらに、倫理、公平性、信用性、透明性やプライバシーが重要な論点となっています。a：AIの専門家だけでなく、他に、法律、倫理、哲学などの領域の研究者、企業関係者、市民やNPO団体所属者、政策関係者などの意見を集約して作成しています。b：Ethically Aligned Designには自律型兵器システムの再構築が項目の1つとして含まれています。c：EUのEthics Guidelineds for Trustworthy AIについては法規制が明言されておらず、したがって、法規制を進めるものではありません。",
    tag="法規・倫理",
)

db = SessionLocal()
model171 = QuestionModel(
    question_text="世界中の様々な政府団体、学術団体(学会や研究所など)、企業において、AI倫理のガイドラインや指針が相次いで発表されている。これについて、最も不適切な選択肢を1つ選べ。",
    correct_answer="a.EUのAI専門家グループによって発表された'Ethics Guidelines for Trustworthy AI'は、EU区域内から参加する研究機関のフィードバックをもとに見直しを実施する予定である。",
    choices=[
        "a.EUのAI専門家グループによって発表された'Ethics Guidelines for Trustworthy AI'は、EU区域内から参加する研究機関のフィードバックをもとに見直しを実施する予定である。",
        "b.米国電気電子学会(IEEE)が公表した'Ethically Aligned Design'の目的に、AIに対する恐怖や過度な期待を払拭することが含まれている。",
        "c.機械学習分野の著名な学会であるICMLでは、機械学習における「公平性・説明責任・透明性」を議論するセッションを併催している。",
        "d.日本におけるAI倫理のガイドラインの1つとして内閣府による「人間中心のAI社会原則」が挙げられる。",
    ],
    commentary="選択肢aが不適切な内容である。世界中でAI倫理に関するガイドラインを設立する理由は、それを政府と民間、そして国際的なレベルで合意が取れることで、AIに対する信頼性が高まり、結果として技術の進化に有利な展開をもたらすためです。a：EUのAIハイレベル専門家会合(AI HLEG)によって発表された「Ethics Guidelines for Trustworthy AI」は、2019年に本ガイドライン策定に関する試験導入段階を開始し、EU域内だけではなくEU域外からも企業、研究所、政府当局などから参加機関を募集し、参加機関からのフィードバックをもとに見直しを経て最終的には国際的なAIガイドラインに発展させる方針です。b：IEEEはAIがもたらす倫理的課題について検討するために、報告書「Ethically Aligned Design(EAD)」を作成しました。その目的は知的な機械システムに対する恐怖や過度な期待を払拭すること、倫理的に調和や配慮された技術をつくることによってイノベーションを促進することです。c：「公平性・説明責任・透明性」は、国際的にFAT(Fairness Accountability Transparency)として認識されています。記述の通り、ICML(International Conference on Machine Learning)では、機械学習におけるFATを議論するセッションを併催しています。d：2018年に内閣府において「人間中心のAI社会原則」が設置されました。ここでは、有識者会議の議論にもとづき、「人間中心のAI社会原則」の原案が公開され、人間がAIに過度に依存したり、AIが人間の行動を制限したりするのではなく、人間が自身の能力を発揮するための道具としてAIを使いこなして、人間の尊厳が尊重される社会の構築を目指しています。",
    tag="法規・倫理",
)

db = SessionLocal()
model172 = QuestionModel(
    question_text="独占禁止法('独禁法')のAIやデータへの適用として、最も不適切な選択肢を1つ選べ。",
    correct_answer="b.「監視アルゴリズム」とは、プロダクトなどを事業者間で合意した価格で販売されているかをAIで監視し市場を支配することであり、現在独禁法でカバーされていないことが問題視されている。",
    choices=[
        "a.個人情報や産業データなどを少数の事業者が独占する「データ寡占」は独占禁止法に違反する可能性がある。",
        "b.「監視アルゴリズム」とは、プロダクトなどを事業者間で合意した価格で販売されているかをAIで監視し市場を支配することであり、現在独禁法でカバーされていないことが問題視されている。",
        "c.「デジタルカルテル」とは、AIを用いた市場支配のことであり、その一部は独禁法で禁止されている。",
        "d.独占禁止法は、AIおよびデータの'不当な取引制限'を禁止している。",
    ],
    commentary="選択肢bが誤った内容である。監視アルゴリズムは、独占禁止法(独禁法)によって禁止されています。監視アルゴリズムとは、事業者間で価格合意を行った通りの価格で販売されているか、AIを使って監視して市場を支配することです。事業者間で価格に関する合意がなされている場合(この合意自体も不正行為)、一部の事業者が合意した価格よりも低価格を設定すれば、その商品ばかりが売れることになります。このような低価格販売は人間を使って監視する代わりに、人件費削減のために、監視アルゴリズムを搭載したAIを使って監視を行います。",
    tag="法規・倫理",
)

db = SessionLocal()
model173 = QuestionModel(
    question_text="フィルターバブルが起きている例として、最も適切な選択肢を1つ選べ。",
    correct_answer="c.特定のジャンルのウェブ記事にばっかり注意を向けさせられる。",
    choices=[
        "a.ウェブストアで買い物をする際に、レコメンド機能によるおすすめへの不信感が増す。",
        "b.AIの仕組みをある程度理解しているため、AIによる推論を単なる自動化とみなし、人工の「知能」の存在に疑いを持つようになる。",
        "c.特定のジャンルのウェブ記事にばっかり注意を向けさせられる。",
        "d.AIによって、人種、性別、国籍、年齢、政治的信念、宗教などのバックグラウンドを理由に人々が不当な差別を受けることがある。",
    ],
    commentary="選択肢cが正しい解答である。フィルターバブル現象とは、レコメンド機能などにおいて嗜好の分析にもとづくパーソナライズが強すぎるため、社会の分断を深め、特定の分野にばっかり注意を向けさせ、特定の団体だけ存在が強化されることで、意識のバイアスがかかってしまう現象を指しています。他の選択肢は、いずれもフィルターバブル現象の直接的な例とはいえません。",
    tag="法規・倫理",
)

db = SessionLocal()
model174 = QuestionModel(
    question_text="AIが個人の意思に影響を与えてしまい、民主主義への脅威・阻害となりうる現象について、最も不適切な選択肢を1つ選べ。",
    correct_answer="c.レコメンドのアルゴリズムによって、ユーザーに有益な情報ばかりが優先された結果、他の情報から遮断された状態に陥ってしまう現象をエコーチェンバーと呼ぶ。",
    choices=[
        "a.エコーチェンバー現象は、陰謀論の拡散に拍車にかける要因となりやすく、社会の分断を引き起こすなど政治の分野でも問題視されている。",
        "b.シークレットブラウザで検索を行うなど、フィルターバブルによって無意識に閲覧する情報が偏ることを自ら防ぐ措置をとることが推奨される。",
        "c.レコメンドのアルゴリズムによって、ユーザーに有益な情報ばかりが優先された結果、他の情報から遮断された状態に陥ってしまう現象をエコーチェンバーと呼ぶ。",
        "d.エコーチェンバー現象はAIの使用がなくても起こりうる現象である。",
    ],
    commentary="選択肢cが誤った内容である。選択肢cはエコーチェンバーではなく、フィルターバブルに関する記述です。この問題はエコーチェンバーとフィルターバブルの2つの現象を理解している必要があります。いずれの現象も、偏った特定の意見や価値観により多く触れることによって、意識や思考にバイアスがかかってしまう現象です。思い込みが加速し、冷静に、批判的に「考える」「疑う」「発見する」という機会がますます失われてしまいます。エコーチェンバーとは、ソーシャルメディア(SNS)を利用する際、自分と興味関心が似ているユーザーをフォローすることによって、SNS上で意見を投稿すると、自分と似たような意見ばっかり返ってくる、という現象です。まるで小さな部屋(チェンバー)の中で自分の声がこだま(エコー)して戻ってくることに由来します。自分が「社会的に間違っている意見」を持っていたとしても、他者からどんどん同調を受けているうちに、自分の間違いを全く疑わないどころか、どんどん過信してしまいます。つまり、自分とは異なる意見が自然と遮断されてしまっています。a：エコーチェンバーは政治の分野でも問題を引き起こし得ます。その代表例は2016年のアメリカ合衆国大統領選挙の際に起きた現象です。この時、ウェブの世界で大統領選挙の候補に関する個人の意見が溢れて、選挙結果にまで強い影響を及ぼしたと言われています。これよりもさらに恐ろしいのは、陰謀論が広がってしまい、あっという間にその陰謀論を真実と大勢が信じ込むことによる、2021年のアメリカ合衆国の議会乱入事件です。d：フィルターバブルはレコメンドのアルゴリズム(AI)に関する問題であるのに対し、エコーチェンバーは人間の情報の選択の仕方で発生します。",
    tag="法規・倫理",
)

db = SessionLocal()
model175 = QuestionModel(
    question_text="AIパーソナライズについて考えられる問題点として、不適切な選択肢を1つ選べ。",
    correct_answer="d.フィルターバブルという現象は、人々が自分の観点に合わない情報を自ら積極的に回避しようとする現象のことである。",
    choices=[
        "a.アルゴリズムが商品情報や顧客属性などのデータから抽出したパターンは、社会に潜むバイアスをそのまま引き継ぎ、ユーザーに偏った推薦をしてしまう可能性がある。",
        "b.ECサイト上で買い物客がその表示を望むかどうかにかかわらず、レコメンドが表示され、回避することが容易ではない。",
        "c.自分に勧められているウェブ記事について、推薦の根拠が明確になっていないため、人々の意思に無意識に影響を与えやすい。",
        "d.フィルターバブルという現象は、人々が自分の観点に合わない情報を自ら積極的に回避しようとする現象のことである。",
    ],
    commentary="選択肢dが誤った内容である。例えば、SNS上で、利用者が自分の意見に近いユーザーのみフォローしあるいは返信し、反対意見を述べるユーザーの表示を減らすような行動をとると、これは情報の偏りをもたらしますが、「ユーザーの意思による行動」なので、フィルターバブルの記述としてはふさわしくありません。フィルターバブル現象とは、レコメンド機能など、嗜好の分析にもとづくパーソナライズが強すぎると、意識にバイアスがかかってしまう現象を指します。他の選択肢は全て、AIパーソナライズの主要な問題に該当します。",
    tag="法規・倫理",
)

db = SessionLocal()
model176 = QuestionModel(
    question_text="",
    correct_answer="",
    choices=[
        "",
        "",
        "",
        "",
    ],
    commentary="",
    tag="法規・倫理",
)

db = SessionLocal()
model177 = QuestionModel(
    question_text="AIの社会への浸透によってもたらされる変化や課題として、最も不適切な選択肢を1つ選べ。",
    correct_answer="a.AIはアルゴリズムによって計算が行われ、人間の意思を介さないため、客観的な結果出力を期待できる。",
    choices=[
        "a.AIはアルゴリズムによって計算が行われ、人間の意思を介さないため、客観的な結果出力を期待できる。",
        "b.AIの性能を最大限に発揮するには多様なバックグラウンドや経験を持つ人間からのインプットが必要であるため、AIの普及はインクルージョン(多様性のある開かれた社会)を促す存在になる。",
        "c.AIが人間の仕事に置き換わることによるスキルの喪失が懸念されている。",
        "d.トレーサビリティとは、IoT技術を用いて製造の各工程においてデータの記録と保存をし、AIを用いたデータの追跡と分析を行うことである。問題発生の際に原因究明につながることが期待できる。",
    ],
    commentary="選択肢aが誤った内容である。AI(機械学習)は人間の意思を介さずに、データにある特徴量にもとづいて自動的にパターンを学習し、それにもとづいて判断を行います。しかし、AIの学習に使用するデータは実社会から生まれたものです。よって、社会に潜むバイアスを学習した結果がそのまま反映している可能性があり、必ずしも客観的な結果を出力するとは限りません。他の選択肢は、AIの活用が社会にもたらす変化に関する正しい記述です。",
    tag="法規・倫理",
)

db = SessionLocal()
model178 = QuestionModel(
    question_text="労働市場と人のスキル取得の観点から、AI技術の活用法について、最も適切な選択肢を1つ選べ。",
    correct_answer="b.高電圧が流れる変電所の点検や深水領域での捜索など危険な作業をAI搭載ロボットで行うようになった。",
    choices=[
        "a.自動翻訳の精度が上昇したことをうけて、必要に応じて翻訳ソフトウェアを使用すればよいと判断し、学校で外国語の授業を廃止した。",
        "b.高電圧が流れる変電所の点検や深水領域での捜索など危険な作業をAI搭載ロボットで行うようになった。",
        "c.人間の主観が混入するとバイアスを引き起こしうるため、AI技術を利用して人事査定を行い、AIの判断に全面的に委ねる。",
        "d.飛行機の操縦がAIによって自動化できるようになると、パイロットが必要ではなくなり、航空会社は操縦技術を持たず、AIシステムの設計と監督のスキルを持つ技術者のみ雇用すればよい。",
    ],
    commentary="選択肢bが正しい解答である。従来人間が担っていた業務の一部をAIで代替することはコスト削減、高速化、人手不足の対策として期待されています。それに伴い、ルーティング化しやすい定型業務などを中心に雇用量が減ることが予想されます。一方で、人間が全面的もしくは部分的に関わる必要な仕事もあります。AIに任せる部分と人間が関与する部分を切り分けることが重要です。a：AIを用いた機械翻訳は翻訳業務の簡略化など役に立つことが多いです。一方で生身の人間が直接別の国の言葉でコミュニケーションをとることが好ましいケースがあるなど、外国語教育を排除してよいとはいえません。b：危険を伴う作業をドローンやAIロボットで代替することがAIの有益な活用法の1つです。c：AIから出力された結果は、データバイアスやアルゴリズムバイアスの影響を受けやすいので、初期査定をAIで代替した場合でも、人間がその結果を再確認することが推奨されています。d：飛行機を操縦できるAIが普及した場合でも、そのようなAIを設計、監視、運営するには、操縦に関連する知見を持つ人材が必要です。",
    tag="法規・倫理",
)

db = SessionLocal()
model179 = QuestionModel(
    question_text="以下の文章を読み、(ア)と(イ)にあてはまる組み合わせとして、最も適切な選択肢を1つ選べ。高度な人工知能(AI)を搭載し、人間の関与なしに殺傷する能力を有する自律型致死兵器システムは(ア)と呼ばれる。日本政府は(ア)の開発はしないと宣言する一方、(イ)という立場をとっている。",
    correct_answer="c.(ア)LAWS (イ)人の意思が介在する自律型兵器の開発は規制すべきではない",
    choices=[
        "a.(ア)JAIC (イ)人の意思が介在する自律型兵器の開発は規制すべきではない",
        "b.(ア)LAWS (イ)アメリカ国防総省の開発プロジェクトを支援すべき",
        "c.(ア)LAWS (イ)人の意思が介在する自律型兵器の開発は規制すべきではない",
        "d.(ア)JAIC (イ)アメリカ国防総省の開発プロジェクトを支援すべき",
    ],
    commentary="選択肢cが正しい組み合わせである。LAWS(Lethal Autonomous Weapons Systems)とは、人間の判断を介さないで、AI自身の判断だけで標的や敵に攻撃を行う自律型殺傷兵器です。通称「キラーロボット」とも呼ばれています。LAWSが非倫理的、非道徳的である懸念により、国連をはじめとする多くの企業や団体でその禁止が強く主張されています。記述の通り、日本政府はLAWSの開発はしないと宣言する一方、人の意思が介在する自律型兵器の研究・開発は規制すべきではないという立場です。JAIC(Joint AI Center)とは、アメリカ国防総省の人工知能の研究開発を行うジョイントAIセンターのことであり、そこでAIの軍事利用に関する研究が行われています。",
    tag="法規・倫理",
)

db = SessionLocal()
model180 = QuestionModel(
    question_text="AIの軍事利用にまつわる動向について、最も適切な選択肢を1つ選べ。",
    correct_answer="a.国連において、AIの軍事利用に関する規制が主張された。",
    choices=[
        "a.国連において、AIの軍事利用に関する規制が主張された。",
        "b.国連加盟国はAIを搭載された兵器の開発を放棄した。",
        "c.現在、Google社はAIを利用したドローン兵器の開発を米政府と共同で進めている。",
        "d.Microsoft社は政府のAI兵器開発プロジェクトに携わらないという宣明を出した。",
    ],
    commentary="選択肢aが正しい解答である。2018年以降、国連でAIの軍事利用に関する議論が行われ、その中で、グテレス事務総長は、「人間の関与なしに殺傷する能力と総量を持つ機械は、政治的に容認できず、道徳的にも嫌悪感を引き起こし、国際法によって禁止されるべきである」と強く訴えました。また、テロ組織が最新技術を容易に入手可能と摘発し、核兵器の施設に対するサイバー攻撃が起こりうるとも警告しました。AIの他に、3Dプリンター、バイオテクノロジー、顔認証など最先端のIT技術の軍事利用の規制についても議論されました。b：米国、中国、ロシアをはじめとする国連加盟国でAIの軍事利用の開発が進められています。人間の意思を全く介さない完全自律型兵器までは至らず、開発は行うものの、実際の利用には合意しない姿勢がほとんどです。c：民間企業の中でAIの軍事利用に対する反対運動が活発化しています。かつて、Googleがアメリカ国防総省と共同で、ドローン兵器に利用するためのAI活用パイロットプログラム「Project Maven」を進めていました。しかし、Googleの社員から軍事目的のAI開発について反対の声が上がり、契約は2019年で打ち切りになりました。Googleはこれを受け、2018年6月に「AI at Google: our principles」を発表し、「AIを兵器のために開発することはしない」というAIの平和利用宣言の声明を出しました。d：Google社が政府のAI兵器開発プロジェクトに協力しない姿勢を示したのに対し、Microsoft社は、「防衛や災害派遣など市民が米軍から受ける恩恵は大きい」として、軍事利用の研究への協力を継続する意向を示しました(後にAmazon社も)。",
    tag="法規・倫理",
)

db = SessionLocal()
model181 = QuestionModel(
    question_text="2019年1月1日より改正著作権法が施行された。改正著作権法の中でもデジタル・ネットワーク化の進展に向けた規定として、最も不適切な選択肢を1つ選べ。",
    correct_answer="d.Web検索により表示する検索結果に、元の著作物の内容を表示することは違法である",
    choices=[
        "a.コンピュータを用いて情報解析を行い、その結果を提供することができる",
        "b.情報解析を行う他人のためにAI研究・開発用データセットを作成・譲渡することができる",
        "c.情報解析や技術開発など、他人の著作物を享受する目的でなければ、著作者の同意がなくても利用できる",
        "d.Web検索により表示する検索結果に、元の著作物の内容を表示することは違法である",
    ],
    commentary="AIの研究・開発に関連する規定として、もともと著作権法第47条の7がありました。世界的に見てもAI開発に対して柔軟な規定でしたが、改正法により更に柔軟性を高めました。改正著作権法では、特に著作物の①非享受利用と②軽微利用について新たに定められました。①非享受利用は、他人の著作物(画像や音楽などのコンテンツ)を視聴者等の知的・精神的欲求を満たす効用を得る目的(著作物を享受する目的)で利用しない場合は、著作権者の同意なく利用が可能となりました。②軽微利用は、著作物の利用促進に資する行為で、権利者に与える不利益が軽微である一定の利用を行う場合は、著作権者の同意なく利用が可能となりました。このことから、選択肢a.b.cの内容は適法となります。選択肢dの、検索エンジンで検索し、検索結果に元の著作物の内容の一部(サムネイルやスニペットなど)を表示することは適法です。",
    tag="法規・倫理",
)

db = SessionLocal()
model182 = QuestionModel(
    question_text="AIのビジネス応用について述べたものとして、最も適切な選択肢を1つ選べ。",
    correct_answer="c.課題を分析した上で、AI活用の必要性の有無を含めて解決手法を選択する",
    choices=[
        "a.学習データに偏りがあってもアルゴリズムの選定をしっかりすれば予測結果が偏ることはない",
        "b.一度精度の高い学習モデルを生成すれば、導入後の保守は必要としない",
        "c.課題を分析した上で、AI活用の必要性の有無を含めて解決手法を選択する",
        "d.AIベンダーに委託する場合、AIの知識は不要であり、データの提供に集中する",
    ],
    commentary="AIの導入自体が目的になると、AIのビジネス応用がうまくいかなくなる可能性が高まります。解決すべき業務課題を明確にした上でAIの導入が他の方法と比べて有効なのか、有効な場合はどのようなデータを収集する必要があるのか、よく分析した上で判断すべきです。選択肢a：モデルに与えるデータに偏りがあると、モデルが偏ったルールを学習し、人種や性別などで公平性のない推論をすることに繋がりかねません。これは一般的にアルゴリズムの選定だけで解決することは難しく、学習に用いるデータに偏りがないか分析し、適切なデータを用いることが重要です。選択肢b：たとえ精度の高いモデルを導入したとしてもニーズや環境の変化によりAIに求められる結果や、求められる精度が変わる可能性があるため、必要に応じて再学習などをすべきです。選択肢d：AIの開発では、必要なデータの種類や量、実装、運用にかかるコストなど、契約時点では不明瞭なことが多く、開発を進める過程で開発者と委託者ですり合わせていく必要があります。委託者もAI開発の勘所を理解していないと望む結果は得にくくなるでしょう。",
    tag="法規・倫理",
)

db = SessionLocal()
model183 = QuestionModel(
    question_text="プライバシー・バイ・デザインの考え方の説明として、最も適切な選択肢を1つ選べ。",
    correct_answer="c.AIサービスの企画や設計段階からプライバシー保護施策を組み込む",
    choices=[
        "a.透明性レポートを公開し、信頼性を確保する",
        "b.AIの運用を開始した後に、プライバシー保護施策を組み込む",
        "c.AIサービスの企画や設計段階からプライバシー保護施策を組み込む",
        "d.Partnership on AIに加入する",
    ],
    commentary="プライバシー・バイ・デザインは、AIやその他サービスの企画や設計段階からユーザのプライバシー保護をあらゆる側面から検討し、予めプライバシー保護対策を組み込む考え方です。これにより運用を開始した後も安全にプライバシーを保護できます。",
    tag="法規・倫理",
)

db = SessionLocal()
model184 = QuestionModel(
    question_text="AIに対する倫理的な問題や価値観の問題が議論されている。Google社が開発したGoogle Photosが起こした事例として、最も適切な選択肢を1つ選べ。",
    correct_answer="d.黒人男女に対してカテゴリをゴリラであると判定した",
    choices=[
        "a.撮影した画像を暴力的な表現に加工した",
        "b.自動車運転で物体認識できたはずの信号無視をした",
        "c.著作権や肖像権を無視して画像アップロードした",
        "d.黒人男女に対してカテゴリをゴリラであると判定した",
    ],
    commentary="2015年にGoogleが開発したフォトアプリGoogle Photosがアフリカ系の男女に「ゴリラ」というラベルを付ける事例がありました。2018年に雑誌Wired US版が5万枚以上の画像を使って検証したところ、ゴリラを含む一部の霊長類は検索単語からタグが外されていました。そのため、霊長類に対しては検索機能が動作しないという実態が明らかになると同時に、機械学習の課題が浮き彫りになりました。",
    tag="法規・倫理",
)

db = SessionLocal()
model185 = QuestionModel(
    question_text="AIに対する倫理的な問題や価値観の問題が議論されている。Microsoft社が開発したTayが起こした事例として、最も適切な選択肢を1つ選べ。",
    correct_answer="b.ヘイト発言・差別的発言をした",
    choices=[
        "a.人類を滅亡させると発言した",
        "b.ヘイト発言・差別的発言をした",
        "c.人間が行った犯罪を援助した",
        "d.犯罪予告をした",
    ],
    commentary="Microsoft社が開発したTayは、SNSで会話するチャットボットとして登場しました。ユーザとの会話を通して学習していくことを目指して開発されましたが、次第に差別的・暴力的な発言が増え、サービス停止となりました。選択肢aは、Hanson Robotics社が開発したAIロボットSophinaの事例です。",
    tag="法規・倫理",
)

db = SessionLocal()
model186 = QuestionModel(
    question_text="",
    correct_answer="",
    choices=[
        "",
        "",
        "",
        "",
    ],
    commentary="",
    tag="法規・倫理",
)

db = SessionLocal()
model187 = QuestionModel(
    question_text="日本の内閣府が2018年に、実現することを目標に掲げている未来社会ビジョンの名称として、最も適切な選択肢を1つ選べ。",
    correct_answer="b.Society5.0",
    choices=[
        "a.AIaaS",
        "b.Society5.0",
        "c.PRISM",
        "d.Insdustrie4.0",
    ],
    commentary="内閣府は2018年に、未来社会ビジョン「Society 5.0(超スマート社会)」の実現を目標として掲げました。Society 5.0は、「必要なもの・サービスを、必要な人に、必要な時に、必要なだけ提供し、社会の様々なニーズにきめ細かに対応でき、あらゆる人が質の高いサービスを受けられ、年齢、性別、地域、言語といった様々な違いを乗り越え、活き活きと快適に暮らすことのできる社会」というように表現されています。選択肢aは、AI as a Serviceで、AIプログラムを構築する環境をサービスとして提供するビジネスモデルのことです。選択肢cは、官民研究開発投資拡大プログラムのことです。選択肢dは、ドイツ連邦政府が公表した国家戦略のことです。",
    tag="法規・倫理",
)

db = SessionLocal()
model188 = QuestionModel(
    question_text="日本の内閣府は、未来社会ビジョンの実現には第四次産業革命技術の社会実装が鍵だとしている。第四次産業革命技術に含まれる技術として、最も適切な選択肢を1つ選べ。",
    correct_answer="a.IoT、ビッグデータ、AI、ロボット",
    choices=[
        "a.IoT、ビッグデータ、AI、ロボット",
        "b.IoT、クラウド、AI、5G",
        "c.ブロックチェーン、ビッグデータ、AI、クラウド",
        "d.ブロックチェーン、ビッグデータ、RPA、ロボット",
    ],
    commentary="第四次産業革命技術(IoT、ビッグデータ、AI,ロボット)の社会実装がSociety 5.0の実現に繋がります。Society 5.0は、IoTで全ての人とモノがつながり、それにより蓄積された膨大なビッグデータ、を人間の能力を超えたAIが解析し、その結果がロボットなどを通して人間にフィードバックされることで、これまでには出来なかった新たな価値が産業や社会にもたらされることになります。",
    tag="法規・倫理",
)

db = SessionLocal()
model189 = QuestionModel(
    question_text="以下の文章を読み、(ア)～(イ)に当てはまる組み合わせの選択肢を1つ選べ。AIやディープラーニングが注目される昨今、技術者を支援するプラットフォームが増えてきている。代表的なものとして、Kaggleは(ア)を、Google Scholarは(イ)をそれぞれ可能にしている。",
    correct_answer="d.(ア)コンペティションへの参加、(イ)Web検索による論文・学術誌へのアクセス",
    choices=[
        "a.(ア)世界の有名大学のオンライン講義の受講、(イ)オンラインによるAIプログラミング学習",
        "b.(ア)世界の有名大学のオンライン講義の受講、(イ)Web検索による論文・学術誌へのアクセス",
        "c.(ア)コンペティションへの参加、(イ)オンラインによるAIプログラミング学習",
        "d.(ア)コンペティションへの参加、(イ)Web検索による論文・学術誌へのアクセス",
    ],
    commentary="Kaggleは、世界中の機械学習・データサイエンスに携わる人たちが参加するコミュニティやコンペティション、およびその運営会社です。Google Scholarは、Googleの検索サービスの1つです。学術研究資料に特化したサービスで、論文、学術誌、出版物の全文やメタデータへのアクセスを可能としています。",
    tag="法規・倫理",
)

db = SessionLocal()
model190 = QuestionModel(
    question_text="以下の文章を読み、(ア)～(ウ)に当てはまる組み合わせの選択肢を1つ選べ。自動運転技術は、その精度によって0～5のレベル分けがされている。これは、アメリカの非営利団体(ア)の「J3016」にて定められている。自動運転化が全くされていない通常の乗用車をレベル0とし、自動ブレーキなどの運転支援の機能がついたものはレベル(イ)、天候や道路などの特定の場所・条件に限り人手を必要としない運転機能をもつものはレベル(ウ)、あらゆる走行環境でも人手を全く必要としない運転機能をもつものをレベル5とされている。J3016では、レベル3以上を「自動運転」と定義している。",
    correct_answer="b.(ア)SAE、(イ)1、(ウ)3",
    choices=[
        "a.(ア)SAE、(イ)1、(ウ)4",
        "b.(ア)SAE、(イ)1、(ウ)3",
        "c.(ア)ITS、(イ)2、(ウ)4",
        "d.(ア)ITS、(イ)2、(ウ)4",
    ],
    commentary="SAE(Society of Automotive Engineers)は、1905年に設立された乗り物に関する標準化機構です。自動運転のレベルを定義するJ3016を発行しており、日本は独自の自動運転の定義ではなく、J3016を採用しています。",
    tag="法規・倫理",
)

db = SessionLocal()
model191 = QuestionModel(
    question_text="システム開発における代表的な開発手法にウォーターフォール型とアジャイル型がある。アジャイル型の特徴として、最も適切でない選択肢を1つ選べ。",
    correct_answer="c.要件不足や認識違いにより手戻り作業が発生しやすい",
    choices=[
        "a.試行錯誤が必要な開発に適している",
        "b.コストやスケジュールを管理しにくい",
        "c.要件不足や認識違いにより手戻り作業が発生しやすい",
        "d.仕様変更に柔軟に対応可能",
    ],
    commentary="選択肢cは、ウォーターフォール型の特徴です。ウォーターフォール型は、その他に「責任範囲が明確にできる」「コストやスケジュールを管理しやすい」といった特徴があり、要件やゴールが明確に決まっている開発に適しています。選択肢c以外は、アジャイルの特徴です。",
    tag="法規・倫理",
)

db = SessionLocal()
model192 = QuestionModel(
    question_text="AI開発時に契約や開発が進まない課題に対して、経済産業省はAI・データ契約ガイドライン検討会を設置し、4つの段階で契約を締結しながら開発を進める探索的段階型を提唱している。4つの段階として、最も適切な選択肢を1つ選べ。",
    correct_answer="d.アセスメント、PoC、開発、追加学習",
    choices=[
        "a.プロトタイピング、PoC、運用、追加学習",
        "b.データ契約、設計、開発、テスト",
        "c.データ契約、PoC、開発、追加学習",
        "d.アセスメント、PoC、開発、追加学習",
    ],
    commentary="AI開発においてステークホルダー間の認識違いを避けるためにも、適切なコミュニケーションやプロジェクト管理が必要になります。こうしたニーズに対して経済産業省は、AI・データ契約ガイドライン検討会を設置し、「アセスメント」「PoC」「開発」「追加学習」の4つの段階に分けて、それぞれの段階で必要な契約を締結していく探索的段階型を提唱しています。",
    tag="法規・倫理",
)

db = SessionLocal()
model193 = QuestionModel(
    question_text="経済産業省が定めた「AI・データの利用に関する契約ガイドライン」では、AI開発のプロセスを4つの段階に分けている。PoC段階における目的として、最も適切な選択肢を1つ選べ。",
    correct_answer="a.学習用データセットを用いてユーザが希望する精度の学習済みモデルが生成できるか検証する",
    choices=[
        "a.学習用データセットを用いてユーザが希望する精度の学習済みモデルが生成できるか検証する",
        "b.ベンダが納品した学習済みモデルについて、追加の学習用データセットを使って学習する",
        "c.一定量のデータを用いて学習済みモデルの生成可能性を検証する",
        "d.学習済みモデルを生成する",
    ],
    commentary="PoCはモデルの本開発・導入の前段階で、期待する精度が得られるかを検証します。試行錯誤を繰り返すことで不確実な要素を取り除きます。選択肢bは追加学習、選択肢cはアセスメント、選択肢dは開発の段階における目的です。",
    tag="法規・倫理",
)

db = SessionLocal()
model194 = QuestionModel(
    question_text="AIの共同開発をする上で留意すべきこととして、最も適切でない選択肢を1つ選べ。",
    correct_answer="c.契約交渉は、実際の開発状況に合わせてステークホルダー間で認識を合わせながら進めていく必要があるが、秘密保持契約については開発の終盤で結ぶことが望ましい",
    choices=[
        "a.設計・開発に移行した従来のソフトウェア開発においては、仕様が十分に特定されていることから請負型の契約が親和的であることが多いが、不確実性の高いAI開発の場合はPoCや開発段階において準委任型の契約が親和的である。",
        "b.アジャイル型開発ではステークホルダーが関与する機会が多くあるため、要求に対して柔軟な対応が可能だが、責任の範囲や投資の回収時期が曖昧になりがちであるため、これらに関しても密なコミュニケーションを図る必要がある。",
        "c.契約交渉は、実際の開発状況に合わせてステークホルダー間で認識を合わせながら進めていく必要があるが、秘密保持契約については開発の終盤で結ぶことが望ましい",
        "d.経済産業省が提唱する探索的段階型では、開発プロセスのそれぞれの段階で必要な契約を結ぶことで、試行錯誤しながらニーズに合ったモデルを生成することがしやすくなるとしている。",
    ],
    commentary="秘密保持契約(NDA)は、個人情報や顧客情報、ノウハウなどの重要な情報のやり取りを他社と行う場合に、これらを勝手に外部に開示したり、目的外のこと利用したりするを禁止する契約です。AI開発においては、開発の初期段階からノウハウや技術はもちろん、データのやり取りが発生するため、開発初期から秘密保持契約を締結することが適切です。",
    tag="法規・倫理",
)

db = SessionLocal()
model195 = QuestionModel(
    question_text="CRISP-DMの特徴として、最も適切な選択肢を1つ選べ。",
    correct_answer="d.CRISP-DMの各工程は、必ず順番に進めなければならない訳ではなく、相互に行き来することがある。",
    choices=[
        "a.CRISP-DMは、データ分析プロセスの方法論であり、5つの工程で構成されている。",
        "b.CRISP-DMでは、「データの準備」を行ってから「データの理解」を行う",
        "c.CRISP-DMでは、「評価」後は必ず「展開/共有」する",
        "d.CRISP-DMの各工程は、必ず順番に進めなければならない訳ではなく、相互に行き来することがある。",
    ],
    commentary="CRISP-DMは、データ分析プロセスの方法論であり、以下の6つの工程で構成されています。・ビジネス課題の理解・データの理解・データの準備・モデル作成・評価・展開/共有　各工程は一方通行のプロセスではなく、必要に応じて行ったりを繰り返しながら適切な結果へと結びつけるためのプロセスです。",
    tag="法規・倫理",
)

db = SessionLocal()
model196 = QuestionModel(
    question_text="プログラミング言語であるPythonの特徴として、最も適切でない選択肢を1つ選べ。",
    correct_answer="b.処理速度が非常に高速である",
    choices=[
        "a.シンプルなコードで読みやすく、わかりやすい",
        "b.処理速度が非常に高速である",
        "c.機械学習を実施する上で必要とされるライブラリが豊富",
        "d.アプリケーションやWebシステムなどの開発にも利用できる",
    ],
    commentary="Pythonは、ソースコードを逐次解釈しながら実行する言語(インタプリタ型)であるため、処理速度が遅いというデメリットがあります。",
    tag="法規・倫理",
)

db = SessionLocal()
model197 = QuestionModel(
    question_text="Define-by-Runの説明として、最も適切な選択肢を1つ選べ。",
    correct_answer="a.順伝播処理をしながら計算グラフを構築する",
    choices=[
        "a.順伝播処理をしながら計算グラフを構築する",
        "b.計算グラフを構築した後に順伝播処理をする",
        "c.パラメータの最適化が容易だが、処理途中の結果が確認しづらい",
        "d.Facebook(現Meta)製のPyTorchは、Define-by-Runではなく、Define-and-Runの考え方が取り入れられている",
    ],
    commentary="主流の深層学習フレームワークが取り入れているDefine-by-Runは、学習データを入力しながら計算グラフ(ニューラルネットワーク)を構築する方式です。順伝播処理の実行と計算グラフの構築を行うため、実行中の処理結果を確認しやすいなどの柔軟性があります。",
    tag="法規・倫理",
)

db = SessionLocal()
model198 = QuestionModel(
    question_text="機械学習を行う際に、母集団を代表しないデータが学習データとして選ばれてしまう事象を指すバイアスとして、最も適切な選択肢を1つ選べ。",
    correct_answer="c.サンプリングバイアス",
    choices=[
        "a.アルゴリズムバイアス",
        "b.測定バイアス",
        "c.サンプリングバイアス",
        "d.観察者バイアス",
    ],
    commentary="サンプリングバイアスは、学習に使用するデータに、モデルの活用環境が正確に反映されていない場合に生じる事象です。母集団とは、調査や研究の対象とする集合全体のことです。",
    tag="法規・倫理",
)

db = SessionLocal()
model199 = QuestionModel(
    question_text="MLOpsの説明として、最も適切な選択肢を1つ選べ。",
    correct_answer="b.機械学習チーム/開発チームと運用チームが互いに強調し、円滑な運用体制を築くこと",
    choices=[
        "a.ITシステムの運用において、AIを適用しさらなる自動化や効率化を図ること",
        "b.機械学習チーム/開発チームと運用チームが互いに強調し、円滑な運用体制を築くこと",
        "c.AIの企画・設計段階からあらかじめプライバシー保護の取り組みを検討すること",
        "d.100個のクラスがラベリングされている画像データセットのこと",
    ],
    commentary="MLOpsは'Machine Learning'と'Operations'の合成語で、機械学習チーム/開発チームと運用チームが互いに強調し、モデルの実装から運用までのライフサイクルを円滑に進めるための管理体制を築くことを指します。",
    tag="法規・倫理",
)

db = SessionLocal()
model200 = QuestionModel(
    question_text="説明可能なAI(XAI)の説明として、最も適切な選択肢を1つ選べ。",
    correct_answer="b.予測結果や推論の計算プロセスの解釈可読性が高い",
    choices=[
        "a.ソースコードの可読性が高い",
        "b.予測結果や推論の計算プロセスの解釈可読性が高い",
        "c.学習に使われたデータの概要が明確",
        "d.モデルのパラメータ数や構造を把握できる",
    ],
    commentary="説明可能なAI(XAI)は、予測結果や推論結果に至るプロセスが人間によって説明可能になっているモデルのこと、あるいはその技術や研究のことです。つまり、モデルの推論プロセスを人間が解釈可能であるか(解釈可能性が高い)を指します。",
    tag="法規・倫理",
)

db = SessionLocal()
model201 = QuestionModel(
    question_text="個人情報保護法における個人情報の説明として、最も適切な選択肢を1つ選べ。",
    correct_answer="a.故人のみに関わる情報は保護の対象外である",
    choices=[
        "a.故人のみに関わる情報は保護の対象外である",
        "b.個人の姓(名字)と勤務先だけであれば個人を特定されることはないため、個人情報にあたらない",
        "c.個人識別符号は、カード等の書類に記載された符号のことであるため、指紋や音声、歩き方は該当しない",
        "d.数値化されたデータ(特徴量など)は個人情報になり得ない",
    ],
    commentary="個人情報保護法の個人情報は「生存する個人」が対象であるため、故人のみに関わる情報は保護の対象外です。ただし、故人の情報であっても生存する個人と関連がある場合には、その生存する個人の個人情報になる場合があるため、注意が必要です。選択肢bについて、姓と勤務先だけでも個人を特定される可能性はあるため、個人情報となり得ます。選択肢cについて、個人識別符号は。カードの書類に記載された符号以外に身体の一部の特徴を変換した符号も含まれるため、指紋や音声、歩き方も該当し、それによって個人が特定できる場合は個人情報にあたります。選択肢dについて、数値化されたデータも個人識別符号に該当するため、個人情報になる可能性はあります。",
    tag="法規・倫理",
)

db = SessionLocal()
model202 = QuestionModel(
    question_text="個人情報について以下の文章を読み、(ア)～(イ)に当てはまる組み合わせの選択肢を1つ選べ。個人情報保護法上、個人情報は4つに分類される。個人データとは、データベースに含まれる個人情報のことをいう。保有個人データとは、個人情報取扱事業者に開示・訂正・消去等の権限があり、(ア)を超えて保有するものである。(イ)とは、人種、信条、社会的身分、病歴、犯罪の経歴、犯罪被害を受けた事実、その他本人に対する不当な差別、偏見などが含まれた個人情報のことである。",
    correct_answer="d.(ア)6ヶ月、(イ)要配慮個人情報",
    choices=[
        "a.(ア)1年、(イ)従属的個人情報",
        "b.(ア)1年、(イ)要配慮個人情報",
        "c.(ア)6ヶ月、(イ)従属的個人情報",
        "d.(ア)6ヶ月、(イ)要配慮個人情報",
    ],
    commentary="問題文のとおりです。なお、要配慮個人情報を取得する際には、本人からの同意を得る必要があります。",
    tag="法規・倫理",
)

db = SessionLocal()
model203 = QuestionModel(
    question_text="匿名加工情報を取り扱う事業者に課せられる義務として、最も適切でない選択肢を1つ選べ。",
    correct_answer="b.匿名加工情報の加工方法を公開しなければならない",
    choices=[
        "a.匿名加工情報に含まれる個人に関する情報の項目を公表しなければならない",
        "b.匿名加工情報の加工方法を公開しなければならない",
        "c.自らが作成した匿名加工情報を、個人を特定するために他の情報と照合してはならない",
        "d.匿名加工情報に関する苦情処理方法公表しなければならない",
    ],
    commentary="義務の1つである安全管理措置の観点から匿名加工情報の加工方法の漏えいは防止しなければいけません。",
    tag="法規・倫理",
)

db = SessionLocal()
model204 = QuestionModel(
    question_text="発明者に関する説明として、最も適切でない選択肢を1つ選べ。",
    correct_answer="a.複数人が共同で発明した場合、そのうちの一人のみが発明者になれる",
    choices=[
        "a.複数人が共同で発明した場合、そのうちの一人のみが発明者になれる",
        "b.特許法上、AI自体が発明者になることできない",
        "c.特許法上、法人が発明者になることはできない",
        "d.発明しても特許要件を満たさなければ特許法で保護されない",
    ],
    commentary="複数人が共同で発明をした場合には、その全員が発明者となって特許を取得することができます。なお、特許法上、自然人のみが発明者になれるため、法人やAIが発明者になることはできません。",
    tag="法規・倫理",
)

db = SessionLocal()
model205 = QuestionModel(
    question_text="不正競争防止法上の営業秘密として保護されるために必要な特性として、最も適切な選択肢を1つ選べ。",
    correct_answer="d.秘密管理性、有用性、非公知性",
    choices=[
        "a.安全性、独自性、有期性",
        "b.安全性、有用性、有期性",
        "c.秘密管理性、独自性、非公知性",
        "d.秘密管理性、有用性、非公知性",
    ],
    commentary="不正競争防止法上、次の3つの特性が認められる情報は営業秘密として保護されます",
    tag="法規・倫理",
)

db = SessionLocal()
model206 = QuestionModel(
    question_text="ディープラーニングを利用して、2つの画像や動画の一部を交換させる技術して、最も適切な選択肢を1つ選べ。",
    correct_answer="b.ディープフェイク",
    choices=[
        "a.ディープスワッピング",
        "b.ディープフェイク",
        "c.ディープスルー",
        "d.敵対的生成ネットワーク",
    ],
    commentary="ディープフェイクは、世間一般には偽画像や偽動画のことを指すと認識されていますが、本来の意味は「ディープラーニングを利用して、2つの画像や動画の一部をスワップ(交換)させる技術です。ポルノ動画の顔を有名人の顔に変更した動画を作成、公開したり、政治家や有名人などの影響力のある人の発言を動画で作り出したりするなどの倫理的な問題にも発展しています。",
    tag="法規・倫理",
)

db = SessionLocal()
model207 = QuestionModel(
    question_text="インターネット上で自分の見たい情報しか見えなくなることを指す用語として、最も適切な選択肢を1つ選べ。",
    correct_answer="c.フィルターバブル",
    choices=[
        "a.コンテンツフィルタリング",
        "b.パーソナライゼーション",
        "c.フィルターバブル",
        "d.アンダードッグ効果",
    ],
    commentary="フィルターバブルは、インターネット上で泡(バブル)の中に包まれたように自分の見たい情報しか見えなくなることを指す用語です。インターネット上でAIなどによって趣味嗜好や検索傾向が分析され、情報を選り分けられることで、視野が狭くなることや異なる価値観・考え方に触れる機会がなくなることが問題点として挙げられています。",
    tag="法規・倫理",
)

db = SessionLocal()
model208 = QuestionModel(
    question_text="Adversarial Attacks(敵対的な攻撃)と関連が深い内容として、最も適切な選択肢を1つ選べ。",
    correct_answer="b.ある画像に微小なノイズを付加することで誤った認識をさせた",
    choices=[
        "a.実在しない高精度なアイドル画像を生成した",
        "b.ある画像に微小なノイズを付加することで誤った認識をさせた",
        "c.フェイクニュースを自動生成できるモデルを生成した",
        "d.機械学習に用いる画像データの輝度や明度を変えたり、反転させたりした",
    ],
    commentary="Adversarial Attacksは、意図的に微小なノイズや特定の模様(パッチ)を加えたデータを用いてAIを騙す攻撃手法です。有名な例として、パンダの画像に微小なノイズを加えたことで、画像認識モデルがテナガザルと認識しました。",
    tag="法規・倫理",
)

db = SessionLocal()
model209 = QuestionModel(
    question_text="シリアス・ゲームの説明として、最も適切な選択肢を1つ選べ。",
    correct_answer="b.純粋な娯楽のためではなく、社会問題の解決を目的とするコンピュータゲームの総称",
    choices=[
        "a.ゲーム感覚でAI開発に取り組めるツール群",
        "b.純粋な娯楽のためではなく、社会問題の解決を目的とするコンピュータゲームの総称",
        "c.特定の目的やゴールが存在せず、プレイヤーが自分で目的や目標を決めて自由に遊ぶコンピュータゲームの総称",
        "d.画像認識モデルの精度を競うゲームの総称",
    ],
    commentary="シリアス・ゲームは、純粋な娯楽目的ではなく、社会問題の解決や教育、啓発を目的として作られているコンピュータゲームの総称です。",
    tag="法規・倫理",
)

db = SessionLocal()
model210 = QuestionModel(
    question_text="GDPRに関する説明として、最も適切な選択肢を1つ選べ。",
    correct_answer="d.GDPRでは個人の氏名や住所、クレジットカード番号のみならず、位置情報やクッキー情報も個人情報と見做される",
    choices=[
        "a.GDPRはEEA域内に事業展開している日本企業の現地従業員も対象となるが、EEA内で収集したデータの分析などを日本国内のみで実施している場合は規制の対象とならない",
        "b.GDPRはEU加盟国の場合は規制が緩和されるため、EEA域内で取得した個人データをEEA域外に移転できる",
        "c.GDPRにおいて十分性認定を受けた国は煩雑な手続きなしでEU域内から個人データを持ち出せるようになるが、2021年時点で日本は十分性認定を受けていないため個人データを日本に移転することはできない",
        "d.GDPRでは個人の氏名や住所、クレジットカード番号のみならず、位置情報やクッキー情報も個人情報と見做される",
    ],
    commentary="2018年5月に適用開始したGDPR(EU一般データ保護規則)では、個人を直接的に、または間接的に識別され得る情報も個人情報と見做しているため、位置情報やオンライン識別子(クッキー情報やIPアドレス)も個人情報に見做されます。GDPRはEU加盟国に対しても同一に直接効力を持つため、個人データをEEA域外に移転することは原則禁止されます。また、日本は2019年1月23日に十分性認定を受けています。",
    tag="法規・倫理",
)

db = SessionLocal()
model211 = QuestionModel(
    question_text="「標本」とは何を指しますか？",
    correct_answer="b.母集団から抽出された一部のデータ",
    choices=[
        "a.母集団全体のデータ",
        "b.母集団から抽出された一部のデータ",
        "c.標準偏差",
        "d.平均値",
    ],
    commentary="標本とは母集団から抽出された一部のデータを指します。",
    tag="基礎数学",
)

db = SessionLocal()
model212 = QuestionModel(
    question_text="「平均値」の計算方法は次のうちどれですか？",
    correct_answer="a.各データを合計してデータ数で割る",
    choices=[
        "a.各データを合計してデータ数で割る",
        "b.データを大きい順に並べて中央の値をとる",
        "c.データを小さい順に並べて中央の値をとる",
        "d.各データを掛け合わせてその総乗をデータ数で割る",
    ],
    commentary="平均値は各データで合計してデータ数で割ることが求められます。",
    tag="基礎数学",
)

db = SessionLocal()
model213 = QuestionModel(
    question_text="「分散」は何を測定する指標ですか？",
    correct_answer="a.データのばらつき具合",
    choices=[
        "a.データのばらつき具合",
        "b.データの中央値",
        "c.データの最大値と最小値の差",
        "d.データの平均値",
    ],
    commentary="分散はデータのばらつき具合を測定する指標です。",
    tag="基礎数学",
)

db = SessionLocal()
model214 = QuestionModel(
    question_text="標本の数値データが以下の通りであるとき、平均値を求めてください 。 :  [12, 15, 18, 20, 22]",
    correct_answer="d.17.4",
    choices=[
        "a.12.8",
        "b.13.9",
        "c.16.9",
        "d.17.4",
    ],
    commentary="平均値はデータの合計をデータ数で割ることで求められます。",
    tag="基礎数学",
)

db = SessionLocal()
model215 = QuestionModel(
    question_text="標本の数値データが以下の通りであるとき、標準偏差を求めてください。  :  [10, 12, 14, 16, 18]",
    correct_answer="c.約2.24",
    choices=[
        "a.約0.24",
        "b.約1.24",
        "c.約2.24",
        "d.約3.24",
    ],
    commentary="標準偏差は各データと平均値の差の二乗を合計してデータ数を割った後、平均根を取ることで求められます。",
    tag="基礎数学",
)

db = SessionLocal()
model216 = QuestionModel(
    question_text="外から見えない袋の1~5の数字の書いたボールが一つずつ入っている。中身を見ずに一つだけ取り出す場合の期待値を選択肢から選べ",
    correct_answer="c.3.3",
    choices=[
        "a.1.1",
        "b.12/5",
        "c.3.3",
        "d.5/3",
    ],
    commentary="期待値は取り出される数値の平均です。　(1 + 2 + 3 + 4 + 5) / 5 = 3が正解です",
    tag="基礎数学",
)

db = SessionLocal()
model217 = QuestionModel(
    question_text="あるスーパーのアプリは来店するたびに「来店ポイント」が付与される。付与されるのは1ポイントまたは10ポイントです。10ポイントが付与される確率は1/10です。Aさんが一度スーパーに行った場合、付与されるポイントの期待値として、最も適切な選択肢を1つ選べ。",
    correct_answer="a.期待値は1.9",
    choices=[
        "a.期待値は1.9",
        "b.期待値は1.0",
        "c.期待値は1.1",
        "d.期待値は2.0",
    ],
    commentary="正解はaである。期待値は、(確率変数の値)  ×  (その値をとる確率)を全通りについて足しあわせた値です。・10ポイントが付与される確率1/10、確率変数は10・1ポイントが付与される確率 1-(1/10)=9/10、確率変数は1よって計算式は以下となります。(1 × 9/10)+(10 × 1/10)=9/10+1= 1.9ポイント期待値の計算式を確認した上で、例えば、サイコロを1度振った時の出る目の期待値を計算してみることをお勧めします。",
    tag="基礎数学",
)

db = SessionLocal()
model218 = QuestionModel(
    question_text="サイコロを振る際に、出る目xがある値をとる確率f(x)が以下の式に従う場合、xの期待値として最も正しい選択肢を1つ選べ。f(x)  =  1/6、  1、2、…、6",
    correct_answer="d.3.5",
    choices=[
        "a.2.5",
        "b.3",
        "c.4",
        "d.3.5",
    ],
    commentary="期待値は以下のように計算されます。(1 × 1/6) + (2 × 1/6) + (3 × 1/6) + (4 × 1/6) + (5 × 1/6) + (6 × 1/6)=(1 + 2 + 3 + 4 + 5 + 6) × 1/6=21/6",
    tag="基礎数学",
)

db = SessionLocal()
model219 = QuestionModel(
    question_text="次の2つの母集団U1とU2を比べた時の特徴として、最も不適切な選択肢を1つ選べ。U1 = [47, 55, 60, 79, 100]、U2 = [49, 55, 60, 70, 75]",
    correct_answer="a.U2はU1より分散は大きい",
    choices=[
        "a.U2はU1より分散は大きい",
        "b.U2はU1より標準偏差が小さい",
        "c.U1に比べ、U2の平均が小さい",
        "d.U1とU2の中央値は同じ",
    ],
    commentary="この問題は、ほとんど計算しなくても、分散、標準偏差、平均、中央値の求め方を理解していれば、数値を観察することで正解にたどり着けるはずです。a,b：標準偏差は分散の平方根をとったものです。よって、分散が大きければ標準偏差も大きくなります。U1はU2より分散のばらつきが大きいので、U1はU2より分散(標準偏差)は大きいです。よって、選択肢aが誤りです。c.U1とU2に関して、4つ目までの数値の大小は劇的な差はないものの、5つ目の数値はU1の100がU2の75より遥かに大きいので、そこから計算した平均値はU1の方が大きいと推定できます。d.中央値とは、小さい順または大きい順に全ての数値を並べた際にちょうど真ん中にくる値です。ただし値が偶数個ある場合、真ん中の2つを2で割った値が中央値に当たります。ここで、5つの数値の中間に位置する中央値は、どちらも真ん中の60です。",
    tag="基礎数学",
)

db = SessionLocal()
model220 = QuestionModel(
    question_text="標本誤差という量に関する記述として、最も適切な選択肢を1つ選べ。",
    correct_answer="c.標本誤差とは、標本の値と母集団の値の差を表す。",
    choices=[
        "a.標本誤差とは標準の値のばらつきを表す。",
        "b.標本誤差は母集団のデータのばらつきから大きな影響を受けない。",
        "c.標本誤差とは、標本の値と母集団の値の差を表す。",
        "d.標本誤差は取り出されたサンプルのサイズに依存しない。",
    ],
    commentary="正解はcである。標本誤差とは、標本の値と母集団の値の差を表す数量です。母集団から標本を抽出して調査を実施する際に、調査の結果が信頼できるものかどうかを評価する目安として標本誤差を参考にすることがあります。一般的に標本誤差は、抽出されたサンプルのサイズが大きいほど、あるいは母集団のデータのばらつきが小さいほど小さくなります。しかし、ほとんどの場合、母集団の真の値が知られていません。その場合厳密に標本誤差を求めることは不可能です。代わりに、標本誤差のおおよその範囲を判断するために、標準誤差を使います。標準誤差とは、標本と母集団の間にどの程度の誤差があるかを、確率的に計算した量です。これも小さければ小さいほど、標本の調査結果は母集団に近いと言えます。",
    tag="基礎数学",
)

db = SessionLocal()
model221 = QuestionModel(
    question_text="確率分布について述べた内容について、最も不適切な選択肢を1選べ。",
    correct_answer="b.珍しい事象が一定期間内に発生する回数を表す確率変数は、一般的に標準正規分布に従う。",
    choices=[
        "a.標準正規分布と正規分布の確率密度関数はともに釣り鐘の形をしている。",
        "b.珍しい事象が一定期間内に発生する回数を表す確率変数は、一般的に標準正規分布に従う。",
        "c.身長や体重、製品の重さ、電池の寿命などの測定値を確率変数とする場合、その分布は連続的な確率密度変数となる。",
        "d.確率密度変数の曲線と横軸で囲まれた面積は確率に対応する。",
    ],
    commentary="不適切なのはbである。珍しい事象(例：工場の製品が以上である事象)は、標準化正規分布ではなく、二項分布あるいはポアソン分布に従うことが知られています。二項分布は2通りの結果しかない試行(ベルヌーイ試行)の時に、その試行の結果が従う分布です。例：コイン投げで表が出れば「成功」、裏が出れば「失敗」とするときの「成功」または「失敗」の回数1日に地震が起こる確率をpとすると、365日間でN回自身が起こる確率は、PN×(1-p)(365-N)というに項分布になるポアソン分布は、「ランダムに起きる事象」がある期間に何回起こるかの確率を調べるときに用いる確率分布です。どの時刻でも同様な起こりやすさでランダムに起こる現象と仮定した場合に、「単位時間あたりに平均N回起こる現象が、単位時間にk回起きる確率」(N、kは整数)を表すのに使われます。",
    tag="基礎数学",
)

db = SessionLocal()
model222 = QuestionModel(
    question_text="(ア)に最もよくあてはまる選択肢を1つ選べ。関数 y=f(x)のx=aにおける(ア)はf'(a)と書かれ、曲線f(x)のx=aにおける接線の傾きと解釈できる。",
    correct_answer="b.微分係数",
    choices=[
        "a.共相関係数",
        "b.微分係数",
        "c.導関数",
        "d.重み係数",
    ],
    commentary="正解はbである。関数 y= f(x)の接線をx=aにおいて引いたとき、その傾きf'(a)は、f(x)のx=aにおける微分係数と呼びます。導関数と混同しないように気を付けましょう。導関数は具体的な説明変数xの値を指定しない、f'(x)のことです。",
    tag="基礎数学",
)

db = SessionLocal()
model223 = QuestionModel(
    question_text="次の文章を読み、(ア)(イ)(ウ)に入る用語の組み合わせとして、最も適切な選択肢を1つ選べ。画像認識において、画像の画素の数値を特徴量として使う。画像とは画素の数値が縦横に並んでいる状態とみなすことができる。一般的に、数値が一列に並んだ構造は数学では(ア)と呼ばれ、縦×横の二次元で数値が並んでいる構造は(イ)と呼ばれる。(ウ)は(ア)と(イ)を扱っている数学の分野の1つである。",
    correct_answer="b.(ア)ベクトル(イ)行列(ウ)線形代数",
    choices=[
        "a.(ア)ベクトル(イ)テンソル(ウ)集合論",
        "b.(ア)ベクトル(イ)行列(ウ)線形代数",
        "c.(ア)セット(イ)集合(ウ)集合論",
        "d.(ア)セット(イ)テンソル(ウ)線形代数",
    ],
    commentary="選択肢、1、4にある「テンソル」は「行列」と似た意味で使われることが多いです。厳密に言うと、テンソルは「行列」を二次元に限定せず、多次元に拡張したものです。「行列」も「テンソル」の一部なので、(イ)に入る答えとして必ずしも間違っていませんが、選択肢1の(ウ)の「集合論」や選択肢4の(ア)の「セット」が適切ではないため正解にはなりません。",
    tag="基礎数学",
)

db = SessionLocal()
model224 = QuestionModel(
    question_text="行列AとBが共に m×nの行列であるとき、AとBのアダマール積のサイズとして、最も適切な選択肢を1つ選べ。",
    correct_answer="b.m×n",
    choices=[
        "a.n×n",
        "b.m×n",
        "c.n×m",
        "d.m ×m",
    ],
    commentary="正解はbである。アダマール積とは、縦横が同じ形の行列に対して、成分ごとに積を取った結果を成分とする行列です。よって、同じ形の行列で返すのが特徴です。　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　この場合、行列AとBが共にm×nの行列なので、アダマール積をとった結果もm×nです。　　　　　　　　アダマール積は機械学習のための配列型データの前処理などに使われることがあります。サイズが統一された2つのデータを掛け合わせることで新しいデータを作ることができます。",
    tag="基礎数学",
)

db = SessionLocal()
model225 = QuestionModel(
    question_text="外から見えない袋の1～5の数字の書いたボールが一つずつ入っている。中身を見ずに一つだけ取り出す場合の期待値を選択肢から選べ。",
    correct_answer="c.3",
    choices=[
        "a.1",
        "b.12/5",
        "c.3",
        "d.5/3",
    ],
    commentary="期待値は取り出される数値の平均です。(1+2+3+4+5)/5=3が正解です。",
    tag="基礎数学",
)

db = SessionLocal()
model226 = QuestionModel(
    question_text="次に示す母集団UがU'に変更された場合に言えることについて、もっとも適切なものを選択肢から選べ。U=[40、30、45、55、60]、U’=[40、30、95、55、60]",
    correct_answer="a.Uに比べ、U'の標準偏差は大きい",
    choices=[
        "a.Uに比べ、U'の標準偏差は大きい",
        "b.U'の中央値は変わらない",
        "c.Uに比べ、U'の平均は小さい",
        "d.Uに比べ、U'の分散は小さい",
    ],
    commentary="Uの3つ目の要素が45から95に変更されています。標準偏差と分散はデータのばらつきを表す指標です。平均から大きく外れる値に変更されたため、標準偏差や分散は大きくなります。",
    tag="基礎数学",
)

db = SessionLocal()
model227 = QuestionModel(
    question_text="以下の文章を読み、(ア)に最もよく当てはまる選択肢を1つ選べ。ランダムに操作を行い、操作の結果によって報酬を与える。報酬が最大になるように訓練していく学習方法を(ア)という。",
    correct_answer="d.強化学習",
    choices=[
        "a.ランダムフォレスト",
        "b.アソシエーション分析",
        "c.アンサンブル学習",
        "d.強化学習",
    ],
    commentary="ランダムに操作を繰り返し、正解に近い操作を行ったときに高い報酬を与えることで学習させていく方法を強化学習と呼ぶ。代表的な例として、囲碁のAIであるAlphaGoなどがある。",
    tag="機械学習",
)

db = SessionLocal()
model228 = QuestionModel(
    question_text="以下の文章を読み、(ア)に最もよく当てはまる選択肢を1つ選べ。強化学習において、エージェントが選択した行動の最終的な報酬の期待値を(ア)と呼ぶ。",
    correct_answer="b.Q値",
    choices=[
        "a.F値",
        "b.Q値",
        "c.M値",
        "d.L値",
    ],
    commentary="強化学習では、行動の最終的な報酬の期待値をQ値と呼びます。またQ値を求める関数をQ関数と呼び、学習方法によってQ関数が異なります。",
    tag="機械学習",
)

db = SessionLocal()
model229 = QuestionModel(
    question_text="最初に計算されたQ値と、実際に行動して得られるQ値の期待値との差を、Q値に反映させる学習方法をなんと呼ぶか。選択肢から最も適切なものを選べ。",
    correct_answer="d.Q学習",
    choices=[
        "a.SARSA",
        "b.モンテカルロ法",
        "c.勾配降下法",
        "d.Q学習",
    ],
    commentary="Q学習は計算したQ値と実際に行動して得られるQ値の期待値の差をQ値に反映させます。",
    tag="機械学習",
)

db = SessionLocal()
model230 = QuestionModel(
    question_text="一度行動して得られたQ値を使って、元のQ値を更新する学習方法をなんと呼ぶか、選択肢から最も適切なものを選べ。",
    correct_answer="a.SARSA",
    choices=[
        "a.SARSA",
        "b.モンテカルロ法",
        "c.勾配降下法",
        "d.Q学習",
    ],
    commentary="Q学習がQ値の期待値を計算するのに対して、SARSAはもう一度行動させて得られるQ値を使用してQ値を更新します。",
    tag="機械学習",
)

db = SessionLocal()
model231 = QuestionModel(
    question_text="報酬を得られるまでQ値の更新をせず、報酬を得たタイミングで今までのQ値を更新する学習方法をなんと呼ぶか、選択肢から最も適切なものを選べ。",
    correct_answer="b.モンテカルロ法",
    choices=[
        "a.SARSA",
        "b.モンテカルロ法",
        "c.勾配降下法",
        "d.Q学習",
    ],
    commentary="実際の報酬を得て初めてQ値を更新する手法をモンテカルロ法と呼びます。",
    tag="機械学習",
)

db = SessionLocal()
model232 = QuestionModel(
    question_text="Q学習にDeep Learningを取り入れた学習手法をなんと呼ぶか、最もよく当てはまる選択肢を1つ選べ。",
    correct_answer="c.DQN",
    choices=[
        "a.DCQ",
        "b.DLQ",
        "c.DQN",
        "d.DCQN",
    ],
    commentary="Q学習にDeep Learningを取り入れたものをDQN(Deep Q Network)と呼びます。状態を入力値、行動を出力値として、Q値を学習します。Q値を出力値として学習を行います。",
    tag="機械学習",
)

db = SessionLocal()
model233 = QuestionModel(
    question_text="強化学習において複数のエージェントを用意してそれぞれが学習を行う手法をなんというか。",
    correct_answer="d.マルチエージェント学習",
    choices=[
        "a.アンサンブル学習",
        "b.マルチモーダル",
        "c.ドメインランダマイゼーション",
        "d.マルチエージェント学習",
    ],
    commentary="複数のエージェントで並列に学習を行う手法をマルチエージェント学習と言います。",
    tag="機械学習",
)

db = SessionLocal()
model234 = QuestionModel(
    question_text="強化学習のモデルであるRainbowに含まれる手法として不適切なものを選択肢から選べ。",
    correct_answer="d.LSTM",
    choices=[
        "a.Noisy DQN",
        "b.Dueling DQN",
        "c.A3C",
        "d.LSTM",
    ],
    commentary="LSTMはRNNの一種でRainbowとは関係がありません。RainbowはDQN、DDQN、Prioritized DDQN、Dueling DDQN、A3C、Distributional DQN、Noisy DQNの7つの手法を取り入れています。",
    tag="機械学習",
)

db = SessionLocal()
model235 = QuestionModel(
    question_text="以下の文章が説明した単語として最も適切なものを選択肢から選べ。過去に蓄積されたデータのみで強化学習を行う手法",
    correct_answer="c.オフライン強化学習",
    choices=[
        "a.バッチ学習",
        "b.オンライン強化学習",
        "c.オフライン強化学習",
        "d.一気通貫学習",
    ],
    commentary="過去に蓄積されたデータから学習する手法をオフライン強化学習と言います。強化学習の実際に動作させるという行為は陸巣を伴う可能性があるため、sim2realなど様々な方法が研究されています。",
    tag="機械学習",
)

db = SessionLocal()
model236 = QuestionModel(
    question_text="Q値の期待値と実際の行動から得られるQ値との差を何と呼ぶか選択肢から選べ。",
    correct_answer="d.TD",
    choices=[
        "a.偏差",
        "b.学習誤差",
        "c.SSD",
        "d.TD",
    ],
    commentary="Q値の期待値と実際の行動から得られるQ値との差をTD(Temporal Difference)と呼びます。TDをもとに学習する手法にQ学習やSARSAなどがあります。",
    tag="機械学習",
)

db = SessionLocal()
model237 = QuestionModel(
    question_text="方策ベースの学習方法として適切なものを選択肢から選べ。",
    correct_answer="d.Actor-Critic",
    choices=[
        "a.バッチ学習",
        "b.Q学習",
        "c.DQN",
        "d.Actor-Critic",
    ],
    commentary="Actor-Criticは、Actor(行動者)とCritic(評価者)の二つの役割に分かれており、Actorは方策から行動を選択し、環境は状態と報酬を返します。CriticはActorの方策を評価します。Actor-Criticは方策をもとにして学習する方策ベースの学習方法といえます。",
    tag="機械学習",
)

db = SessionLocal()
model238 = QuestionModel(
    question_text="Actor-Criticにディープラーニングを取り入れて応用したモデルを何と呼ぶか選択肢から選べ。",
    correct_answer="a.A3C",
    choices=[
        "a.A3C",
        "b.Adam",
        "c.Dueling Network",
        "d.Noisy Network",
    ],
    commentary="A3CはActor-Criticにディープラーニングを取り入れてマルチエージェント学習を行うモデルです。Adamは最適化アルゴリズムの一つです。Dueling Network、Noisy NetworkはDQNの改良手法です。Dueling Network、Nosiy Networkは強化学習モデルですが、Actor Criticではありません。",
    tag="機械学習",
)

db = SessionLocal()
model239 = QuestionModel(
    question_text="シミュレーションで強化学習を行う際、シミュレーションの環境をランダムに変更することによって、AIの汎化性能を上げる手法を何と呼ぶか選択肢から選べ。",
    correct_answer="c.ドメインランダマイゼーション",
    choices=[
        "a.ランダムフォレスト",
        "b.BERT",
        "c.ドメインランダマイゼーション",
        "d.シンボルグラウンディング",
    ],
    commentary="シミュレーションの環境をランダムに変更することによって、AIの汎化性能を上げる手法をドメインランダマイゼーションと呼びます。",
    tag="機械学習",
)

db = SessionLocal()
model240 = QuestionModel(
    question_text="オフライン強化学習の説明として適切なものを選択肢から選べ。",
    correct_answer="",
    choices=[
        "a.現実世界に存在するものだけで学習を行う",
        "b.既存のデータだけで学習を行う",
        "c.インターネットに繋がっていないコンピュータを使用して学習を行う",
        "d.データを使わずに学習を行う",
    ],
    commentary="既存のデータだけで学習を行う手法をオフライン学習と呼びます。現実世界での学習が難しく、かつ、シミュレーションも難しい場合に利用されます。",
    tag="機械学習",
)

db = SessionLocal()
model241 = QuestionModel(
    question_text="強化学習において、シミュレーションの世界と現実世界のギャップを埋めることを何と呼ぶか、選択肢から選べ。",
    correct_answer="b.TD誤差",
    choices=[
        "a.sim2real",
        "b.TD誤差",
        "c.word2vec",
        "d.連続値制御",
    ],
    commentary="強化学習で現実世界の試行が難しい場合は、シミュレーションでの学習が主流になります。しかし、現実世界とシミュレーション世界は全く同じではなく、AIがシミュレーションの世界に過学習してしまいます。なるべくシミュレーションと現実の差を埋めようという考え方がsim2realです。sim2realはsimulated to realを略したものです。",
    tag="機械学習",
)

db = SessionLocal()
model242 = QuestionModel(
    question_text="状態表現学習の説明として適切なものを選択肢から選べ。",
    correct_answer="a.現実世界をどのようにシミュレーションするかを学習する",
    choices=[
        "a.現実世界をどのようにシミュレーションするかを学習する",
        "b.画像の状態を学習する",
        "c.3Dのバーチャル空間を学習データとする",
        "d.既存のデータだけで学習する",
    ],
    commentary="状態表現学習は、現実世界をシミュレーションの世界で再現するために行われる学習です。",
    tag="機械学習",
)

db = SessionLocal()
model243 = QuestionModel(
    question_text="強化学習をする際に目的にあった報酬を設定することが大切である。目的と報酬の組み合わせとして最も不適切なものを選択肢から選べ。",
    correct_answer="a.目的：将棋に勝利する、報酬：駒ごとに点数を決め、取った駒の点数を報酬とする",
    choices=[
        "a.目的：将棋に勝利する、報酬：駒ごとに点数を決め、取った駒の点数を報酬とする",
        "b.目的：シミュレーション世界で自動運転で目的地に到着する、報酬：交差点を曲がった回数を報酬とする",
        "c.迷路のゴールへ辿り着く、報酬：進んだ距離を報酬とする",
        "d.目的：人と会話する、報酬：相手の返事までの時間を報酬とする",
    ],
    commentary="選択肢bは、基本的に曲がる回数は少ないほうが目的地へ最短距離で行くことができるので報酬とすべきではありません。選択肢cも同じく、なるべく距離を短くしたほうが効率よく迷路を解いてくれるでしょう。選択肢dは、返事までの時間が長いということは、相手が返答に困っているということになり、会話が成立していないと判断できます。",
    tag="機械学習",
)

db = SessionLocal()
model244 = QuestionModel(
    question_text="機械学習と人工知能の関係について正しいものはどれですか？",
    correct_answer="a.機械学習は人工知能の一部であり、データから学習する手法を提供する",
    choices=[
        "a.機械学習は人工知能の一部であり、データから学習する手法を提供する",
        "b.機械学習は人工知能と無関係な分野である",
        "c.機械学習は人工知能よりも広い概念である",
        "d.機械学習と人工知能は同じ意味を持つ用語である",
    ],
    commentary="機械学習は人工知能の一部であり、データから学習する手法を提供します。機械学習は、AIシステムが経験からパターンを見つけ、予測や意思決定を行うための重要な技術です。",
    tag="機械学習",
)

db = SessionLocal()
model245 = QuestionModel(
    question_text="線形回帰とは何を予測するための手法ですか？",
    correct_answer="b.連続的な出力",
    choices=[
        "a.カテゴリズムな出力",
        "b.連続的な出力",
        "c.バイナリな出力",
        "d.テキストデータの分類",
    ],
    commentary="線形回帰は、連続的な出力を予測するための手法です。",
    tag="機械学習",
)

db = SessionLocal()
model246 = QuestionModel(
    question_text="ロジスティック回帰は何を予測するための手法ですか？",
    correct_answer="c.バイナリな出力",
    choices=[
        "a.テキストな出力",
        "b.連続的な出力",
        "c.バイナリな出力",
        "d.画像データの分類",
    ],
    commentary="ロジスティック回帰は、バイナリな出力を予測するための手法です。",
    tag="機械学習",
)

db = SessionLocal()
model247 = QuestionModel(
    question_text="ランダムフォレストは何のための手法ですか？",
    correct_answer="c.クラス分類や回帰のためのアンサンブル手法",
    choices=[
        "a.画像処理",
        "b.テキスト解析",
        "c.クラス分類や回帰のためのアンサンブル手法",
        "d.ビデオ編集",
    ],
    commentary="ランダムフォレストは、クラス分類や回帰のためのアンサンブル手法です。",
    tag="機械学習",
)

db = SessionLocal()
model248 = QuestionModel(
    question_text="ブースティングは何のための手法ですか？",
    correct_answer="b.徳微量の選択",
    choices=[
        "a.パラメータ最適化",
        "b.徳微量の選択",
        "c.データの前処理",
        "d.アンサンブル学習",
    ],
    commentary="ブースティングは、アンサンブル学習の手法の一つです。",
    tag="機械学習",
)

db = SessionLocal()
model249 = QuestionModel(
    question_text="サポートベクターマシン(SVM)は何のための手法ですか？",
    correct_answer="b.データのクラスタリング",
    choices=[
        "a.クラス分類や回帰のためのアンサンブル手法",
        "b.データのクラスタリング",
        "c.サンプルデータの複製",
        "d.線形分離可能なデータの分類",
    ],
    commentary="サポートベクターマシン(SVM)は主に分類のための手法で、特に線形分離可能なデータの分類に使用されます。カーネル手法を用いることで非線形分離も可能ですが、アンサンブル手法ではありません。",
    tag="機械学習",
)

db = SessionLocal()
model250 = QuestionModel(
    question_text="k-means法は何を行うための手法ですか？",
    correct_answer="a.クラスタリング",
    choices=[
        "a.クラスタリング",
        "b.回帰分析",
        "c.分類",
        "d.次元削減",
    ],
    commentary="k-means法は、データをクラスタに分類するためのクラスタリング手法です。",
    tag="機械学習",
)

db = SessionLocal()
model251 = QuestionModel(
    question_text="ウォード法は何のための手法ですか？",
    correct_answer="a.クラスタリング",
    choices=[
        "a.クラスタリング",
        "b.回帰分析",
        "c.分類",
        "d.次元削減",
    ],
    commentary="ウォード法は、階層的クラスタリング手法の一つで、データを階層的にクラスタに分割します。",
    tag="機械学習",
)

db = SessionLocal()
model252 = QuestionModel(
    question_text="主成分分析(PCA)は何を行うための手法ですか？",
    correct_answer="d.次元削減",
    choices=[
        "a.クラスタリング",
        "b.回帰分析",
        "c.分散の最大化",
        "d.次元削減",
    ],
    commentary="主成分分析(PCA)は、データの次元削減を行うための手法で、情報の損失を最小限に抑えながらデータを新しい座標系に変換します。",
    tag="機械学習",
)

db = SessionLocal()
model253 = QuestionModel(
    question_text="協調フィルタリングは何を行うための手法ですか？",
    correct_answer="b.レコメンデーション",
    choices=[
        "a.クラスタリング",
        "b.レコメンデーション",
        "c.分類",
        "d.回帰分析",
    ],
    commentary="協調フィルタリングは、ユーザーの過去の行動や他のユーザーの行動に基づいて、アイテムのレコメンデーションを行うための手法です。",
    tag="機械学習",
)

db = SessionLocal()
model254 = QuestionModel(
    question_text="トピックモデルは何のための手法ですか？",
    correct_answer="b.テキストの解析",
    choices=[
        "a.クラスタリング",
        "b.テキストの解析",
        "c.分類",
        "d.回帰分析",
    ],
    commentary="トピックモデルは、大量のテキストデータからトピック(主語)抽出するための手法です。",
    tag="機械学習",
)

db = SessionLocal()
model255 = QuestionModel(
    question_text="ビックデータの特徴として正しいものはどれですか？",
    correct_answer="b.伝統的なデータ処理ツールで容易に処理できる",
    choices=[
        "a.データの量が小さく、処理が簡単",
        "b.伝統的なデータ処理ツールで容易に処理できる",
        "c.高速でリアルタイムに処理できる",
        "d.複雑なデータセットや構造を持つ",
    ],
    commentary="ビックデータは、通常、複雑なデータセットや構造を持ち、伝統的なデータ処理ツールでは処理が難しい特徴があります。",
    tag="機械学習",
)

db = SessionLocal()
model256 = QuestionModel(
    question_text="レコメンデーションエンジンの主な目的は何ですか？",
    correct_answer="c.ユーザーに適切なアイテムを推薦する",
    choices=[
        "a.データの保護",
        "b.ウェブサイトのデザイン",
        "c.ユーザーに適切なアイテムを推薦する",
        "d.サーバーのパフォーマンス向上",
    ],
    commentary="レコメンデーションエンジンは、ユーザーに適切なアイテムを推薦することを目的としています？",
    tag="機械学習",
)

db = SessionLocal()
model257 = QuestionModel(
    question_text="スパムフィルターの機能として正しいものはどれですか？",
    correct_answer="d.不要な電子メールの検出",
    choices=[
        "a.ネットワークのセキュリティ保護",
        "b.ウェブページのランキング",
        "c.不要な広告のブロック",
        "d.不要な電子メールの検出",
    ],
    commentary="スパムフィルターは、不要な電子メールを検出してフィルタリングするためのツールです。",
    tag="機械学習",
)

db = SessionLocal()
model258 = QuestionModel(
    question_text="統計的自然言語処理の主な手法は何ですか？",
    correct_answer="b.機械学習手法",
    choices=[
        "a.ルールベース手法",
        "b.機械学習手法",
        "c.テキストマイニング手法",
        "d.パターン認識手法",
    ],
    commentary="統計的自然言語処理は、機械学習手法を使用してテキストデータを解析し、言語処理タスクを実行します。",
    tag="機械学習",
)

db = SessionLocal()
model259 = QuestionModel(
    question_text="コーパスとは何ですか？",
    correct_answer="d.テキストデータの集合",
    choices=[
        "a.文章の訳文",
        "b.プログラミング言語のコード",
        "c.単語の辞書",
        "d.テキストデータの集合",
    ],
    commentary="コーパスは、テキストデータの集合であり、自然言語処理のために学習や研究に使用されます。",
    tag="機械学習",
)

db = SessionLocal()
model260 = QuestionModel(
    question_text="バンディットアルゴリズムは何に関連していますか？",
    correct_answer="c.強化学習",
    choices=[
        "a.データのクラスタリング",
        "b.レコメンデーション",
        "c.強化学習",
        "d.次元削減",
    ],
    commentary="バンディットアルゴリズムは、強化学習の一種で、多肢選択問題における最適な選択を学習するための手法です。",
    tag="機械学習",
)

db = SessionLocal()
model261 = QuestionModel(
    question_text="マルコフ決定過程モデルは何をモデリングするための手法ですか？",
    correct_answer="d.確率的な遷移と報酬",
    choices=[
        "a.静的な状態空間",
        "b.動的な状態空間",
        "c.エピソードの列",
        "d.確率的な遷移と報酬",
    ],
    commentary="マルコフ決定過程モデルは、確率的な遷移と報酬を持つ動的な状態空間をモデリングするための手法",
    tag="機械学習",
)

db = SessionLocal()
model262 = QuestionModel(
    question_text="価値関数は何を評価するための関数ですか",
    correct_answer="b.状態の価値",
    choices=[
        "a.行動の価値",
        "b.状態の価値",
        "c.方策の価値",
        "d.報酬の価値",
    ],
    commentary="価値関数は一般に「状態の価値」を評価するための関数です。一方、行動の価値を評価する関数は「行動価値関数」または「Q関数」と呼ばれます。",
    tag="機械学習",
)

db = SessionLocal()
model263 = QuestionModel(
    question_text="人工知能(AI)の定義として最も適切なものはどれですか？",
    correct_answer="b.コンピュータが人間の知能を模倣して行動する技術",
    choices=[
        "a.コンピュータが自動的にデータを収集する技術",
        "b.コンピュータが人間の知能を模倣して行動する技術",
        "c.コンピュータが高精度で計算を行う技術",
        "d.コンピュータがネットワークを通じて情報を交換する技術",
    ],
    commentary="人工知能(AI)は、コンピュータが人間の知能を模倣して行動する技術を指します。これは、推論、学習、問題解決、理解などの知的な行動を含みます。",
    tag="AI概論",
)

db = SessionLocal()
model264 = QuestionModel(
    question_text="次のうち、人工知能の一般的な目的に該当するものはどれですか？",
    correct_answer="b.人間の認知能力の模倣と行動",
    choices=[
        "a.データの暗号化",
        "b.人間の認知能力の模倣と行動",
        "c.インターネット接続の高速化",
        "d.コンピュータのハードウェア性能の向上",
    ],
    commentary="人工知能の一般的な目的は、人間の認知能力の模倣と向上にあります。これには、知覚、推論、学習、言語理解などの人間の知的能力を再現することが含まれます",
    tag="AI概論",
)

db = SessionLocal()
model265 = QuestionModel(
    question_text="強いAI(Strong AI)と弱いAI(Weak AI)の違いとして正しいものはどれですか？",
    correct_answer="b.強いAIは人間と同じレベルの知能を持ち、弱いAIは特定のタスクに特価している",
    choices=[
        "a.強いAIは物理的なタスクを行うが、弱いAIは論理的なタスクを行う",
        "b.強いAIは人間と同じレベルの知能を持ち、弱いAIは特定のタスクに特価している",
        "c.強いAIはデータを収集するが、弱いAIはデータを解析する",
        "d.強いAIは完全に自律的であり、弱いAIは人間の指示を必要とする",
    ],
    commentary="強いAI(Strong AI)は人間と同じレベルの知能を持ち、あらゆる知的タスクをこなせるとされる概念であるのに対し、弱いAI(Weak AI)は特定のタスクに特化しているシステムを指します。現在実用化されているのはほとんどが弱いAIです",
    tag="AI概論",
)

db = SessionLocal()
model266 = QuestionModel(
    question_text="チューリングテストとは何ですか？",
    correct_answer="c.コンピュータが人間と区別できないほどの知的な応答をするかどうかを評価するテスト",
    choices=[
        "a.コンピュータの処理速度を測定するテスト",
        "b.コンピュータが他のコンピュータと通信する能力を評価するテスト",
        "c.コンピュータが人間と区別できないほどの知的な応答をするかどうかを評価するテスト",
        "d.コンピュータが画像を認識する能力を評価するテスト",
    ],
    commentary="チューリングテストは、コンピュータが人間と区別できないほどの知的な応答をするかどうかを評価するテストです。1950年にアラン・チューリングが提唱しました。",
    tag="AI概論",
)

db = SessionLocal()
model267 = QuestionModel(
    question_text="人工知能という用語が初めて提唱されたのはどの会議ですか？",
    correct_answer="a.ダートマス会議",
    choices=[
        "a.ダートマス会議",
        "b.ロスアラモス会議",
        "c.バロアルト会議",
        "d.ハーバード会議",
    ],
    commentary="1956年に開催されたダートマス会議で、ジョン・マッカーシーらが「人工知能」という用語を初めて提唱しました。この会議はAI研究の出発点とされています。",
    tag="AI概論",
)

db = SessionLocal()
model268 = QuestionModel(
    question_text="1950年代にジョン・マッカーシーが提唱した人工知能の定義はどれですか？",
    correct_answer="b.コンピュータが推論と問題解決を行う能力",
    choices=[
        "a.コンピュータが人間のように行動する能力",
        "b.コンピュータが推論と問題解決を行う能力",
        "c.コンピュータが学習と適応を行う能力",
        "d.コンピュータが知的な仕事を行う能力",
    ],
    commentary="ジョン・マッカーシーは、AIを「コンピュータが知的な仕事を行う能力」と定義しました。彼はAI研究の先駆者であり、LISPプログラミング言語の開発者でもあります。",
    tag="AI概論",
)

db = SessionLocal()
model269 = QuestionModel(
    question_text="1970年代から1980年代にかけて、人工知能の商業応用として広く研究されたシステムは何ですか？",
    correct_answer="b.エキスパートシステム",
    choices=[
        "a.ニューラルネットワーク",
        "b.エキスパートシステム",
        "c.強化学習システム",
        "d.自然言語処理システム",
    ],
    commentary="エキスパートシステムは、専門知識をコンピュータ上でシミュレートするシステムで、この時期に広く商業応用されました。代表例には、MYCINという医療診断システムがあります。",
    tag="AI概論",
)

db = SessionLocal()
model270 = QuestionModel(
    question_text="「AIの冬」と呼ばれる期間が訪れた主な理由として最も適切なものはどれですか？",
    correct_answer="a.研究資金の大幅な削減",
    choices=[
        "a.研究資金の大幅な削減",
        "b.コンピュータの性能低下",
        "c.インターネットの普及",
        "d.ビッグデータの不足",
    ],
    commentary="「AIの冬」は、期待に反して成果が出なかったため、AI研究への投資が大幅に現象した時期を指します。この結果、研究活動が停滞しました。",
    tag="AI概論",
)

db = SessionLocal()
model271 = QuestionModel(
    question_text="ローブナーコンテストは何をテストするための競技会ですか？",
    correct_answer="c.自然言語生成",
    choices=[
        "a.言語理解",
        "b.ロボット技術",
        "c.自然言語生成",
        "d.人工知能の一般的な能力",
    ],
    commentary="ローブナーコンテストは、人工知能が人間のように自然言語を理解し、生成する能力をテストするための競技会です。具体的には、「チューリングテスト」をベースにしており、コンピュータプログラムが人間と区別できないほどの会話を行う能力を試します。",
    tag="AI概論",
)

db = SessionLocal()
model272 = QuestionModel(
    question_text="中国語の部屋は何をシュミレートするための実験ですか？",
    correct_answer="c.言語の理解",
    choices=[
        "a.複数言語の翻訳",
        "b.文章の生成",
        "c.言語の理解",
        "d.多言語の会話",
    ],
    commentary="中国語の部屋(Chinese Room)は、言語の理解をシュミレートするための実験です。この実験は、ジョン・サールが提唱したもので、コンピュータがシンボル操作によって中国語の文章を処理できたとしても、実際にはその意味を理解しているわけではないということを示そうとするものです。",
    tag="AI概論",
)

db = SessionLocal()
model273 = QuestionModel(
    question_text="機械翻訳の主な目的は何ですか？",
    correct_answer="c.言語間の自動翻訳",
    choices=[
        "a.オリジナルの文章の保護",
        "b.パラグラフの構造を理解する",
        "c.言語間の自動翻訳",
        "d.言語の発音を学ぶ",
    ],
    commentary="機械翻訳の主な目的は、言語間の自動翻訳を実現することです。",
    tag="AI概論",
)

db = SessionLocal()
model273 = QuestionModel(
    question_text="ルールベース機械翻訳の特徴は何ですか？",
    correct_answer="c.言語間の文法ルールを利用する",
    choices=[
        "a.大規模なトレーニングデータが必要",
        "b.文脈を考慮する",
        "c.言語間の文法ルールを利用する",
        "d.統計的手法を使用する",
    ],
    commentary="ルールベース機械翻訳は、言語間の文法ルールを利用して翻訳を行います。",
    tag="AI概論",
)

db = SessionLocal()
model274 = QuestionModel(
    question_text="統計学的機械翻訳の主な特徴は何ですか？",
    correct_answer="c.言語の文脈を考慮する",
    choices=[
        "a.大規模なトレーニングデータが必要",
        "b.言語の文法を厳密に尊守する",
        "c.言語の文脈を考慮する",
        "d.ルールベースアプローチを使用する",
    ],
    commentary="統計学的機械翻訳は、言語の文脈を考慮して翻訳を行います。",
    tag="AI概論",
)

db = SessionLocal()
model275 = QuestionModel(
    question_text="イライザ(ELIZA)の開発者は誰ですか？",
    correct_answer="c.ジョセフ・ワイゼンバウム",
    choices=[
        "a.ジョン・マッカーシー",
        "b.マーヴィン・ミンスキー",
        "c.ジョセフ・ワイゼンバウム",
        "d.アラン・チューリング",
    ],
    commentary="イライザ(ELIZA)は、1996年にジョセフ・ワイゼンバウムによって開発された初期の自然言語処理プログラムです。",
    tag="AI概論",
)

db = SessionLocal()
model276 = QuestionModel(
    question_text="イライザ効果とは何ですか？",
    correct_answer="b.人々がコンピュータプログラムに対して感情的な反応を示す現象",
    choices=[
        "a.AIが人間の感情を完全に理解する現象",
        "b.人々がコンピュータプログラムに対して感情的な反応を示す現象",
        "c.AIが人間と同じように推論する現象",
        "d.AIが自立的に学習する現象",
    ],
    commentary="イライザ効果は、人々が実際には理解していない単純なプログラムに対して感情的な反応を示す現象です。",
    tag="AI概論",
)

db = SessionLocal()
model276 = QuestionModel(
    question_text="マイシン(MYCIN)は何のために開発されたエキスパートシステムですか？",
    correct_answer="b.医療診断",
    choices=[
        "a.気象予想",
        "b.医療診断",
        "c.自動運転",
        "d.株式取引",
    ],
    commentary="マイシン(MYCIN)は、細菌感染症の診断と治療のために開発された医療エキスパートシステムです。",
    tag="AI概論",
)

db = SessionLocal()
model277 = QuestionModel(
    question_text="DENDRALプロジェクトの目的は何ですか？",
    correct_answer="c.化学構造の解析",
    choices=[
        "a.自然言語処理",
        "b.画像認識",
        "c.化学構造の解析",
        "d.音声認識",
    ],
    commentary="DENDRALは、化学構造の解析を目的としたエキスパートシステムであり、質量分析データから有機化合物の構造を推定するために使用されました。",
    tag="AI概論",
)

db = SessionLocal()
model278 = QuestionModel(
    question_text="インタビューシステムの主要な利用例として適切なものはどれですか？",
    correct_answer="b.病歴の収集",
    choices=[
        "a.自動運転車の制御",
        "b.病歴の収集",
        "c.音声合成",
        "d.パターン認識",
    ],
    commentary="インタビューシステムは、ユーザーから病歴などの情報を収集するために利用されるシステムです。",
    tag="AI概論",
)

db = SessionLocal()
model279 = QuestionModel(
    question_text="AI効果の説明として、最も適切な選択肢を1つ選べ。",
    correct_answer="b.AIへの期待が大きいのに対し、一度AIの原理を知ると、人々は「これは知能ではなく、単なる自動化である」と失望する。",
    choices=[
        "a.AIが普及し、より多くの人がAIの原理を理解するようになるにつれて、AIへの期待が高まる。",
        "b.AIへの期待が大きいのに対し、一度AIの原理を知ると、人々は「これは知能ではなく、単なる自動化である」と失望する。",
        "c.AIによって多くの職業が失われ、雇用をはじめとする社会問題をもたらす。",
        "d.仕組みのわかりやすいAIの開発により、AIが社会に受け入れやすくなった。",
    ],
    commentary="AI効果とは、AIによって様々な課題が解決可能になってきた近年、AIの原理をいったん知ってしまうと、「人工の知能ではなく、単なる自動化に過ぎない」と思ってしまう人間の心理を指します。本来のAIへの期待の大きさの分だけ失望してしまいます。他の選択肢はＡＩ効果の説明とは異なります。",
    tag="AI概論",
)

db = SessionLocal()
model280 = QuestionModel(
    question_text="AIに期待できる性能として、最も不適切な選択肢を1つ選べ",
    correct_answer="a.AI効果とは、強いAIですら本物の知識をもたないと考える人間の心理状態を意味する。",
    choices=[
        "a.AI効果とは、強いAIですら本物の知識をもたないと考える人間の心理状態を意味する。",
        "b.弱いAIは特定のタスクにおいて、高性能を出すことができる",
        "c.現在実用化されているAIシステムは全て弱いAIである",
        "d.AI効果とは、いったん仕組みを理解すると、AIに知識がなく、ただの自動化システムに過ぎないと思ってしまう人間の心理状態を意味する",
    ],
    commentary="AI効果の本質は、「AIを単なる自動化と思ってしまう」ことです。よって、選択肢1はAI効果に関する内容として誤りであり、かつ選択肢4は正しい内容です。弱いAI：特定のタスクにおいて性能を発揮する特化型AI。例：工場の製造ラインで異常検知を行うAI、機械翻訳AI。・強いAI：人間のような自意識と自立性にもとづく知的活動が可能である汎用型AI",
    tag="AI概論",
)

db = SessionLocal()
model281 = QuestionModel(
    question_text="機械やソフトウェアに知識があるとみなせるかどうかを判別する手法として、最も適切な選択肢を1つ選べ。",
    correct_answer="d.チューリングテスト",
    choices=[
        "a.身体性テスト",
        "b.中国語の部屋",
        "c.交差検証",
        "d.チューリングテスト",
    ],
    commentary="チューリングテストは、コンピュータに知識が存在するか判別する仕組みです。選択肢a：存在しない単語です。選択肢b：「中国語の部屋」はチューリングテストに対する反論の一例です。選択肢c：機械学習において学習済みモデルの精度をテストするための手法です。",
    tag="AI概論",
)

db = SessionLocal()
model282 = QuestionModel(
    question_text="第2次AIブームを特徴づける内容として、最も適切な選択肢を1つ選べ",
    correct_answer="c.知識をコンピュータに蓄え、質問に対す専門家にかわって返答するAIが開発された",
    choices=[
        "a.チェスや迷路をはじめとするゲームが得意なAIの開発にはじめて成功した",
        "b.推論と探索を得意とするAIの研究が盛んに行われた",
        "c.知識をコンピュータに蓄え、質問に対す専門家にかわって返答するAIが開発された",
        "d.画像から特徴表現を自動的に見つけ出すAIが開発された",
    ],
    commentary="第2次AIブームでは、コンピュータ(AI)に特定の専門分野の知識を大量に溜め込み、パターンマッチングを利用し専門家のように応答するエキスパートシステムが実用化されました。選択肢a、b：第1次AIブームの特徴です。この時期に、ゲームのような明確に定義されている時間に限って、自動化や推論・探索の性能を発揮しました。選択肢d：第3次AIブームの特徴です。この時期にディープラーニングがブレークスルー(技術の急激な進展)を果たし、データから自動的に特徴を抽出し、画像認識などで高精度を出せたことで注目されるようになりました。",
    tag="AI概論",
)

db = SessionLocal()
model283 = QuestionModel(
    question_text="以下の文章を読み、(ア)に最もよくあてはまる選択肢を1つ選べ。第2次AIブームでは、一見社会に有用なAIの開発に成功したように見えたものの、しばらくして(ア)という問題が発覚するとともに徐々に第2次AIブームも衰退していった。",
    correct_answer="a.大量な知識の獲得と管理が大変",
    choices=[
        "a.大量な知識の獲得と管理が大変",
        "b.知識をヒアリングした専門家の意見が時間とともに変わっていく",
        "c.著作権の問題",
        "d.データの計算に高性能なコアを必要としていた",
    ],
    commentary="エキスパートシステムは、自ら知識を獲得できないため、知識を専門家からヒアリングし、貯蓄、管理するコストが難点でした。また、人間の知識は経験や常識にもとづく部分が多いため、整合性や一貫性を保つために膨大なルール作りも困難でした。この一連の困難を「知識獲得のボトルネック」とも呼び、1980年代に第2次AIブームが収束したきっかけとなりました。",
    tag="AI概論",
)

db = SessionLocal()
model284 = QuestionModel(
    question_text="第2次AIブームの時に開発された、有機化合物の分子構造を推定するシステムとして、最も適切な選択肢を1つ選べ。",
    correct_answer="a.DENDRAL",
    choices=[
        "a.DENDRAL",
        "b.CASNET",
        "c.MYCIN",
        "d.Watson",
    ],
    commentary="第2次AIブームでは、知識をコンピュータに蓄え、それにもとづいて専門家のように質問に応答するエキスパートシステムが実用化されました。DENDRALは、質量分析法で分析したデータを活用して、未知の有機化合物の分子構造を推定するエキスパートシステムです。選択肢b：CASNETは、緑内障の診断支援を行うエキスパートシステムです。選択肢c：MYCINは、感染症の専門医の代わりに診察を行うエキスパートシステムです。選択肢d：Watson(ワトソン)は、2009年にIBMから発表され、ライトウェイトオントロジーを応用した質問応答ができるAIです。2011年に、米国のクイズ番組「Jeopardy!」において人間のチャンピオンと対戦し、勝利を果たしたことで有名です。",
    tag="AI概論",
)

db = SessionLocal()
model285 = QuestionModel(
    question_text="第1次AIブームに生まれた探索・推論を可能とするAIの用途として、最も適切な選択肢を1つ選べ",
    correct_answer="b.掃除ロボット",
    choices=[
        "a.ATM",
        "b.掃除ロボット",
        "c.決定木",
        "d.顔認識システム",
    ],
    commentary="掃除ロボットは、センサーを用いて部屋の形を探索しながら障害物の存在を推論します。そのため、同じ所を複数回通過せずに効率よく掃除することができます。掃除ロボットのような古典的なAIは、特定な分野において状況に応じて振る舞いができる「レベル2のAI」に分類されます。選択肢a：ATMには探索や推論の要素が含まれず、シンプルな条件マッチングを使ったシステムです。選択肢c：決定木は機械学習の手法の1つであり、第1次AIブームに誕生したAIよりもワンランク上の「レベル3のAI」です。選択肢d：顔認識システムは一般的に、ディープラーニングを活用した「レベル4のAI」であり、第3次AIブームの時期に開発されています。",
    tag="AI概論",
)

# db = SessionLocal()
# model286 = QuestionModel(
#     question_text="",
#     correct_answer="",
#     choices=[
#         "a.",
#         "b.",
#         "c.",
#         "d.",
#     ],
#     commentary="",
#     tag="AI概論",
# )

db = SessionLocal()
model287 = QuestionModel(
    question_text="以下の文章を読み、(ア)に最もよくあてはまる選択肢を1つ選べ。第1次AIブームにおいては、(ア)を用いた人工知能が台頭した。",
    correct_answer="c.探索と推論",
    choices=[
        "a.パーセプトロン",
        "b.分類と回帰",
        "c.探索と推論",
        "d.知識ペース",
    ],
    commentary="探索と推論を用いて、比較的ルールがシンプルな問題に対して解を導出することができたことが、第1次AIブームに火をつけました。探索は初期状態から目的状態に至るまでの道筋を、場合分けや試行錯誤をしながら探すこと、推論は既知の知識をもとに未知の出来事を推測することを指します。他の選択肢は、第1次AIブームの特徴を表さない用語です。選択肢a：パーセプトロンは第3次AIブームに登場したニューラルネットワークの基本的な構成単位です。選択肢b：分類と回帰は、主に教師あり学習(機械学習)を用いて行われるタスクです。選択肢d：あらゆる分野の知識を蓄える場所が知識スペース(ナレッジベース)と呼ばれます。これは、第2次AIブームにおいて、自然言語で記述された知識を記号体系に変換しコンピュータに受け継がせる研究に関連する用語です。",
    tag="AI概論",
)

db = SessionLocal()
model288 = QuestionModel(
    question_text="これまでにAIブームが３度起きたと言われる。第２次AIブームの終焉の原因として、最も不適切な選択肢を１つ選べ。",
    correct_answer="c.知識をデータとして保存するためのディスク・メモリーを確保することが大変",
    choices=[
        "a.知識の項目間で矛盾が生じないように知識を管理することが大変",
        "b.該当部分に関する知識を満遍なくコンピュータに集約するのが大変",
        "c.知識をデータとして保存するためのディスク・メモリーを確保することが大変",
        "d.質疑応答における言葉の揺らぎに対応できるようにシステムを構築することが大変",
    ],
    commentary="第２次AIブームを代表する技術であるエキスパートシステムは第1次AIブームの時に比べて実世界での適用範囲は広がったものの、選択肢a、b、dのような課題があったため、ブームは終焉を迎えました。選択肢cだけがこの時代のエキスパートシステムにまつわる困難と直接関係していません。第2次AIブームでエキスパートシステムが普及する中で次のような知識の抽出と蓄積に関する問題点が判明しました。・専門知識を取り込むためには毎回、専門家にヒアリングする必要がある。ヒアリングした内容から有用な知識だけを取り出す処理は、非常にコストが高い。概念間に関係性を記述したルールを追加すればするほど、維持管理が大変。数多くのルールが互いに矛盾し、一貫性を保ちにくい。",
    tag="深層学習",
)

db = SessionLocal()
model289 = QuestionModel(
    question_text="エキスパートシステムの開発と活用に伴う困難について、最も不適切な選択肢を１つ選べ",
    correct_answer="c.蓄積する知識の量が多いあまり、それを処理するためのコンピュータ処理能力が不十分だった。",
    choices=[
        "a.複数の分野を横断した汎用的なエキスパートシステムの構築が困難だった。",
        "b.経験則や常識にもとづいた知識を抽出し、体系的にコンピュータに実装することが困難だった。",
        "c.蓄積する知識の量が多いあまり、それを処理するためのコンピュータ処理能力が不十分だった。",
        "d.人間の専門家とは異なり、応答が不自然であることもあった。",
    ],
    commentary="第２次AIブームを代表するエキスパートシステムでは、専門家(エキスパート)から知識をヒアリングし、その知識をコンピュータの中で整理し蓄積します。ユーザーが質問をした際に、該当すると思われる答えを抽出し回答します。エキスパートシステムが医療や自然科学など、様々な分野で実用化されました。一方で、知識の整備と保守には高いコストがかかっていました。適格な判断を下すためには、ありとあらゆる専門知識を教え込む作業が必要となり相当な労力が必要です。また、知識を管理するために、世の中の「全て」のルールを適用することは非現実的です。それゆえ、システムを使う中では頻繁に例外や矛盾にぶつかることがあります。選択肢cだけは、エキスパートシステムが対面していた課題とは関係ない項目です。コンピュータの処理能力や知識を保存するデータベースそのものは、第2次AIブームの主要な問題ではありませんでした。",
    tag="深層学習",
)

db.add(model131)
db.add(model132)
db.add(model133)
db.add(mode134)
db.add(mode135)
db.add(mode136)
db.add(mode137)
db.add(mode138)
db.add(model139)
db.add(model140)
db.add(model141)
db.add(model142)
db.add(model143)
db.add(model144)
db.add(model145)
db.add(model146)
db.add(model147)
db.add(model148)
db.add(model149)
db.add(model150)
db.add(model151)
db.add(model152)
db.add(model153)
db.add(model154)
db.add(model155)
db.add(model156)
db.add(model157)
db.add(model158)
db.add(model160)
db.add(model161)
db.add(model162)
db.add(model163)
db.add(model164)
db.add(model165)
db.add(model166)
db.add(model167)
db.add(model168)
db.add(model169)
db.add(model170)
db.add(model171)
db.add(model172)
db.add(model173)
db.add(model174)
db.add(model175)
db.add(model176)
db.add(model177)
db.add(model178)
db.add(model179)
db.add(model180)
db.add(model181)
db.add(model182)
db.add(model183)
db.add(model184)
db.add(model185)
db.add(model186)
db.add(model187)
db.add(model188)
db.add(model189)
db.add(model190)
db.add(model191)
db.add(model192)
db.add(model193)
db.add(model194)
db.add(model195)
db.add(model196)
db.add(model197)
db.add(model198)
db.add(model199)
db.add(model200)
db.add(model201)
db.add(model202)
db.add(model203)
db.add(model204)
db.add(model205)
db.add(model206)
db.add(model207)
db.add(model208)
db.add(model209)
db.add(model210)
db.add(model211)
db.add(model212)
db.add(model213)
db.add(model214)
db.add(model215)
db.add(model216)
db.add(model217)
db.add(model218)
db.add(model219)
db.add(model220)
db.add(model221)
db.add(model222)
db.add(model223)
db.add(model224)
db.add(model225)
db.add(model226)
db.add(model227)
db.add(model228)
db.add(model229)
db.add(model230)
db.add(model231)
db.add(model232)
db.add(model233)
db.add(model234)
db.add(model235)
db.add(model236)
db.add(model237)
db.add(model238)
db.add(model239)
db.add(model240)
db.add(model241)
db.add(model242)
db.add(model243)
db.add(model244)
db.add(model245)
db.add(model246)
db.add(model247)
db.add(model248)
db.add(model249)
db.add(model250)
db.add(model251)
db.add(model252)
db.add(model253)
db.add(model254)
db.add(model255)
db.add(model256)
db.add(model257)
db.add(model258)
db.add(model259)
db.add(model260)
db.add(model261)
db.add(model262)
db.add(model263)
db.add(model264)
db.add(model265)
db.add(model266)
db.add(model267)
db.add(model268)
db.add(model269)
db.add(model270)
db.add(model271)
db.add(model272)
db.add(model273)
db.add(model274)
db.add(model275)
db.add(model276)
db.add(model277)
db.add(model278)
db.add(model279)
db.add(model280)
db.add(model281)
db.add(model282)
db.add(model283)
db.add(model284)
db.add(model285)
db.add(model287)
db.add(model288)
db.add(model289)
db.commit()
